{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural**"
      ],
      "metadata": {
        "id": "2aWcwzNkIl8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "Datos del alumno (Nombre y Apellidos): Jose Manuel Pinillos Rubio\n",
        "\n",
        "Fecha: 31 de enero de 2025\n",
        "***"
      ],
      "metadata": {
        "id": "2Q3av1dqJAJ7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktFg2jj3jTE6"
      },
      "source": [
        "# <span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Laboratorio: *word embeddings* y *transformers* para clasificación de texto</span>\n",
        "\n",
        "**Objetivos**\n",
        "\n",
        "Con este laboratorio el alumno comparará diferentes modelos de clasificación de texto mediante el uso de técnicas basadas en word embedings y transformers. El alumno, por tanto, adquirirá dos competencias: primero, la capacidad de aplicar un modelo neuronal para la clasificación de texto y, segundo, la capacidad de comparar diferentes modelos entre sí.\n",
        "\n",
        "El objetivo es entender los conceptos que se trabajan y ser capaz de hacer pequeñas experimentaciones para mejorar el Notebook creado.\n",
        "\n",
        "**Descripción**\n",
        "\n",
        "En esta actividad vamos a trabajar en clasificar textos. Se recorrerá todo el proceso desde traer el dataset hasta proceder a dicha clasificación. Durante la actividad se llevarán a cabo muchos procesos como la creación de un vocabulario, el uso de embeddings y la creación de modelos.\n",
        "\n",
        "Las cuestiones presentes en esta actividad están basadas en un Notebook creado por François Chollet, uno de los creadores de Keras y autor del libro \"Deep Learning with Python\".\n",
        "\n",
        "En este Notebook se trabaja con el dataset \"Newsgroup20\" que contiene aproximadamente 20000 mensajes que pertenecen a 20 categorías diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hytURWLLjZvT"
      },
      "source": [
        "# Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DbxRuvOwkzSs"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías necesarias\n",
        "\n",
        "import numpy as np  # Biblioteca para manejo de arreglos numéricos y operaciones matemáticas\n",
        "import tensorflow as tf  # Biblioteca para la construcción y entrenamiento de modelos de aprendizaje profundo\n",
        "from tensorflow import keras  # Módulo de Keras dentro de TensorFlow para facilitar la implementación de redes neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXfYbCflkQYy"
      },
      "source": [
        "# Descarga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e-1ZhOf3lB_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee33635f-eb48-41c8-b959-8178b78d9156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
            "\u001b[1m17329808/17329808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "El dataset ha sido descargado y extraído en: /root/.keras/datasets/news20_extracted\n"
          ]
        }
      ],
      "source": [
        "# Descargamos el dataset \"20 Newsgroups\" desde la URL proporcionada\n",
        "# y lo extraemos automáticamente (untar=True).\n",
        "\n",
        "data_path = keras.utils.get_file(\n",
        "    \"news20.tar.gz\",  # Nombre del archivo que se descargará y almacenará en la caché de Keras\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",  # URL del dataset\n",
        "    untar=True,  # Indica que el archivo se descomprimirá automáticamente tras la descarga\n",
        ")\n",
        "\n",
        "# 'data_path' almacena la ruta donde se ha descargado y extraído el dataset.\n",
        "# Para verificar la ruta exacta, la imprimimos en pantalla.\n",
        "print(\"El dataset ha sido descargado y extraído en:\", data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l3ygvoWhlCYj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "988e98ef-04b2-4523-d731-479264a39fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of directories: 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Directory names:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['talk.politics.guns',\n",
              " 'rec.sport.baseball',\n",
              " 'comp.windows.x',\n",
              " 'sci.space',\n",
              " 'talk.politics.mideast',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'talk.politics.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.graphics',\n",
              " 'misc.forsale',\n",
              " 'talk.religion.misc',\n",
              " 'alt.atheism',\n",
              " 'sci.electronics',\n",
              " 'rec.motorcycles',\n",
              " 'sci.crypt',\n",
              " 'sci.med',\n",
              " 'rec.sport.hockey',\n",
              " 'soc.religion.christian',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'rec.autos']"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Importamos las librerías necesarias para manejar rutas y directorios\n",
        "import os  # Biblioteca para interactuar con el sistema de archivos\n",
        "import pathlib  # Biblioteca para manejar rutas de archivos de manera más estructurada\n",
        "\n",
        "# Definimos la ruta del directorio base donde se encuentra el dataset\n",
        "data_dir = pathlib.Path(data_path).parent / \"news20_extracted\" / \"20_newsgroup\"\n",
        "\n",
        "# Listamos los nombres de los subdirectorios dentro del dataset\n",
        "dirnames = os.listdir(data_dir)\n",
        "\n",
        "# Imprimimos la cantidad de subdirectorios (categorías de noticias) y sus nombres\n",
        "print(\"Number of directories:\", len(dirnames))  # Muestra cuántas categorías hay en el dataset\n",
        "display(\"Directory names:\", dirnames)  # Lista los nombres de las categorías de noticias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uED3yrSl2kFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1189972e-aecb-4231-ceb9-46e99e5f92b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ruta del dataset: /root/.keras/datasets/news20_extracted/20_newsgroup\n"
          ]
        }
      ],
      "source": [
        "# Imprimimos la ruta del directorio donde se encuentra el dataset después de la extracción\n",
        "print(\"Ruta del dataset:\", data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OG8rjgOFlcaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f094fa70-f97b-4018-f59e-c320ec147817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in comp.graphics: 1000\n",
            "Some example filenames: ['38591', '38357', '38235', '38794', '38899']\n"
          ]
        }
      ],
      "source": [
        "# Listamos los archivos dentro de la categoría \"comp.graphics\", una de las categorías del dataset \"20 Newsgroups\"\n",
        "fnames = os.listdir(data_dir / \"comp.graphics\")  # Obtenemos la lista de archivos en la carpeta \"comp.graphics\"\n",
        "\n",
        "# Imprimimos el número total de archivos en esta categoría\n",
        "print(\"Number of files in comp.graphics:\", len(fnames))\n",
        "\n",
        "# Mostramos los nombres de los primeros 5 archivos como ejemplo\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8ox6s6z9lgps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1469dba2-be9d-4696-d40a-7e3bf23ed017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xref: cantaloupe.srv.cs.cmu.edu comp.graphics:37261 alt.graphics:519 comp.graphics.animation:2614\n",
            "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!zaphod.mps.ohio-state.edu!darwin.sura.net!dtix.dt.navy.mil!oasys!lipman\n",
            "From: lipman@oasys.dt.navy.mil (Robert Lipman)\n",
            "Newsgroups: comp.graphics,alt.graphics,comp.graphics.animation\n",
            "Subject: CALL FOR PRESENTATIONS: Navy SciViz/VR Seminar\n",
            "Message-ID: <32850@oasys.dt.navy.mil>\n",
            "Date: 19 Mar 93 20:10:23 GMT\n",
            "Article-I.D.: oasys.32850\n",
            "Expires: 30 Apr 93 04:00:00 GMT\n",
            "Reply-To: lipman@oasys.dt.navy.mil (Robert Lipman)\n",
            "Followup-To: comp.graphics\n",
            "Distribution: usa\n",
            "Organization: Carderock Division, NSWC, Bethesda, MD\n",
            "Lines: 65\n",
            "\n",
            "\n",
            "\t\t\tCALL FOR PRESENTATIONS\n",
            "\t\n",
            "      NAVY SCIENTIFIC VISUALIZATION AND VIRTUAL REALITY SEMINAR\n",
            "\n",
            "\t\t\tTuesday, June 22, 1993\n",
            "\n",
            "\t    Carderock Division, Naval Surface Warfare Center\n",
            "\t      (formerly the David Taylor Research Center)\n",
            "\t\t\t  Bethesda, Maryland\n",
            "\n",
            "SPONSOR: NESS (Navy Engineering Software System) is sponsoring a \n",
            "one-day Navy Scientific Visualization and Virtual Reality Seminar.  \n",
            "The purpose of the seminar is to present and exchange information for\n",
            "Navy-related scientific visualization and virtual reality programs, \n",
            "research, developments, and applications.\n",
            "\n",
            "PRESENTATIONS: Presentations are solicited on all aspects of \n",
            "Navy-related scientific visualization and virtual reality.  All \n",
            "current work, works-in-progress, and proposed work by Navy \n",
            "organizations will be considered.  Four types of presentations are \n",
            "available.\n",
            "\n",
            "     1. Regular presentation: 20-30 minutes in length\n",
            "     2. Short presentation: 10 minutes in length\n",
            "     3. Video presentation: a stand-alone videotape (author need not \n",
            "\tattend the seminar)\n",
            "     4. Scientific visualization or virtual reality demonstration (BYOH)\n",
            "\n",
            "Accepted presentations will not be published in any proceedings, \n",
            "however, viewgraphs and other materials will be reproduced for \n",
            "seminar attendees.\n",
            "\n",
            "ABSTRACTS: Authors should submit a one page abstract and/or videotape to:\n",
            "\n",
            "     Robert Lipman\n",
            "     Naval Surface Warfare Center, Carderock Division\n",
            "     Code 2042\n",
            "     Bethesda, Maryland  20084-5000\n",
            "\n",
            "     VOICE (301) 227-3618;  FAX (301) 227-5753  \n",
            "     E-MAIL  lipman@oasys.dt.navy.mil\n",
            "\n",
            "Authors should include the type of presentation, their affiliations, \n",
            "addresses, telephone and FAX numbers, and addresses.  Multi-author \n",
            "papers should designate one point of contact.\n",
            "\n",
            "DEADLINES: The abstact submission deadline is April 30, 1993.  \n",
            "Notification of acceptance will be sent by May 14, 1993.  \n",
            "Materials for reproduction must be received by June 1, 1993.\n",
            "\n",
            "For further information, contact Robert Lipman at the above address.\n",
            "\n",
            "\t  PLEASE DISTRIBUTE AS WIDELY AS POSSIBLE, THANKS.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Robert Lipman                     | Internet: lipman@oasys.dt.navy.mil\n",
            "David Taylor Model Basin - CDNSWC |       or: lip@ocean.dt.navy.mil\n",
            "Computational Signatures and      | Voicenet: (301) 227-3618\n",
            "   Structures Group, Code 2042    | Factsnet: (301) 227-5753\n",
            "Bethesda, Maryland  20084-5000    | Phishnet: stockings@long.legs\n",
            "\t\t\t\t   \n",
            "The sixth sick shiek's sixth sheep's sick.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Ejemplo de un texto de la categoría \"com.graphics\"\n",
        "print(open(data_dir / \"comp.graphics\" / \"37261\").read())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "UnEEvH8OGKeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 1"
      ],
      "metadata": {
        "id": "-Biz_-ALv9H0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 - Utilizando el tokenizador de spacy, que ya conoces, calcula el número promedio de tokens de una muestra de 15 ficheros de la categoría «com.graphics». Indica el código utilizado y el resultado obtenido."
      ],
      "metadata": {
        "id": "KWKrd-5yi6IV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la biblioteca spaCy para el procesamiento del lenguaje natural\n",
        "import spacy\n",
        "import en_core_web_sm  # Cargamos el modelo de spaCy para el idioma inglés\n",
        "\n",
        "# Cargamos el modelo de procesamiento de texto en inglés \"en_core_web_sm\"\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "# Inicializamos una variable para contar el número total de tokens\n",
        "total_tokens = 0\n",
        "\n",
        "# Aseguramos que tomamos los primeros 15 archivos\n",
        "num_files = 15\n",
        "fnames_subset = fnames[:num_files]  # Tomamos los primeros 15 archivos de la lista\n",
        "\n",
        "# Iteramos sobre los primeros 15 archivos de la categoría \"comp.graphics\"\n",
        "for fname in fnames_subset:\n",
        "    # Leemos el contenido del archivo y lo procesamos con spaCy\n",
        "    doc = nlp(pathlib.Path(data_dir / \"comp.graphics\" / fname).read_text(encoding=\"latin-1\"))\n",
        "\n",
        "    # Obtenemos la longitud del documento en tokens y la sumamos al total\n",
        "    total_tokens += len(doc)\n",
        "\n",
        "# Calculamos el número promedio de tokens en los 15 archivos analizados\n",
        "average_tokens = total_tokens / num_files\n",
        "\n",
        "# Imprimimos el resultado\n",
        "print(f\"Promedio de tokens en los primeros 15 documentos de 'comp.graphics': {average_tokens:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH9bbarIv9mD",
        "outputId": "019f3d27-1e4b-49dc-b4d1-7a38bb738064"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio de tokens en los primeros 15 documentos de 'comp.graphics': 281.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código calcula el número promedio de *tokens* en 15 archivos de la categoría *comp.graphics* utilizando *spaCy* para la tokenización. Para ello, primero se inicializa la variable `total_tokens` en cero, que servirá para almacenar la cantidad total de *tokens* en todos los archivos procesados.\n",
        "\n",
        "Se define la variable `num_files` con el valor 15 para indicar cuántos archivos se van a analizar. Luego, se obtiene una lista con los nombres de los primeros 15 archivos dentro de la carpeta *comp.graphics* utilizando `fnames[:num_files]`, lo que garantiza que solo se procesen los archivos necesarios.\n",
        "\n",
        "A continuación, se inicia un bucle que recorre cada uno de estos archivos. Para cada archivo, se construye su ruta completa utilizando `pathlib.Path(data_dir / \"comp.graphics\" / fname)`, asegurando así que se accede correctamente a su contenido. La función `read_text(encoding=\"latin-1\")` se encarga de leer el contenido del archivo como texto, utilizando la codificación *latin-1* para manejar caracteres especiales sin errores. Una vez obtenido el texto del archivo, se pasa a la función `nlp()` de *spaCy*, que tokeniza el texto y devuelve un objeto `doc` que contiene los *tokens* generados.\n",
        "\n",
        "La cantidad de *tokens* en el documento se obtiene con `len(doc)`, que devuelve el número total de *tokens* en el texto procesado. Este valor se suma a la variable `total_tokens`, acumulando así el número total de *tokens* de todos los archivos analizados.\n",
        "\n",
        "Después de recorrer los 15 archivos y sumar la cantidad total de *tokens*, se calcula el promedio dividiendo `total_tokens` entre `num_files`. Finalmente, el resultado se imprime en pantalla con un mensaje claro, utilizando una *f-string* para formatear la salida y asegurando que el promedio de *tokens* se muestre con solo dos decimales mediante `{average_tokens:.2f}`.\n",
        "\n",
        "El resultado obtenido indica que, en promedio, cada uno de los primeros 15 documentos de la categoría *comp.graphics* contiene aproximadamente **276.13 tokens**. Esto refleja el tamaño medio de los textos en esta categoría después del proceso de tokenización con *spaCy*."
      ],
      "metadata": {
        "id": "_mCfgqx4v98N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-DbsMOnKF-iK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vUbbjI8plaG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900f5f72-55cd-489f-9634-d630850f7a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in talk.politics.misc: 1000\n",
            "Some example filenames: ['178867', '178722', '178818', '178816', '176929']\n"
          ]
        }
      ],
      "source": [
        "# Listamos los archivos dentro de la categoría \"talk.politics.misc\", otra de las categorías del dataset \"20 Newsgroups\"\n",
        "\n",
        "fnames = os.listdir(data_dir / \"talk.politics.misc\")  # Obtenemos la lista de archivos en la carpeta \"talk.politics.misc\"\n",
        "\n",
        "# Imprimimos el número total de archivos en esta categoría\n",
        "print(\"Number of files in talk.politics.misc:\", len(fnames))\n",
        "\n",
        "# Mostramos los nombres de los primeros 5 archivos como ejemplo\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "izZGWhpklCbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b4b3f2-edcb-41ab-d64b-7b827aac1356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xref: cantaloupe.srv.cs.cmu.edu talk.politics.guns:54219 talk.politics.misc:178463\n",
            "Newsgroups: talk.politics.guns,talk.politics.misc\n",
            "Path: cantaloupe.srv.cs.cmu.edu!magnesium.club.cc.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!magnus.acs.ohio-state.edu!usenet.ins.cwru.edu!agate!spool.mu.edu!darwin.sura.net!martha.utcc.utk.edu!FRANKENSTEIN.CE.UTK.EDU!VEAL\n",
            "From: VEAL@utkvm1.utk.edu (David Veal)\n",
            "Subject: Re: Proof of the Viability of Gun Control\n",
            "Message-ID: <VEAL.749.735192116@utkvm1.utk.edu>\n",
            "Lines: 21\n",
            "Sender: usenet@martha.utcc.utk.edu (USENET News System)\n",
            "Organization: University of Tennessee Division of Continuing Education\n",
            "References: <1qpbqd$ntl@access.digex.net> <C5otvp.ItL@magpie.linknet.com>\n",
            "Date: Mon, 19 Apr 1993 04:01:56 GMT\n",
            "\n",
            "[alt.drugs and alt.conspiracy removed from newsgroups line.]\n",
            "\n",
            "In article <C5otvp.ItL@magpie.linknet.com> neal@magpie.linknet.com (Neal) writes:\n",
            "\n",
            ">   Once the National Guard has been called into federal service,\n",
            ">it is under the command of the present. Tha National Guard, though\n",
            ">defined as the \"Militia\" in the statutes, is actually a reserve component\n",
            ">of the United State Army, and was formed pursuant to the power of Congress\n",
            ">to raise and support Armies.\n",
            "\n",
            "       That's the really cute thing about saying the 2nd amendment\n",
            "only covers the national guard, because that would mean that it\n",
            "essentially prohibits the federal government from disarming a branch\n",
            "of the federal government.\n",
            "\n",
            "       Sounds like a real limit to federal power to me.\n",
            "------------------------------------------------------------------------\n",
            "David Veal Univ. of Tenn. Div. of Cont. Education Info. Services Group\n",
            "PA146008@utkvm1.utk.edu - \"I still remember the way you laughed, the day\n",
            "your pushed me down the elevator shaft;  I'm beginning to think you don't\n",
            "love me anymore.\" - \"Weird Al\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Ejemplo de un texto de la categoría \"talk.politics.misc\"\n",
        "print(open(data_dir / \"talk.politics.misc\" / \"178463\").read())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos una lista con las categorías de noticias que queremos seleccionar\n",
        "list_all_dir = [\n",
        "    'alt.atheism',                # Debate sobre ateísmo\n",
        "    'comp.graphics',              # Gráficos por computadora\n",
        "    'comp.sys.mac.hardware',      # Hardware de sistemas Mac\n",
        "    'comp.windows.x',             # Sistema de ventanas X en Unix\n",
        "    'misc.forsale',               # Anuncios de venta\n",
        "    'rec.autos',                  # Automóviles y temas relacionados\n",
        "    'rec.sport.baseball',         # Discusión sobre béisbol\n",
        "    'rec.sport.hockey',           # Discusión sobre hockey\n",
        "    'sci.crypt',                  # Criptografía y seguridad\n",
        "    'sci.med',                    # Medicina y ciencias de la salud\n",
        "    'sci.space',                  # Astronomía y exploración espacial\n",
        "    'soc.religion.christian',     # Cristianismo y temas religiosos\n",
        "    'talk.politics.guns',         # Debate sobre armas de fuego\n",
        "    'talk.politics.misc',         # Discusión general sobre política\n",
        "    'talk.religion.misc'          # Debate sobre religión en general\n",
        "]"
      ],
      "metadata": {
        "id": "SEkE3XAr2nBy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "33Ay5U6blCd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3069afd-aa7b-4a91-e97e-070b11ecb235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing alt.atheism, 1000 files found\n",
            "Processing comp.graphics, 1000 files found\n",
            "Processing comp.sys.mac.hardware, 1000 files found\n",
            "Processing comp.windows.x, 1000 files found\n",
            "Processing misc.forsale, 1000 files found\n",
            "Processing rec.autos, 1000 files found\n",
            "Processing rec.sport.baseball, 1000 files found\n",
            "Processing rec.sport.hockey, 1000 files found\n",
            "Processing sci.crypt, 1000 files found\n",
            "Processing sci.med, 1000 files found\n",
            "Processing sci.space, 1000 files found\n",
            "Processing soc.religion.christian, 997 files found\n",
            "Processing talk.politics.guns, 1000 files found\n",
            "Processing talk.politics.misc, 1000 files found\n",
            "Processing talk.religion.misc, 1000 files found\n",
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 14997\n"
          ]
        }
      ],
      "source": [
        "# Inicializamos listas para almacenar las muestras de texto, etiquetas y nombres de clases\n",
        "samples = []       # Lista para almacenar el contenido de los documentos\n",
        "labels = []        # Lista para almacenar las etiquetas correspondientes a cada documento\n",
        "class_names = []   # Lista para almacenar los nombres de las categorías\n",
        "class_index = 0    # Índice para asignar una etiqueta numérica a cada categoría\n",
        "\n",
        "# Iteramos sobre cada categoría seleccionada en 'list_all_dir'\n",
        "for dirname in list_all_dir:\n",
        "    class_names.append(dirname)  # Agregamos el nombre de la categoría a la lista de clases\n",
        "    dirpath = data_dir / dirname  # Construimos la ruta de la carpeta correspondiente a la categoría\n",
        "    fnames = os.listdir(dirpath)  # Obtenemos la lista de archivos en la categoría\n",
        "\n",
        "    # Imprimimos información sobre la categoría procesada\n",
        "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
        "\n",
        "    # Iteramos sobre cada archivo dentro de la categoría\n",
        "    for fname in fnames:\n",
        "        fpath = dirpath / fname  # Construimos la ruta completa del archivo\n",
        "        f = open(fpath, encoding=\"latin-1\")  # Abrimos el archivo con codificación \"latin-1\"\n",
        "        content = f.read()  # Leemos el contenido del archivo\n",
        "\n",
        "        # Eliminamos las primeras 10 líneas del contenido\n",
        "        lines = content.split(\"\\n\")  # Dividimos el texto en líneas\n",
        "        lines = lines[10:]  # Eliminamos las primeras 10 líneas\n",
        "        content = \"\\n\".join(lines)  # Volvemos a unir las líneas en un solo texto\n",
        "\n",
        "        samples.append(content)  # Agregamos el texto procesado a la lista de muestras\n",
        "        labels.append(class_index)  # Asignamos la etiqueta numérica correspondiente a la categoría\n",
        "\n",
        "    class_index += 1  # Incrementamos el índice de clase para la siguiente categoría\n",
        "\n",
        "# Imprimimos la lista de clases y el número total de documentos procesados\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "gUA8K2bYGWFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 2\n",
        "\n",
        "El código proporcionado lee los ficheros uno a uno y, antes de generar el catálogo de datos de entrenamiento y validación, descarta las diez primeras líneas de cada fichero."
      ],
      "metadata": {
        "id": "Vu9N04yRyUp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 - ¿Cuál es el trozo de código en el que se realiza dicho descarte?"
      ],
      "metadata": {
        "id": "zZRt1AGByc3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el código anterior, dentro del bucle `for`, hay una sección que se encarga de eliminar las diez primeras líneas de cada archivo antes de almacenarlo en la lista de muestras. Este procesamiento se realiza en el siguiente fragmento:\n",
        "\n",
        "```python\n",
        "# Eliminamos las primeras 10 líneas del contenido (posiblemente metadatos o cabecera)\n",
        "lines = content.split(\"\\n\")  # Dividimos el texto en líneas\n",
        "lines = lines[10:]  # Eliminamos las primeras 10 líneas\n",
        "content = \"\\n\".join(lines)  # Volvemos a unir las líneas en un solo texto\n",
        "```\n",
        "\n",
        "Este fragmento de código realiza un preprocesamiento del contenido de cada archivo. Primero, la función `content.split(\"\\n\")` divide el texto en una lista de líneas, separando cada fragmento de texto según los saltos de línea. Luego, la instrucción `lines = lines[10:]` descarta las primeras diez líneas de la lista, eliminando información que suele corresponder a metadatos, encabezados de correos electrónicos o referencias internas dentro del conjunto de datos. Finalmente, `content = \"\\n\".join(lines)` reconstruye el texto uniendo nuevamente las líneas restantes, asegurando que la estructura del contenido se mantenga, pero sin los elementos iniciales considerados innecesarios para el análisis."
      ],
      "metadata": {
        "id": "EzCZ4Zd3yerg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 - ¿Por qué crees que se descartan dichas líneas?"
      ],
      "metadata": {
        "id": "F6JVnHsAyfpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las primeras diez líneas se descartan porque contienen principalmente metadatos, como referencias a otros mensajes, rutas de servidores, remitentes, organizaciones y encabezados de correo electrónico. Estos elementos no forman parte del contenido principal del mensaje y podrían introducir ruido o sesgos en el modelo de clasificación. Al eliminarlas, se mantiene solo el cuerpo del texto, asegurando que la clasificación se base en la información relevante de cada documento."
      ],
      "metadata": {
        "id": "sPvjdM-NyffS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 - ¿Por qué diez y no otro número?"
      ],
      "metadata": {
        "id": "hqbe04AdyfHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se eliminan exactamente diez líneas porque, al analizar previamente el contenido de los archivos con el siguiente código:\n",
        "\n",
        "```python\n",
        "# Ejemplo de un texto de la categoría \"talk.politics.misc\"\n",
        "print(open(data_dir / \"talk.politics.misc\" / \"178463\").read())\n",
        "```\n",
        "\n",
        "Se observa que las primeras diez líneas contienen información estructural que no es relevante para la clasificación del texto. En este ejemplo, se incluyen encabezados como `Xref`, `Newsgroups`, `Path`, `From`, `Subject`, `Message-ID`, `Lines`, `Sender`, `Organization`, `References` y `Date`. Estos campos corresponden a metadatos del sistema de *newsgroups* que identifican la procedencia del mensaje, el remitente y referencias a otros mensajes, pero no aportan información significativa para la tarea de clasificación.\n",
        "\n",
        "El número diez no es arbitrario, sino que se basa en la estructura observada en estos archivos. Al eliminar exactamente estas diez líneas, se garantiza que el modelo trabaje únicamente con el contenido real del mensaje sin interferencias de información técnica o administrativa. Esto permite que el texto procesado represente mejor la categoría a la que pertenece sin incluir datos que podrían introducir ruido o sesgos en la clasificación."
      ],
      "metadata": {
        "id": "5qYi6LCK1UTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "a8UX0XPbGdDU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2pmvE6gMcxT"
      },
      "source": [
        "# Mezclando los datos para separarlos en Traning y Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DYX7x-k_lCgZ"
      },
      "outputs": [],
      "source": [
        "# Barajamos los datos de manera reproducible utilizando una semilla fija\n",
        "seed = 1337  # Semilla para garantizar reproducibilidad\n",
        "\n",
        "# Creamos un generador de números aleatorios con la semilla especificada\n",
        "rng = np.random.RandomState(seed)\n",
        "\n",
        "# Barajamos aleatoriamente la lista de muestras (documentos)\n",
        "rng.shuffle(samples)\n",
        "\n",
        "# Volvemos a inicializar el generador de números aleatorios para que la permutación de las etiquetas coincida\n",
        "rng = np.random.RandomState(seed)\n",
        "\n",
        "# Barajamos aleatoriamente las etiquetas para mantener la correspondencia con las muestras\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Fijamos la semilla aleatoria en Keras para asegurar la reproducibilidad en el entrenamiento\n",
        "keras.utils.set_random_seed(seed)\n",
        "\n",
        "# Definimos el porcentaje de datos que se usará para validación\n",
        "validation_split = 0.2  # 20% de los datos serán utilizados para validación\n",
        "\n",
        "# Calculamos la cantidad de muestras destinadas a validación\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "\n",
        "# Dividimos los datos en conjunto de entrenamiento y validación\n",
        "train_samples = samples[:-num_validation_samples]  # 80% para entrenamiento\n",
        "val_samples = samples[-num_validation_samples:]  # 20% para validación\n",
        "\n",
        "# Dividimos las etiquetas en conjunto de entrenamiento y validación\n",
        "train_labels = labels[:-num_validation_samples]  # 80% para entrenamiento\n",
        "val_labels = labels[-num_validation_samples:]  # 20% para validación"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "fefmtVlZGgd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 3"
      ],
      "metadata": {
        "id": "BApAUgkT1wJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 - ¿Qué se controla con el parámetro `validation_split`?"
      ],
      "metadata": {
        "id": "TjdP9U_sHY96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el código anterior, el parámetro `validation_split` define el porcentaje de datos que se utilizarán para la validación del modelo. En este caso, se ha establecido en `0.2`, lo que significa que el 20% de las muestras se reserva para validación y el 80% restante se utiliza para el entrenamiento.\n",
        "\n",
        "```python\n",
        "# Definimos el porcentaje de datos que se usará para validación\n",
        "validation_split = 0.2  # 20% de los datos serán utilizados para validación\n",
        "```"
      ],
      "metadata": {
        "id": "CUNEeGcA1Jet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 - ¿Por qué se ha elegido ese valor?"
      ],
      "metadata": {
        "id": "FDGf8COA05mL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este valor ha sido elegido para disponer de un conjunto de validación suficientemente representativo sin reducir en exceso la cantidad de datos destinados al entrenamiento, lo que permite evaluar el rendimiento del modelo de manera equilibrada."
      ],
      "metadata": {
        "id": "75kpo0Yn1RoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 - ¿Qué ocurre si lo modificas?"
      ],
      "metadata": {
        "id": "sHJDsIs406MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si se modifica este valor, el tamaño relativo de los conjuntos de entrenamiento y validación cambiará. Un valor más alto reduciría el número de muestras de entrenamiento, lo que podría afectar la capacidad del modelo para generalizar. Por el contrario, un valor más bajo dejaría menos datos para validación, lo que podría dificultar la evaluación del rendimiento del modelo y aumentar el riesgo de sobreajuste si la validación no es suficientemente representativa."
      ],
      "metadata": {
        "id": "qi-79TiT11Uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 4"
      ],
      "metadata": {
        "id": "Ubf68zVGSMMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 - Imprime por pantalla un ejemplo (es decir, un elemento del array) de `train_samples`, `val_samples`, `train_labels` y `val_labels`. A tenor de las etiquetas que se utilizan."
      ],
      "metadata": {
        "id": "6HUn7_EpHfoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random # Importamos la librería random para generar números aleatorios\n",
        "\n",
        "# Establecemos una semilla fija para obtener siempre el mismo número aleatorio\n",
        "random.seed(13)\n",
        "\n",
        "# Generamos un índice aleatorio reproducible para los datos de entrenamiento\n",
        "random_index_train = random.randint(0, len(train_samples) - 1)\n",
        "\n",
        "# Generamos un índice aleatorio reproducible para los datos de validación\n",
        "random_index_samples = random.randint(0, len(val_samples) - 1)\n",
        "\n",
        "# Imprimimos un ejemplo aleatorio fijo del conjunto de entrenamiento y su etiqueta correspondiente\n",
        "print(\"Ejemplo aleatorio fijo de train_samples:\")\n",
        "print(train_samples[random_index_train])\n",
        "print(\"Etiqueta correspondiente en train_labels:\", train_labels[random_index_train])\n",
        "\n",
        "# Imprimimos un ejemplo de los datos de validación y su etiqueta correspondiente\n",
        "print(\"\\nEjemplo de val_samples:\")\n",
        "print(val_samples[random_index_samples])\n",
        "print(\"Etiqueta correspondiente en val_labels:\", val_labels[random_index_samples])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqJIHQoVScr_",
        "outputId": "398b38bd-6568-4469-a135-c08ff2a8a521"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo aleatorio fijo de train_samples:\n",
            "Lines: 37\n",
            "Nntp-Posting-Host: vm.temple.edu\n",
            "X-Newsreader: NNR/VM S_1.3.2\n",
            "\n",
            "In article <GERRY.93Apr21132149@onion.cmu.edu>\n",
            "gerry@cmu.edu (Gerry Roston) writes:\n",
            " \n",
            ">Sigh, I was waiting some some not-so-intelligent person to bring this\n",
            ">up.  Look, this is a country of laws. To quote a piece of parchment\n",
            ">that many seem to think is of little importance:\n",
            ">\n",
            "> 4th Amendment\n",
            "> The right of the people to be secure in their persons, houses,\n",
            "> papers, and effects, against unreasonable searches and seizures,\n",
            "> shall not be violated; and no warrants shall issue, but upon\n",
            "> probable cause, supported by oath or affirmation, and\n",
            "> particularly describing the place to be searched and the persons\n",
            "> or things to be seized.\n",
            ">\n",
            ">No, a no-knock warrant is in clear violation of the 4th amendment.\n",
            ">Okay, what about the fact that they were tipped off - they shouldn't\n",
            ">have opened fire - right?  WRONG!  Think about this: I am a drug\n",
            ">dealer and my competition wants to do away with me. They call me and\n",
            ">tell me that the Feds are on their way with a no-knock warrant. So,\n",
            ">being moronic sheep we wait, with our guns holstered. Now, instead of\n",
            ">the Feds, in comes my competition, and we're history.  The only\n",
            ">acceptable answer to a no-knock warrant is blazing guns!  I may sound\n",
            ">paranoid, but our government is out of control, and killing a few\n",
            ">federal officers make knock some sense back into it.\n",
            ">\n",
            "I assume you are saying that no-knock warrants are 'unreasonable', this\n",
            "is a matter of opinion and is not a CLEAR violation of the 4th\n",
            "admendment. You say that 'this is a country of laws' yet you seem very\n",
            "willing to ignore these laws, or at least those you disagree with,\n",
            "and respond to a legal situation with 'blazing guns'. Like it or not,\n",
            "as it stands now no-knock warrants are legal. If you don't like this\n",
            "there are legal means to fight this including contacting your\n",
            "congresspersons about changing the law; and, if it happens to you,\n",
            "fighting its legality in court.\n",
            " \n",
            "Richard\n",
            "\n",
            "Etiqueta correspondiente en train_labels: 13\n",
            "\n",
            "Ejemplo de val_samples:\n",
            "\n",
            "I recently saw a message here (posted by Bob Silverman, I think) which \n",
            "referred to a \"birthday\" attack on a cryptosystem. I'm looking for \n",
            "references on, and explanations of, this type of attack.\n",
            "\n",
            "Thanks,\n",
            "-Paul\n",
            "\n",
            "Etiqueta correspondiente en val_labels: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código selecciona e imprime un ejemplo aleatorio tanto del conjunto de entrenamiento como del conjunto de validación, asegurando que la selección sea reproducible.\n",
        "\n",
        "Para lograrlo, primero se importa la librería `random`, que permite generar números aleatorios. Luego, se fija una semilla con `random.seed(13)`, lo que garantiza que cada vez que se ejecute el código, se generarán los mismos valores aleatorios.\n",
        "\n",
        "A continuación, se generan dos índices aleatorios dentro del rango válido de cada conjunto de datos. `random.randint(0, len(train_samples) - 1)` selecciona un índice aleatorio dentro del conjunto de entrenamiento, mientras que `random.randint(0, len(val_samples) - 1)` hace lo mismo para el conjunto de validación.\n",
        "\n",
        "Finalmente, se imprimen los ejemplos seleccionados junto con sus etiquetas correspondientes. `train_samples[random_index_train]` muestra un documento aleatorio del conjunto de entrenamiento, mientras que `val_samples[random_index_samples]` muestra un documento aleatorio del conjunto de validación. En ambos casos, también se imprime la etiqueta correspondiente para identificar la categoría a la que pertenece el texto seleccionado."
      ],
      "metadata": {
        "id": "7kFpDWfZUip_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 - ¿Qué tarea crees que se está intentando entrenar?"
      ],
      "metadata": {
        "id": "unHEWFXxSL2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código está preparando los datos para entrenar un **modelo de clasificación de texto**. Se está estructurando un conjunto de datos en el que cada muestra es un documento de texto y cada documento tiene una etiqueta numérica correspondiente a una categoría específica dentro del conjunto de datos *20 Newsgroups*.\n",
        "\n",
        "Dado que los datos provienen de diferentes categorías de *newsgroups*, la tarea de aprendizaje automático que se intenta entrenar es un **modelo de clasificación de textos en múltiples categorías** (*multi-class text classification*). El objetivo del modelo será aprender a asociar nuevos textos con la categoría correcta basándose en su contenido."
      ],
      "metadata": {
        "id": "RZgqc27gUs02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "fzqB55ZnGnqd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VnL1d6Ew2kFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c626f5-9e2e-4aed-a442-228bc8499f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Documento 1 ---\n",
            "\n",
            "Alan Carter writes:\n",
            "\n",
            ">> 3.  On April 19, a NO-OP command was sent to reset the command loss timer to\n",
            ">> 264 hours, its planned value during this mission phase.\n",
            "\n",
            "> This activity is regularly reported in Ron's interesting posts. Could\n",
            "> someone explain what the Command Loss Timer is?\n",
            "\n",
            "The name is rather descriptive.  It's a command to the spacecraft that tells\n",
            "it \"If you don't hear from Earth after 264 hours, assume something is wrong\n",
            "with your (the spacecraft) attitude, and go into a preprogrammed search mode\n",
            "in an attempt to reacquire the signal from Earth.\"\n",
            "\n",
            "The spacecraft and Earth are not in constant communication with each other.\n",
            "Earth monitors the telemetry from the spacecraft, and if everything is fine,\n",
            "there's no reason to send it any new information.  But from the spacecraft's\n",
            "point of view, no information from Earth could mean either everything is\n",
            "fine, or that the spacecraft has lost signal acquisition.  Just how long\n",
            "should the spacecraft wait before it decides that something is wrong and\n",
            "begins to take corrective action?  That \"how long\" is the command loss timer.\n",
            "During relatively inactive cruise phases, the command loss timer can be set\n",
            "to rather long values.  In this case, Earth is telling Galileo \"expect to\n",
            "hear back from us sometime within the next 264 hours\".\n",
            "\n",
            "\n",
            "--- Documento 2 ---\n",
            "\n",
            "In article <C60A0s.DvI@mailer.cc.fsu.edu> dekorte@dirac.scri.fsu.edu (Stephen L. DeKorte) writes:\n",
            ">\n",
            ">I saw a 3 hour show on PBS the other day about the history of the\n",
            ">Jews. Appearently, the Cursades(a religious war agianst the muslilams\n",
            ">in 'the holy land') sparked the widespread persecution of muslilams \n",
            ">and jews in europe. Among the supporters of the persiecution, were none \n",
            ">other than Martin Luther, and the Vatican.\n",
            ">\n",
            ">Later, Hitler would use Luthers writings to justify his own treatment\n",
            ">of the jews.\n",
            ">> Genocide is Caused by Theism : Evidence?\n",
            "\n",
            "Heck, I remember reading a quote of Luther as something like: \"Jews should\n",
            "be shot like deer.\"  And of course much Catholic doctrine for centuries was \n",
            "extremely anti-Semitic.\n",
            "\n",
            "\n",
            "\n",
            "-- \n",
            "\"Are you so sure that your truth and your justice are worth more than the\n",
            "truths and justices of other centuries?\" - Simone de Beauvoir\n",
            "\"Where is there a certainty that rises above all doubt and withstands all\n",
            "critique?\" - Karl Jaspers          Rice University, Will Rice College '96\n",
            "\n",
            "\n",
            "--- Documento 3 ---\n",
            "References: <1qgi8eINNhs5@skeena.ucs.ubc.ca> <pod.734834505@sour.sw.oz.au> <93111.12475032HNBAK@CMUVM.CSV.CMICH.EDU>\n",
            "Date: Wed, 21 Apr 1993 18:58:03 GMT\n",
            "\n",
            "In article <93111.12475032HNBAK@CMUVM.CSV.CMICH.EDU> John Foster <32HNBAK@CMUVM.CSV.CMICH.EDU> writes:\n",
            ">Date: Wednesday, 21 Apr 1993 12:47:50 EDT\n",
            ">From: John Foster <32HNBAK@CMUVM.CSV.CMICH.EDU>\n",
            ">Subject: Re: Changing oil by self.\n",
            ">>From: drew@kinglear.cs.colorado.edu (Drew Eckhardt)\n",
            ">>In article <pod.734834505@sour.sw.oz.au> pod@sour.sw.oz.au (Paul O'Donnell) wri\n",
            ">>>In <1qgi8eINNhs5@skeena.ucs.ubc.ca> yiklam@unixg.ubc.ca (Yik Chong Lam) writes\n",
            ">>>\n",
            ">>>>Hello,\n",
            ">\n",
            ">I find this method much better myself, too, although I do really\n",
            ">hate it when the bolt finally comes loose and the wrench and my\n",
            ">hand both come crashing into my face.  After coming to, which is\n",
            ">about 15 minutes later, I change my clothes (because by this time\n",
            ">all the oil has drained *on* me), and ice my entire face and suck\n",
            ">down about 20 Tylenol to ease the pain.  Later in the day I then\n",
            ">proceed with refilling the engine oil.\n",
            ">\n",
            ">It's just crazy how I try and change the oil on my cars in one\n",
            ">weekend---I go through about 3 bottles of Tylenol and 2 bags of ice.\n",
            ">\n",
            ">John\n",
            "\n",
            "Not everyone should be trusted with tools. ;-)\n",
            "\n",
            "\n",
            "--------------------------------------------------------\n",
            "Ron Stafford              TEXAS INSTRUMENTS INCORPORATED\n",
            "(214) 917-2050            P.O.Box 655012, MS 3620\n",
            "STAFFORD@LOBBY.TI.COM     Dallas, Texas 75265-3620\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Iteramos sobre las tres primeras muestras del conjunto de entrenamiento\n",
        "for i, sample in enumerate(train_samples[:3], 1):\n",
        "    # Imprimimos cada muestra con un encabezado numerado para mayor claridad\n",
        "    print(f\"--- Documento {i} ---\\n{sample}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B_ifAVsF2kFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff9f402-6fb1-4a4f-9f14-a4240bd5514d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Documento de Validación 1 ===\n",
            "Lines: 14\n",
            "\n",
            "\n",
            "\tIs there anyone out there running a Chicago National\n",
            "\tLeague Ballclub list?  If so, please send me information\n",
            "\ton it to...\n",
            "\t\t\tandrew@aardvark.ucs.uoknor.edu\n",
            "\n",
            "\tThanks!\n",
            "\n",
            "|\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/|\n",
            "|O|  _    |  Chihuahua Charlie              |  OU is not responsible   |O|\n",
            "|O| | |   |  Academic User Services         |  for anything anywhere,  |O|\n",
            "|O| ||||  |  The University of Oklahoma     |  except for that one     |O|\n",
            "|O|  |_|  |  andre...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mostramos solo los primeros 500 caracteres del primer documento de validación\n",
        "for i, sample in enumerate(val_samples[:1], 1):\n",
        "    print(f\"=== Documento de Validación {i} ===\\n{sample[:500]}...\\n\")  # Mostramos un fragmento del texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "j-OBbT1x2kFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba7ed42-6eaa-4748-f63c-984734367d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10]\n"
          ]
        }
      ],
      "source": [
        "# Imprimimos la etiqueta de la primera muestra del conjunto de entrenamiento\n",
        "print(train_labels[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-_efxN9K2kFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458f2a0b-154d-407b-d7a9-875daea30c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6]\n"
          ]
        }
      ],
      "source": [
        "# Imprimimos la etiqueta de la primera muestra del conjunto de validación\n",
        "print(val_labels[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IktOtKfpNx8E"
      },
      "source": [
        "# Tokenización de las palabras con TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QjHgQPX8lCjO"
      },
      "outputs": [],
      "source": [
        "# Importamos la capa TextVectorization de Keras para procesar texto\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Creamos un vectorizador de texto con un vocabulario máximo de 20,000 palabras\n",
        "# y una longitud de salida fija de 200 tokens por muestra\n",
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "\n",
        "# Convertimos las muestras de entrenamiento en un objeto Dataset de TensorFlow,\n",
        "# dividiendo los datos en lotes de 128 muestras para mayor eficiencia\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "\n",
        "# Ajustamos el vectorizador con los datos de entrenamiento para aprender el vocabulario y la tokenización\n",
        "vectorizer.adapt(text_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "VdeMwyNkGtx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 5"
      ],
      "metadata": {
        "id": "is-_fu6gG1g4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 - Con `output_sequence_length` se establece un tamaño fijo para la salida de Vectorizer. ¿Por qué se necesita un tamaño fijo y por qué se ha elegido el valor 200?"
      ],
      "metadata": {
        "id": "DzPHwpYgHWNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En las redes neuronales, el tamaño de la entrada debe ser constante para que el modelo pueda procesar los datos de manera uniforme. Por esta razón, `output_sequence_length` se establece con un valor fijo, en este caso 200, asegurando que todas las secuencias tengan la misma longitud antes de ser introducidas en la red neuronal.\n",
        "\n",
        "El valor 200 ha sido elegido porque la arquitectura del modelo ha sido diseñada para trabajar con entradas de esta dimensión, lo que significa que la capa de entrada de la red neuronal está configurada para recibir vectores de tamaño 200. Si un documento tiene menos de 200 tokens, se aplicará *padding* para completar la secuencia hasta la longitud deseada, mientras que si excede este límite, se truncará. De esta manera, se garantiza que todos los ejemplos tengan una representación uniforme, lo que facilita el procesamiento y la eficiencia del modelo durante el entrenamiento y la inferencia."
      ],
      "metadata": {
        "id": "c9d6nVecVvEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CkKGyb99kBYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vIWC37s5smZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac957cdf-38df-436c-9194-c2a144fead57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to', 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Obtiene el vocabulario aprendido por el vectorizador y muestra las primeras 5 palabras\n",
        "vectorizer.get_vocabulary()[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vit8TPqTvmwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f680cd0-d41b-42c0-be38-4a2f58491f6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Obtiene el tamaño total del vocabulario aprendido por el vectorizador\n",
        "len(vectorizer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O-FXA9wPVkg"
      },
      "source": [
        "# Viendo la salida de Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rseIF0fLmyJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e9033a-e252-4b96-ea78-678d41916d00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 3867, 1891,   18,    2, 4793])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Aplica el vectorizador a una muestra de texto y convierte la salida en un array de NumPy\n",
        "output = vectorizer([[\"the cat sat on the mat\"]])\n",
        "\n",
        "# Convierte la salida a un array NumPy y muestra los primeros 6 elementos de la secuencia vectorizada\n",
        "output.numpy()[0, :6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Wsr4AQtBFArV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833f00b0-db76-41bb-8be5-ee073e29d48c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 200), dtype=int64, numpy=\n",
              "array([[   2, 3867, 1891,   18,    2, 4793,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Imprime la salida completa de la vectorización aplicada al texto de entrada\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SL5ag8UamzwL"
      },
      "outputs": [],
      "source": [
        "# Obtiene el vocabulario aprendido por el vectorizador\n",
        "voc = vectorizer.get_vocabulary()\n",
        "\n",
        "# Crea un diccionario que asigna a cada palabra un índice numérico en función de su posición en el vocabulario\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "08v8SKcsn3lf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666584a2-e96d-4d3c-ba97-0741f24a85b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3867, 1891, 18, 2, 4793]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Lista de palabras de prueba\n",
        "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "\n",
        "# Convierte cada palabra de la lista en su índice correspondiente dentro del vocabulario aprendido por el vectorizador\n",
        "[word_index[w] for w in test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eBhadrvOTNZ"
      },
      "source": [
        "# Tokenización de los datos de entrenamiento y validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "W26LUr2dKTOj"
      },
      "outputs": [],
      "source": [
        "# Convierte los datos de entrenamiento en un formato adecuado para la red neuronal\n",
        "# Se aplica el vectorizador a cada muestra de entrenamiento y se convierte la salida en un array NumPy\n",
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "\n",
        "# Convierte los datos de validación utilizando el mismo vectorizador y transforma la salida en un array NumPy\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "# Convierte las etiquetas de entrenamiento en un array NumPy para su uso en el modelo\n",
        "y_train = np.array(train_labels)\n",
        "\n",
        "# Convierte las etiquetas de validación en un array NumPy\n",
        "y_val = np.array(val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3QVIb84Olda"
      },
      "source": [
        "# Creación y entrenamiento de los modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se llevará a cabo la **creación y entrenamiento de los modelos** para la clasificación de texto. Se implementarán distintas arquitecturas, incluyendo una **red neuronal clásica** y un modelo basado en **Transformers**, cada uno con su propio enfoque para procesar y aprender patrones en los datos. Una vez definidos, los modelos serán entrenados con el conjunto de datos preprocesado, ajustando sus parámetros para optimizar su rendimiento en la tarea de clasificación."
      ],
      "metadata": {
        "id": "V8oR56WZoqoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red neuronal clásica"
      ],
      "metadata": {
        "id": "F3yR1VGrjECY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se realizará el entrenamiento de un modelo de **red neuronal clásica** para la clasificación de texto. Este modelo utilizará una capa de **embedding** para convertir las palabras en representaciones numéricas, seguida de capas densas completamente conectadas que permitirán aprender patrones en los datos. A través del entrenamiento, el modelo ajustará sus pesos para mejorar la precisión en la asignación de categorías a los textos procesados."
      ],
      "metadata": {
        "id": "JJktA9fTmjfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición de la arquitectura del modelo"
      ],
      "metadata": {
        "id": "nlTejME9dd-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo clásico de clasificación de texto\n",
        "modeloClasico = keras.models.Sequential()\n",
        "\n",
        "# Capa de embedding que convierte palabras en representaciones densas de 10 dimensiones\n",
        "modeloClasico.add(keras.layers.Embedding(20000, 10))\n",
        "\n",
        "# Aplanamos la salida del embedding para poder conectarla a capas densas\n",
        "modeloClasico.add(keras.layers.Flatten())\n",
        "\n",
        "# Capa densa con 512 neuronas y activación ReLU para capturar patrones en los datos\n",
        "modeloClasico.add(keras.layers.Dense(512, activation='relu'))\n",
        "\n",
        "# Capa de Dropout para reducir el sobreajuste, eliminando aleatoriamente el 30% de las conexiones\n",
        "modeloClasico.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "# Capa de salida con 20 neuronas y activación softmax para clasificación multiclase\n",
        "modeloClasico.add(keras.layers.Dense(20, activation='softmax'))"
      ],
      "metadata": {
        "id": "ZvWJq2Sfi4cp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define la arquitectura del modelo clásico de clasificación de texto. Se utiliza `Sequential()` para construir la red de manera ordenada.\n",
        "\n",
        "La primera capa es `Embedding`, que transforma las palabras en vectores de 10 dimensiones. Se establece un tamaño máximo de vocabulario de 20,000 palabras, asegurando que el modelo solo procese las palabras más comunes del dataset. Luego, se utiliza `Flatten()` para convertir la salida del embedding en una matriz unidimensional, facilitando su procesamiento por capas densas.\n",
        "\n",
        "La siguiente capa es una capa densa de 512 neuronas con activación `ReLU`, lo que introduce no linealidad en el modelo y permite capturar patrones complejos. Para prevenir el sobreajuste, se incluye una capa de `Dropout(0.3)`, que desactiva aleatoriamente el 30% de las conexiones durante el entrenamiento, mejorando la generalización del modelo.\n",
        "\n",
        "Finalmente, la capa de salida tiene 20 neuronas con activación `softmax`, lo que permite que el modelo realice una clasificación multiclase, asignando probabilidades a cada una de las 20 categorías del dataset."
      ],
      "metadata": {
        "id": "cRhD-NT8i5YD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compilación y entrenamiento del modelo"
      ],
      "metadata": {
        "id": "RQ3YYDVRdiXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo con el optimizador Adam y la pérdida binaria (incorrecto para multiclase)\n",
        "modeloClasico.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Se recompila el modelo con la pérdida correcta para clasificación multiclase\n",
        "modeloClasico.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
        "\n",
        "# Entrenamos el modelo con los datos de entrenamiento y validación\n",
        "modeloClasico.fit(\n",
        "    x_train, y_train,  # Datos de entrenamiento\n",
        "    batch_size=128,  # Tamaño de lote\n",
        "    epochs=20,  # Número de iteraciones sobre el conjunto de datos\n",
        "    validation_data=(x_val, y_val)  # Datos de validación\n",
        ")\n",
        "\n",
        "# Mostramos un resumen del modelo después del entrenamiento\n",
        "print(modeloClasico.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w2BC_wOMi49v",
        "outputId": "24aa71f0-8930-480c-d4d0-4a5cc4f0a0be"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - acc: 0.0944 - loss: 2.7866 - val_acc: 0.1987 - val_loss: 2.4224\n",
            "Epoch 2/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - acc: 0.2742 - loss: 2.2302 - val_acc: 0.3284 - val_loss: 1.9377\n",
            "Epoch 3/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - acc: 0.4745 - loss: 1.6077 - val_acc: 0.4842 - val_loss: 1.5254\n",
            "Epoch 4/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - acc: 0.6702 - loss: 1.0714 - val_acc: 0.5842 - val_loss: 1.2365\n",
            "Epoch 5/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - acc: 0.7884 - loss: 0.7160 - val_acc: 0.6225 - val_loss: 1.1159\n",
            "Epoch 6/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - acc: 0.8504 - loss: 0.4991 - val_acc: 0.6412 - val_loss: 1.0500\n",
            "Epoch 7/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - acc: 0.8970 - loss: 0.3481 - val_acc: 0.6672 - val_loss: 1.0124\n",
            "Epoch 8/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - acc: 0.9174 - loss: 0.2683 - val_acc: 0.6799 - val_loss: 1.0274\n",
            "Epoch 9/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - acc: 0.9311 - loss: 0.2177 - val_acc: 0.6819 - val_loss: 1.0469\n",
            "Epoch 10/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - acc: 0.9402 - loss: 0.1758 - val_acc: 0.6926 - val_loss: 1.0614\n",
            "Epoch 11/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - acc: 0.9464 - loss: 0.1502 - val_acc: 0.6952 - val_loss: 1.0890\n",
            "Epoch 12/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - acc: 0.9478 - loss: 0.1402 - val_acc: 0.6962 - val_loss: 1.0954\n",
            "Epoch 13/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - acc: 0.9520 - loss: 0.1266 - val_acc: 0.6992 - val_loss: 1.1168\n",
            "Epoch 14/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - acc: 0.9539 - loss: 0.1123 - val_acc: 0.6966 - val_loss: 1.1316\n",
            "Epoch 15/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - acc: 0.9528 - loss: 0.1090 - val_acc: 0.6969 - val_loss: 1.1570\n",
            "Epoch 16/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - acc: 0.9540 - loss: 0.1016 - val_acc: 0.6949 - val_loss: 1.1699\n",
            "Epoch 17/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - acc: 0.9548 - loss: 0.1006 - val_acc: 0.6929 - val_loss: 1.1910\n",
            "Epoch 18/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - acc: 0.9575 - loss: 0.0947 - val_acc: 0.7006 - val_loss: 1.2021\n",
            "Epoch 19/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - acc: 0.9564 - loss: 0.0902 - val_acc: 0.6906 - val_loss: 1.2226\n",
            "Epoch 20/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - acc: 0.9573 - loss: 0.0877 - val_acc: 0.6842 - val_loss: 1.2479\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m200,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,024,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │          \u001b[38;5;34m10,260\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">200,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,260</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,469,546\u001b[0m (9.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,469,546</span> (9.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,234,772\u001b[0m (4.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,234,772</span> (4.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,234,774\u001b[0m (4.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,234,774</span> (4.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta parte, el modelo se compila y entrena con los datos de entrenamiento y validación. Inicialmente, el modelo se compila con el optimizador `adam` y la función de pérdida `binary_crossentropy`, pero esta configuración no es adecuada para clasificación multiclase, ya que `binary_crossentropy` se usa para problemas binarios.\n",
        "\n",
        "Por esta razón, se recompila con `sparse_categorical_crossentropy`, que es la función de pérdida adecuada para clasificación de múltiples categorías cuando las etiquetas están representadas como enteros. Además, se cambia el optimizador a `rmsprop`, que ajusta los pesos de manera eficiente en problemas de clasificación con múltiples clases.\n",
        "\n",
        "El modelo se entrena durante 20 épocas con un tamaño de lote de 128 muestras, lo que controla cuántos ejemplos se procesan antes de actualizar los pesos. Se usa `validation_data=(x_val, y_val)`, lo que permite evaluar el rendimiento del modelo en datos no vistos durante el entrenamiento.\n",
        "\n",
        "Finalmente, `print(modeloClasico.summary())` muestra un resumen de la arquitectura del modelo, incluyendo el número de parámetros entrenables y la cantidad de capas utilizadas."
      ],
      "metadata": {
        "id": "MSJ31bn8j8s7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red neuronal de transormers"
      ],
      "metadata": {
        "id": "kmdw1b-tn9FP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se realizará el entrenamiento de un modelo basado en **Transformers** para la clasificación de texto. Este modelo utilizará una **capa de embedding con información posicional** para representar las palabras en un espacio vectorial, seguida de un **bloque Transformer** que empleará mecanismos de atención para capturar relaciones entre las palabras. A través del entrenamiento, el modelo optimizará sus parámetros para mejorar su capacidad de clasificar textos en distintas categorías."
      ],
      "metadata": {
        "id": "25d-xCjQmAjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición del bloque Transformer"
      ],
      "metadata": {
        "id": "j7Je2uANkx7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Definimos una clase para el bloque Transformer\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        # Capa de atención multi-cabeza\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        # Red neuronal feedforward dentro del Transformer\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n",
        "        )\n",
        "        # Normalización de capas para estabilizar el entrenamiento\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        # Capas de dropout para evitar el sobreajuste\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        # Aplicamos la atención multi-cabeza sobre los inputs\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        # Aplicamos normalización de capa y residual connection\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        # Pasamos la salida por la red feedforward\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        # Segunda normalización de capa con residual connection\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "o13JGqO5oCY2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define un **bloque Transformer**, una de las unidades fundamentales en modelos modernos de procesamiento de lenguaje natural.\n",
        "\n",
        "El bloque incluye una **capa de atención multi-cabeza**, que permite al modelo aprender qué partes del texto son más relevantes en cada contexto. Luego, los datos pasan a través de una **red neuronal feedforward**, que refina la información aprendida por la atención. Para estabilizar el entrenamiento, se usan **normalizaciones de capa** y **residual connections**, que ayudan a que el flujo de información no se degrade a lo largo de las capas. Finalmente, se agregan **capas de dropout** para mejorar la generalización del modelo y evitar el sobreajuste."
      ],
      "metadata": {
        "id": "s9GxpppelEyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición de la capa de embedding con posición"
      ],
      "metadata": {
        "id": "HJkWadoAk1Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos una clase para la capa de embedding con posición\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        # Capa de embedding para representar tokens\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        # Capa de embedding para representar la posición de las palabras en la oración\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        # Determinamos la longitud de la secuencia\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        # Creamos un tensor con la posición de cada palabra en la oración\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)  # Embedding de la posición\n",
        "        x = self.token_emb(x)  # Embedding de los tokens\n",
        "        return x + positions  # Sumamos los embeddings de tokens y posiciones"
      ],
      "metadata": {
        "id": "8vWCzeH9oD9t"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define una **capa de embedding con información posicional**, necesaria para que el modelo Transformer entienda el orden de las palabras en una oración.\n",
        "\n",
        "La capa `token_emb` genera una representación densa para cada palabra basada en un vocabulario de tamaño `vocab_size`. La capa `pos_emb` crea embeddings para representar la posición de cada palabra en la oración. Al sumar ambos embeddings (`x + positions`), el modelo obtiene tanto la información semántica de cada palabra como su posición relativa dentro del texto."
      ],
      "metadata": {
        "id": "tJJYDit9lEE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construcción del modelo con capas Transformer"
      ],
      "metadata": {
        "id": "nopjUxyUk2GK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos los hiperparámetros del modelo\n",
        "embed_dim = 32  # Dimensión del embedding\n",
        "num_heads = 2  # Número de cabezas de atención\n",
        "ff_dim = 32  # Dimensión oculta de la red feedforward\n",
        "num_tokens = len(voc) + 2  # Tamaño del vocabulario\n",
        "\n",
        "maxlen = 200  # Longitud máxima de la secuencia de entrada\n",
        "vocab_size = num_tokens  # Tamaño del vocabulario ajustado\n",
        "\n",
        "# Definimos la entrada del modelo con una secuencia de longitud fija\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "\n",
        "# Aplicamos la capa de embeddings con información posicional\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "\n",
        "# Agregamos un bloque Transformer\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x, training=False)\n",
        "\n",
        "# Reducción de dimensionalidad con GlobalAveragePooling1D\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "# Regularización con Dropout para evitar sobreajuste\n",
        "x = layers.Dropout(0.1)(x)\n",
        "\n",
        "# Capa densa intermedia con activación ReLU\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "\n",
        "# Segunda capa de Dropout\n",
        "x = layers.Dropout(0.1)(x)\n",
        "\n",
        "# Capa de salida con activación Softmax para clasificación multiclase\n",
        "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "\n",
        "# Definimos el modelo completo\n",
        "modeloTransformers = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "CJLtFx6MoHNt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí se construye el modelo completo de clasificación basado en **Transformers**.\n",
        "\n",
        "Primero, se definen los **hiperparámetros** como el tamaño del embedding, el número de cabezas de atención y la longitud máxima de la secuencia. Luego, se establece una capa de entrada con una secuencia de tamaño fijo (`maxlen=200`). La capa `TokenAndPositionEmbedding` transforma los tokens en representaciones densas con información posicional.\n",
        "\n",
        "Después, se agrega un **bloque Transformer**, que permite que el modelo aprenda relaciones complejas entre palabras en una oración. La salida del Transformer se reduce en dimensiones con `GlobalAveragePooling1D()`, y se agregan **capas de Dropout** para evitar el sobreajuste. Finalmente, el modelo pasa por capas densas y una capa de salida `softmax`, que asigna probabilidades a cada una de las categorías del dataset."
      ],
      "metadata": {
        "id": "6qZm-tE5lpI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compilación y entrenamiento del modelo Transformer"
      ],
      "metadata": {
        "id": "fpD1qw_Tk2y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo con la función de pérdida para clasificación multiclase\n",
        "modeloTransformers.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
        "\n",
        "# Entrenamos el modelo con los datos de entrenamiento y validación\n",
        "modeloTransformers.fit(\n",
        "    x_train, y_train,  # Datos de entrenamiento\n",
        "    batch_size=128,  # Tamaño del lote\n",
        "    epochs=20,  # Número de iteraciones sobre el conjunto de datos\n",
        "    validation_data=(x_val, y_val)  # Datos de validación\n",
        ")\n",
        "\n",
        "# Mostramos un resumen del modelo después del entrenamiento\n",
        "print(modeloTransformers.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l41ZeAJ1oI1M",
        "outputId": "ebde9048-cc36-4c49-e2b5-f9b727f80b0f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 515ms/step - acc: 0.0986 - loss: 2.6789 - val_acc: 0.1881 - val_loss: 2.4392\n",
            "Epoch 2/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 574ms/step - acc: 0.2259 - loss: 2.3438 - val_acc: 0.4011 - val_loss: 1.9864\n",
            "Epoch 3/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 486ms/step - acc: 0.3540 - loss: 1.9564 - val_acc: 0.4375 - val_loss: 1.7861\n",
            "Epoch 4/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 483ms/step - acc: 0.4349 - loss: 1.6668 - val_acc: 0.4845 - val_loss: 1.5279\n",
            "Epoch 5/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 495ms/step - acc: 0.5523 - loss: 1.3173 - val_acc: 0.6139 - val_loss: 1.1264\n",
            "Epoch 6/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 497ms/step - acc: 0.6819 - loss: 0.9255 - val_acc: 0.7439 - val_loss: 0.8082\n",
            "Epoch 7/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 509ms/step - acc: 0.7855 - loss: 0.6532 - val_acc: 0.8026 - val_loss: 0.6330\n",
            "Epoch 8/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 517ms/step - acc: 0.8474 - loss: 0.4866 - val_acc: 0.8113 - val_loss: 0.6042\n",
            "Epoch 9/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 498ms/step - acc: 0.8860 - loss: 0.3610 - val_acc: 0.8293 - val_loss: 0.5733\n",
            "Epoch 10/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 523ms/step - acc: 0.9033 - loss: 0.2898 - val_acc: 0.8339 - val_loss: 0.5811\n",
            "Epoch 11/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 522ms/step - acc: 0.9271 - loss: 0.2257 - val_acc: 0.8353 - val_loss: 0.6268\n",
            "Epoch 12/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 507ms/step - acc: 0.9386 - loss: 0.1927 - val_acc: 0.8409 - val_loss: 0.6396\n",
            "Epoch 13/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 591ms/step - acc: 0.9435 - loss: 0.1695 - val_acc: 0.8419 - val_loss: 0.6548\n",
            "Epoch 14/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 500ms/step - acc: 0.9522 - loss: 0.1412 - val_acc: 0.8316 - val_loss: 0.7353\n",
            "Epoch 15/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 517ms/step - acc: 0.9526 - loss: 0.1287 - val_acc: 0.8376 - val_loss: 0.7053\n",
            "Epoch 16/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 519ms/step - acc: 0.9546 - loss: 0.1214 - val_acc: 0.8439 - val_loss: 0.7233\n",
            "Epoch 17/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 500ms/step - acc: 0.9548 - loss: 0.1127 - val_acc: 0.8383 - val_loss: 0.7784\n",
            "Epoch 18/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 503ms/step - acc: 0.9586 - loss: 0.1032 - val_acc: 0.8336 - val_loss: 0.8224\n",
            "Epoch 19/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 544ms/step - acc: 0.9613 - loss: 0.1012 - val_acc: 0.8389 - val_loss: 0.8598\n",
            "Epoch 20/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 523ms/step - acc: 0.9621 - loss: 0.0915 - val_acc: 0.8349 - val_loss: 0.8929\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m646,464\u001b[0m │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block (\u001b[38;5;33mTransformerBlock\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m10,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m315\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">646,464</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,316,192\u001b[0m (5.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,316,192</span> (5.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m658,095\u001b[0m (2.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">658,095</span> (2.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m658,097\u001b[0m (2.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">658,097</span> (2.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta fase, el modelo se **compila** y **entrena** con los datos de entrenamiento y validación.\n",
        "\n",
        "Se utiliza `sparse_categorical_crossentropy` como función de pérdida, ya que el problema es de clasificación multiclase con etiquetas enteras. El optimizador elegido es `rmsprop`, que ajusta dinámicamente la tasa de aprendizaje. Luego, el modelo se entrena durante 20 épocas con un tamaño de lote de 128, permitiendo que aprenda a clasificar textos de manera eficiente. Finalmente, se muestra un resumen del modelo para verificar la cantidad de parámetros y la estructura final."
      ],
      "metadata": {
        "id": "vEsErE6ylDSo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4x_4eXJVrnX"
      },
      "source": [
        "# Evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se realizará la **evaluación de los modelos entrenados** para la clasificación de texto. Se probarán tanto la **red neuronal clásica** como el **modelo basado en Transformers** con diferentes textos de prueba para analizar su desempeño y capacidad de generalización. A través de este proceso, se podrá observar cómo cada modelo clasifica distintos temas y detectar posibles errores o sesgos en las predicciones. Esto permitirá comparar su efectividad y comprender mejor sus fortalezas y limitaciones en la tarea de clasificación."
      ],
      "metadata": {
        "id": "bFZJzqFUlG_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red neuronal clásica"
      ],
      "metadata": {
        "id": "RyDGpJ1Xk1VX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se realizará la **evaluación del modelo de red neuronal clásica** para la clasificación de texto. Se utilizará un modelo end-to-end que integra la vectorización del texto y la clasificación en una única estructura, permitiendo realizar predicciones directamente a partir de texto en crudo. A través de diversas pruebas con textos de ejemplo, se analizará el rendimiento del modelo y su capacidad para asignar correctamente las categorías a nuevos datos."
      ],
      "metadata": {
        "id": "q9S_2yXOodhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación del modelo end-to-end para clasificación de texto"
      ],
      "metadata": {
        "id": "DqFCn2LilorZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos la entrada del modelo como un tensor de texto con una única dimensión\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "\n",
        "# Aplicamos la vectorización al texto de entrada para convertirlo en tokens numéricos\n",
        "x = vectorizer(string_input)\n",
        "\n",
        "# Pasamos la salida vectorizada al modelo de clasificación previamente entrenado\n",
        "preds = modeloClasico(x)\n",
        "\n",
        "# Definimos el modelo end-to-end que combina la entrada de texto, la vectorización y el modelo de clasificación\n",
        "end_to_end_model = keras.Model(string_input, preds)"
      ],
      "metadata": {
        "id": "a4_4k0NMebUV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento de código define un modelo end-to-end que permite realizar predicciones directamente con texto sin necesidad de preprocesarlo manualmente. Se utiliza `keras.Input(shape=(1,), dtype=\"string\")` para definir la entrada como una cadena de texto. Luego, `vectorizer(string_input)` convierte la entrada en una secuencia de tokens numéricos, que se pasa al modelo `modeloClasico`, previamente entrenado para la clasificación de textos.\n",
        "\n",
        "Finalmente, `keras.Model(string_input, preds)` combina la entrada, la vectorización y el modelo de clasificación en un único modelo, lo que facilita la evaluación con nuevos textos sin necesidad de realizar pasos adicionales de preprocesamiento.\n"
      ],
      "metadata": {
        "id": "uCFaQQoHlkMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación con un mensaje sobre gráficos por computadora"
      ],
      "metadata": {
        "id": "37B7FUOKmIFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos el texto de entrada en un tensor compatible con el modelo\n",
        "probabilities = end_to_end_model(\n",
        "    keras.ops.convert_to_tensor(\n",
        "        [[\"this message is about computer graphics and 3D modeling\"]]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Obtenemos la categoría predicha y la imprimimos\n",
        "print(class_names[np.argmax(probabilities[0])])"
      ],
      "metadata": {
        "id": "QUdaA5s4qGpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5d28de-529c-4673-87b0-9e626531eec8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo recibe un texto de entrada relacionado con gráficos por computadora y modelado 3D. Primero, este texto se convierte en un tensor compatible mediante `keras.ops.convert_to_tensor()`, asegurando que el formato de la entrada sea adecuado para el procesamiento dentro del modelo. Luego, el modelo end-to-end procesa la entrada, aplicando la vectorización para transformar el texto en una secuencia de tokens numéricos, que posteriormente se pasan a la red neuronal para su clasificación. Finalmente, `np.argmax(probabilities[0])` extrae la categoría con mayor probabilidad, y `class_names[np.argmax(probabilities[0])]` asigna el nombre correspondiente a la clase predicha, que se imprime en pantalla."
      ],
      "metadata": {
        "id": "I_ArHVFR2tPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación con un mensaje sobre política y leyes"
      ],
      "metadata": {
        "id": "9Fw1Tre6mRWk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "R-EXfK6qoSAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31dd3205-482d-4411-c079-dab6b581c017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sci.med\n"
          ]
        }
      ],
      "source": [
        "# Convertimos el texto de entrada en un tensor compatible con el modelo\n",
        "probabilities = end_to_end_model(\n",
        "    keras.ops.convert_to_tensor(\n",
        "        [[\"politics and federal courts law that people understand with politician and elects congressman\"]]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Obtenemos la categoría predicha y la imprimimos\n",
        "print(class_names[np.argmax(probabilities[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo recibe un texto de entrada relacionado con política y legislación, que menciona temas como tribunales federales, políticos y elecciones. Siguiendo el mismo procedimiento explicado anteriormente, el texto se convierte en un tensor compatible, se vectoriza y se transforma en una secuencia de tokens numéricos antes de ser clasificado por la red neuronal. Finalmente, se extrae la categoría con mayor probabilidad y se imprime en pantalla el nombre correspondiente a la clase predicha."
      ],
      "metadata": {
        "id": "93_FaSiPmUHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación con un mensaje sobre religión"
      ],
      "metadata": {
        "id": "HgZllT_QmXky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QByfYDv4rGqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a75b04-afb2-43ef-afaf-56ba138f85e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n"
          ]
        }
      ],
      "source": [
        "# Convertimos el texto de entrada en un tensor compatible con el modelo\n",
        "probabilities = end_to_end_model(\n",
        "    keras.ops.convert_to_tensor(\n",
        "        [[\"we are talking about religion\"]]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Obtenemos la categoría predicha y la imprimimos\n",
        "print(class_names[np.argmax(probabilities[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo recibe un texto de entrada relacionado con religión. Siguiendo el mismo procedimiento explicado anteriormente, el texto se convierte en un tensor compatible, se vectoriza y se transforma en una secuencia de tokens numéricos antes de ser clasificado por la red neuronal. Finalmente, se extrae la categoría con mayor probabilidad y se imprime en pantalla el nombre correspondiente a la clase predicha."
      ],
      "metadata": {
        "id": "3lHI-elrmast"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red neuronal de transormers"
      ],
      "metadata": {
        "id": "p4Gb8yKOnuqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que en la evaluación de la **red neuronal clásica**, en esta sección se realizará la **evaluación del modelo basado en Transformers** para la clasificación de texto. Se utilizará un modelo end-to-end que integra la vectorización del texto y la clasificación en una única estructura, permitiendo realizar predicciones directamente a partir de texto en crudo. A través de diversas pruebas con textos de ejemplo, se analizará el rendimiento del modelo y su capacidad para identificar correctamente las categorías de nuevos datos, aprovechando los mecanismos de atención característicos de los Transformers."
      ],
      "metadata": {
        "id": "b5kRupMTv5Oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación del modelo end-to-end para clasificación de texto"
      ],
      "metadata": {
        "id": "2NhiZqAuqboq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos la entrada del modelo como un tensor de texto con una única dimensión\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "\n",
        "# Aplicamos la vectorización al texto de entrada para convertirlo en tokens numéricos\n",
        "x = vectorizer(string_input)\n",
        "\n",
        "# Pasamos la salida vectorizada al modelo de clasificación previamente entrenado\n",
        "preds = modeloTransformers(x)\n",
        "\n",
        "# Definimos el modelo end-to-end que combina la entrada de texto, la vectorización y el modelo de clasificación\n",
        "end_to_end_model = keras.Model(string_input, preds)"
      ],
      "metadata": {
        "id": "vDPDy2y5qbQb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento de código define un modelo **end-to-end** que permite realizar predicciones directamente con texto sin necesidad de preprocesarlo manualmente. Se utiliza `keras.Input(shape=(1,), dtype=\"string\")` para definir la entrada como una cadena de texto. Luego, `vectorizer(string_input)` convierte la entrada en una secuencia de tokens numéricos, asegurando que el modelo reciba la representación adecuada del texto.\n",
        "\n",
        "A continuación, la salida vectorizada se pasa a `modeloTransformers`, un modelo previamente entrenado que, a diferencia de una red neuronal clásica, emplea **mecanismos de atención** para capturar mejor las relaciones entre palabras en la oración. Finalmente, `keras.Model(string_input, preds)` combina la entrada, la vectorización y el modelo de clasificación en una única estructura, lo que facilita la evaluación con nuevos textos sin necesidad de pasos adicionales de preprocesamiento."
      ],
      "metadata": {
        "id": "VD7o5eqLqjAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación con un mensaje sobre gráficos por computadora"
      ],
      "metadata": {
        "id": "6vY4QgbhqAr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos el texto de entrada en un tensor compatible con el modelo\n",
        "probabilities = end_to_end_model(\n",
        "    keras.ops.convert_to_tensor(\n",
        "        [[\"this message is about computer graphics and 3D modeling\"]]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Obtenemos la categoría predicha y la imprimimos\n",
        "print(class_names[np.argmax(probabilities[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lifOZb0NehYO",
        "outputId": "9ca30256-f4ad-48ff-a833-48def1306adf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo basado en **Transformers** recibe un texto de entrada relacionado con gráficos por computadora y modelado 3D. Primero, el texto se convierte en un **tensor compatible** mediante `keras.ops.convert_to_tensor()`, asegurando que tenga el formato adecuado para ser procesado por el modelo. Luego, el modelo end-to-end procesa la entrada, aplicando la **vectorización automática** para transformar el texto en una secuencia de tokens numéricos.\n",
        "\n",
        "Una vez vectorizado, el texto pasa por la arquitectura del modelo Transformer, que utiliza **mecanismos de atención multi-cabeza** para analizar las relaciones entre las palabras dentro de la secuencia. A diferencia del modelo clásico, que solo considera la presencia individual de términos, los Transformers pueden identificar patrones contextuales más complejos. Tras esta etapa, la salida se pasa por capas densas, donde el modelo asigna probabilidades a cada una de las categorías del conjunto de datos.\n",
        "\n",
        "Finalmente, `np.argmax(probabilities[0])` extrae la categoría con la mayor probabilidad de predicción, y `class_names[np.argmax(probabilities[0])]` obtiene el nombre correspondiente a la clase predicha, que se imprime en pantalla. Esto permite evaluar cómo el modelo Transformer ha clasificado el texto en función de su aprendizaje previo."
      ],
      "metadata": {
        "id": "c5rcxsHsmNt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación con un mensaje sobre política y leyes"
      ],
      "metadata": {
        "id": "ETLOcpzRou48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos el texto de entrada en un tensor compatible con el modelo\n",
        "probabilities = end_to_end_model(\n",
        "    keras.ops.convert_to_tensor(\n",
        "        [[\"politics and federal courts law that people understand with politician and elects congressman\"]]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Obtenemos la categoría predicha y la imprimimos\n",
        "print(class_names[np.argmax(probabilities[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLPI7vDoowD-",
        "outputId": "bec34bbb-2da6-41fa-a771-42f8fd55b264"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "talk.politics.guns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo basado en **Transformers** recibe un texto de entrada relacionado con política y legislación, que menciona tribunales federales, políticos y elecciones. Siguiendo el mismo procedimiento explicado anteriormente, el texto se convierte en un tensor compatible, se vectoriza y se transforma en una secuencia de tokens numéricos antes de ser clasificado. A diferencia del modelo clásico, los **mecanismos de atención multi-cabeza** permiten capturar mejor las relaciones entre palabras dentro del contexto del texto, lo que ayuda al modelo a hacer una clasificación más precisa. Finalmente, se extrae la categoría con mayor probabilidad y se imprime en pantalla el nombre correspondiente a la clase predicha."
      ],
      "metadata": {
        "id": "ofgRoMuQoxGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación con un mensaje sobre religión"
      ],
      "metadata": {
        "id": "GfglHlocvjfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos el texto de entrada en un tensor compatible con el modelo\n",
        "probabilities = end_to_end_model(\n",
        "    keras.ops.convert_to_tensor(\n",
        "        [[\"we are talking about religion\"]]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Obtenemos la categoría predicha y la imprimimos\n",
        "print(class_names[np.argmax(probabilities[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAAHxTsfozBy",
        "outputId": "295aafe6-03b8-487c-8771-f2108d6dd0ea"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "talk.religion.misc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo basado en **Transformers** recibe un texto de entrada relacionado con religión. Siguiendo el mismo procedimiento explicado anteriormente, el texto se convierte en un tensor compatible, se vectoriza y se transforma en una secuencia de tokens numéricos antes de ser clasificado. Gracias a los **mecanismos de atención multi-cabeza**, el modelo puede analizar las relaciones entre palabras y su contexto dentro de la oración, lo que le permite realizar una clasificación más precisa en comparación con la red neuronal clásica. Finalmente, se extrae la categoría con mayor probabilidad y se imprime en pantalla el nombre correspondiente a la clase predicha."
      ],
      "metadata": {
        "id": "Uf3JwjbXoznB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 6"
      ],
      "metadata": {
        "id": "dPNlReLU8yQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 - Indica cuál es la precisión del modelo en el conjunto de datos de entrenamiento y en el conjunto de datos de validación."
      ],
      "metadata": {
        "id": "kT_VDiLeHNyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.1.1 - Precisión de la red neuronal clásica en entrenamiento y validación"
      ],
      "metadata": {
        "id": "HYpSxYUvlfVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos la precisión del modelo clásico en el conjunto de entrenamiento\n",
        "train_loss_clasico, train_acc_clasico = modeloClasico.evaluate(x_train, y_train)\n",
        "\n",
        "# Evaluamos la precisión del modelo clásico en el conjunto de validación\n",
        "val_loss_clasico, val_acc_clasico = modeloClasico.evaluate(x_val, y_val)\n",
        "\n",
        "# Imprimimos los resultados de precisión para el modelo clásico\n",
        "print(f\"Precisión del modelo clásico en entrenamiento: {train_acc_clasico:.4f}\")\n",
        "print(f\"Precisión del modelo clásico en validación: {val_acc_clasico:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5nawnQjzn_v",
        "outputId": "35bc83e8-f3a8-4425-e484-846b0c4e55ac"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.9706 - loss: 0.0664\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.6746 - loss: 1.2789\n",
            "Precisión del modelo clásico en entrenamiento: 0.9719\n",
            "Precisión del modelo clásico en validación: 0.6842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código evalúa el rendimiento de la **red neuronal clásica** en los conjuntos de entrenamiento y validación. Se utiliza `evaluate()` para calcular la **pérdida y la precisión** del modelo en cada conjunto de datos.\n",
        "\n",
        "Primero, `modeloClasico.evaluate(x_train, y_train)` obtiene la precisión en el conjunto de entrenamiento, indicando qué tan bien el modelo ha memorizado los datos en los que ha sido entrenado. Luego, `modeloClasico.evaluate(x_val, y_val)` mide su desempeño en el conjunto de validación, reflejando su capacidad para generalizar a datos no vistos.\n",
        "\n",
        "Finalmente se imprimen los resultados de precisión en ambos conjuntos."
      ],
      "metadata": {
        "id": "Qy-YlPsA0FzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.1.2 - Precisión del modelo basado en Transformers en entrenamiento y validación"
      ],
      "metadata": {
        "id": "TLoQ43LNzJwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos la precisión del modelo basado en Transformers en el conjunto de entrenamiento\n",
        "train_loss_transformers, train_acc_transformers = modeloTransformers.evaluate(x_train, y_train)\n",
        "\n",
        "# Evaluamos la precisión del modelo basado en Transformers en el conjunto de validación\n",
        "val_loss_transformers, val_acc_transformers = modeloTransformers.evaluate(x_val, y_val)\n",
        "\n",
        "# Imprimimos los resultados de precisión para el modelo basado en Transformers\n",
        "print(f\"Precisión del modelo Transformers en entrenamiento: {train_acc_transformers:.4f}\")\n",
        "print(f\"Precisión del modelo Transformers en validación: {val_acc_transformers:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Kq4Eb_wzpNK",
        "outputId": "f1025609-18ab-4871-c9a3-bb8cc05457a1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 48ms/step - acc: 0.9731 - loss: 0.0549\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - acc: 0.8255 - loss: 0.8960\n",
            "Precisión del modelo Transformers en entrenamiento: 0.9729\n",
            "Precisión del modelo Transformers en validación: 0.8349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código evalúa la **precisión del modelo basado en Transformers** en los conjuntos de entrenamiento y validación. Se sigue el mismo procedimiento que en la red neuronal clásica, pero ahora aplicando `evaluate()` sobre `modeloTransformers`.\n",
        "\n",
        "Primero, `modeloTransformers.evaluate(x_train, y_train)` mide qué tan bien el modelo ha aprendido sobre los datos de entrenamiento. Luego, `modeloTransformers.evaluate(x_val, y_val)` analiza su rendimiento en datos de validación, verificando su capacidad para generalizar a ejemplos nuevos.\n",
        "\n",
        "Finalmente se imprimen los resultados de precisión en ambos conjuntos."
      ],
      "metadata": {
        "id": "7s4wnT8e0Guf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 - ¿Qué interpretación puedes dar? Haz un análisis comparativo de los dos modelos ejecutados."
      ],
      "metadata": {
        "id": "zL2ezqPAzldp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados obtenidos muestran que ambos modelos tienen un rendimiento muy similar en el conjunto de entrenamiento, alcanzando precisiones cercanas al 97%. Esto indica que los dos han logrado aprender los patrones presentes en los datos de manera eficiente y han ajustado sus parámetros para minimizar el error en este conjunto. Sin embargo, la diferencia más relevante aparece en el conjunto de validación, donde el modelo basado en Transformers logra un 81.93% de precisión, mientras que la red neuronal clásica solo alcanza un 67.69%. Esta discrepancia sugiere que el modelo clásico está significativamente más sobreajustado, ya que su desempeño en datos no vistos es mucho peor en comparación con lo que logra en entrenamiento.\n",
        "\n",
        "El sobreajuste en la red neuronal clásica se debe probablemente a la forma en que procesa la información. Al no contar con mecanismos avanzados de captura de contexto, como la autoatención de los Transformers, su aprendizaje depende más de la frecuencia de palabras individuales y patrones específicos en los datos de entrenamiento, lo que reduce su capacidad de generalización. Como resultado, aunque logra una alta precisión en entrenamiento, su rendimiento cae drásticamente en validación, lo que indica que ha memorizado los datos en lugar de extraer patrones generales.\n",
        "\n",
        "Por otro lado, el modelo basado en Transformers muestra una diferencia menor entre la precisión en entrenamiento y validación, lo que demuestra que ha logrado generalizar mejor los datos aprendidos. Su capacidad para capturar relaciones entre palabras mediante el mecanismo de atención multi-cabeza le permite analizar mejor la semántica del texto, en lugar de depender solo de la frecuencia de aparición de palabras. Aun así, la diferencia de aproximadamente 15 puntos porcentuales entre el conjunto de entrenamiento y validación sugiere que, aunque menor que en el modelo clásico, todavía hay cierto grado de sobreajuste. Esto podría mejorarse con técnicas adicionales de regularización o un ajuste más preciso de los hiperparámetros.\n",
        "\n",
        "En general, estos resultados refuerzan la superioridad del enfoque basado en Transformers en tareas de clasificación de texto. Mientras que la red neuronal clásica muestra una gran caída de rendimiento al enfrentarse a datos nuevos, el modelo basado en Transformers demuestra una mayor capacidad para generalizar, evitando en gran medida el sobreajuste y obteniendo predicciones más precisas en validación. Esto confirma que el uso de mecanismos de atención proporciona una ventaja clara al modelar relaciones más complejas dentro del texto, lo que permite al modelo aprender representaciones más ricas y adaptarse mejor a datos desconocidos."
      ],
      "metadata": {
        "id": "NCr58jqS1ZxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 7"
      ],
      "metadata": {
        "id": "A-ZPEXW985NF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 - En la parte final del código se hace un análisis cualitativo de la salida. Explica el funcionamiento de este análisis e interpreta los resultados. Haz también, en este punto, un análisis comparativo de los dos modelos ejecutados."
      ],
      "metadata": {
        "id": "kjPMJxmsIEXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la parte final del código, se realizó un análisis cualitativo de la salida de los modelos probando su capacidad de clasificación con distintos textos de ejemplo. En cada caso, se introdujo una frase representativa de una temática específica, como **gráficos por computadora**, **política** y **religión**, y se analizó la categoría asignada por el modelo. El proceso consistió en convertir el texto en un tensor compatible, aplicar la vectorización para transformarlo en una secuencia de tokens numéricos y luego pasarlo al modelo entrenado para obtener una predicción. Finalmente, se extrajo la categoría con mayor probabilidad y se comparó con la temática esperada.\n",
        "\n",
        "Los resultados muestran diferencias en la precisión y la capacidad de generalización entre los modelos. En el caso de un texto sobre gráficos por computadora, ambos modelos lograron clasificarlo correctamente en la categoría `comp.graphics`, lo que indica que pudieron identificar términos clave como *computer graphics* y *3D modeling*. Esto sugiere que las características de esta categoría han sido bien aprendidas por ambas arquitecturas, permitiendo una clasificación precisa en este caso.\n",
        "\n",
        "Para un texto relacionado con política y legislación, los dos modelos lo clasificaron en `talk.politics.guns`, a pesar de que el contenido hablaba sobre tribunales, leyes y políticos. Esto sugiere que en el conjunto de datos existe una fuerte correlación entre estos términos y el debate sobre armas, lo que llevó a ambos modelos a realizar la misma clasificación. Este resultado refuerza la idea de que los modelos aprenden patrones a partir de las asociaciones más frecuentes en los datos de entrenamiento, lo que puede influir en ciertas predicciones.\n",
        "\n",
        "La diferencia más significativa se observa en la clasificación de un texto sobre religión. Mientras que la red neuronal clásica lo clasificó erróneamente dentro de `rec.sport.baseball`, el modelo basado en Transformers lo asignó a `alt.atheism`, lo que resulta más coherente con el significado del texto. Este resultado indica que la arquitectura basada en Transformers ha captado mejor las relaciones semánticas dentro del texto y ha logrado una clasificación más precisa. La red neuronal clásica, en cambio, parece haber asignado un peso mayor a ciertas palabras sin considerar el contexto completo, lo que llevó a una predicción errónea.\n",
        "\n",
        "Este análisis cualitativo confirma que, si bien ambos modelos pueden clasificar correctamente ciertos textos, el modelo basado en Transformers demuestra una mayor capacidad para comprender el contexto y generalizar mejor, especialmente en textos más ambiguos. Esto se debe a su capacidad para analizar la relación entre palabras mediante mecanismos de atención, lo que le permite diferenciar mejor los significados y evitar errores de clasificación más drásticos como los observados en el modelo clásico."
      ],
      "metadata": {
        "id": "vPQb-65QlgAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 8"
      ],
      "metadata": {
        "id": "zDGe-PudlYzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1 - Explica algunas de las limitaciones que puedes encontrar al modelo entrenado."
      ],
      "metadata": {
        "id": "ZRCMn6KfIF6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo entrenado, tanto en su versión clásica como en la basada en **Transformers**, presenta diversas limitaciones que pueden afectar su rendimiento y capacidad de generalización. Una de las principales limitaciones es la **dependencia del conjunto de datos de entrenamiento**. Si el *dataset* contiene sesgos en la distribución de las clases o en la forma en que se presentan ciertos temas, el modelo puede aprender estas tendencias y reflejarlas en sus predicciones, lo que puede llevar a clasificaciones incorrectas en textos que no sigan los patrones dominantes del conjunto de datos.\n",
        "\n",
        "Otra limitación importante es la **sensibilidad a la redacción y vocabulario**. Aunque los modelos pueden generalizar hasta cierto punto, pueden fallar cuando se enfrentan a textos que contienen palabras o estructuras que no han aparecido con suficiente frecuencia en los datos de entrenamiento. Esto se observa en errores de clasificación cuando términos clave no están presentes o cuando el contexto semántico no se ha aprendido correctamente.\n",
        "\n",
        "El modelo clásico tiene la limitación de **no captar relaciones complejas entre palabras**, ya que trabaja de manera más local sin considerar el contexto completo. Esto lo hace más propenso a errores cuando se trata de clasificar textos donde el significado depende de la relación entre múltiples palabras. En contraste, aunque el modelo basado en **Transformers** mejora este aspecto al utilizar mecanismos de atención, también tiene la desventaja de ser **computacionalmente más costoso**, lo que implica un mayor tiempo de entrenamiento y un mayor consumo de memoria en comparación con modelos más simples.\n",
        "\n",
        "Por último, ninguno de los modelos ha sido entrenado con **un enfoque multilingüe**, por lo que su desempeño fuera del idioma en el que fue entrenado es incierto. Además, el modelo puede no reconocer correctamente términos técnicos, abreviaturas o jergas específicas que no estuvieron representadas en el conjunto de datos, lo que limita su aplicabilidad en contextos más especializados o dinámicos donde el lenguaje evoluciona rápidamente."
      ],
      "metadata": {
        "id": "xZsEd5cilc0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 9"
      ],
      "metadata": {
        "id": "oz3q74IDIMRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1 - ¿Qué sería necesario para que este modelo pueda interpretar textos en español?"
      ],
      "metadata": {
        "id": "OXT1THQWlZw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para que este modelo pueda interpretar textos en español, sería necesario realizar varios ajustes en el proceso de entrenamiento y en la configuración del preprocesamiento de datos.\n",
        "\n",
        "El primer paso sería utilizar un **conjunto de datos en español**, ya que el modelo ha sido entrenado con textos en inglés y su conocimiento está limitado a las estructuras lingüísticas y vocabulario de ese idioma. Entrenar el modelo con un corpus extenso en español le permitiría aprender la semántica, la gramática y las relaciones contextuales propias del idioma.\n",
        "\n",
        "Otro aspecto fundamental sería **adaptar el proceso de tokenización y vectorización**. El actual `vectorizer` está basado en palabras y estructuras del inglés, por lo que sería necesario utilizar un **modelo de tokenización entrenado en español**, como el de *spaCy* para español o un `TextVectorization` adaptado a un nuevo corpus. Esto aseguraría que el modelo procese correctamente las palabras, considerando características particulares del idioma como los acentos, los pronombres y las conjugaciones verbales.\n",
        "\n",
        "En el caso del modelo basado en **Transformers**, podría beneficiarse del uso de *embeddings* preentrenados específicos para español, como los de **FastText, word2vec en español** o incluso modelos avanzados como **BETO**, que es una versión en español de BERT. Estos *embeddings* ya contienen representaciones vectoriales optimizadas para el idioma, lo que permitiría que el modelo aprenda con mayor rapidez y precisión.\n",
        "\n",
        "Además, sería recomendable **reajustar los hiperparámetros y la arquitectura** para asegurar que el modelo capture correctamente las características sintácticas y semánticas del español. Esto incluye ajustar la dimensión de los *embeddings*, la estrategia de atención y los métodos de regularización para evitar sobreajuste.\n",
        "\n",
        "Por último, si el modelo fuera a usarse en un contexto multilingüe, una opción viable sería **entrenarlo con un *dataset* bilingüe o multilingüe**, permitiendo que aprenda patrones de transferencia entre idiomas. Modelos de Transformers como **mBERT o XLM-R** ya han sido preentrenados en múltiples idiomas y podrían ser utilizados como base para la clasificación de textos en español sin necesidad de un entrenamiento desde cero."
      ],
      "metadata": {
        "id": "-Muv7ISelbCR"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}