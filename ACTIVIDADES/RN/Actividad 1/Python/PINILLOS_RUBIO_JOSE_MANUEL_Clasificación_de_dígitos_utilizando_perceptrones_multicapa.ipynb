{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Redes Neuronales y Aprendizaje Profundo**"
      ],
      "metadata": {
        "id": "o3dp9DdAVBt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "Datos del alumno (Nombre y Apellidos): Jose Manuel Pinillos Rubio\n",
        "\n",
        "Fecha: 1 de mayo de 2025\n",
        "***"
      ],
      "metadata": {
        "id": "bkGGwKObWFpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Clasificación de dígitos utilizando perceptrones multicapa</span>"
      ],
      "metadata": {
        "id": "AxYwUFDXWe1_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiDzBoKGwmMZ"
      },
      "source": [
        "## Descripción de la actividad\n",
        "\n",
        "En esta actividad vamos a utilizar una red neuronal para clasificar imágenes de dígitos del 0 al 9 escritos a mano. Para ello, utilizaremos Keras con TensorFlow.\n",
        "\n",
        "El dataset a utilizar es MNIST, una base de datos constituida por (como no) imágenes de dígitos escritos a mano. Este dataset es ampliamente utilizado en docencia como punto de entrada al entrenamiento de redes neuronales y otros, pero también es muy utilizado en trabajos reales de investigación para el entrenamiento de imágenes. Puedes consultar más información sobre el dataset en [este enlace](https://es.wikipedia.org/wiki/Base_de_datos_MNIST).\n",
        "\n",
        "El código utilizado para contestar tiene que quedar claramente reflejado en el Notebook. Puedes crear nuevas celdas si así lo deseas para estructurar tu código y sus salidas. A la hora de entregar el notebook, **asegúrate de que los resultados de ejecutar tu código han quedado guardados y que son perfectamente visibles en la versión PDF que debes entregar adjunta**. Por ejemplo, a la hora de entrenar una red neuronal tiene que verse claramente un log de los resultados de cada epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSHr268SwmMa"
      },
      "source": [
        "# -------------------- Keras y TensorFlow --------------------\n",
        "import keras  # Interfaz de alto nivel para construir y entrenar redes neuronales\n",
        "from keras.datasets.mnist import load_data  # Carga directa del dataset MNIST\n",
        "\n",
        "from keras.models import Sequential  # Permite definir un modelo como una secuencia de capas\n",
        "from keras.layers import Dense, Flatten, Dropout, LeakyReLU  # Capas densas, de aplanamiento, regularización y activación avanzada\n",
        "from tensorflow.keras import Input  # Capa explícita de entrada para modelos secuenciales\n",
        "\n",
        "import tensorflow as tf  # Framework de aprendizaje profundo sobre el que se ejecuta Keras\n",
        "from tensorflow.keras.optimizers import Adam  # Optimizador Adam para entrenamiento\n",
        "from keras.optimizers import SGD, Adagrad, RMSprop  # Otros optimizadores disponibles para comparación\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping  # Detención temprana para evitar sobreentrenamiento\n",
        "from keras.callbacks import Callback  # Clase base para crear callbacks personalizados\n",
        "from keras.regularizers import l2, l1_l2  # Regularizadores L2 y combinación L1_L2 para evitar sobreajuste\n",
        "\n",
        "# -------------------- Utilidades --------------------\n",
        "import matplotlib.pyplot as plt  # Biblioteca para visualización de datos y gráficos\n",
        "import numpy as np  # Biblioteca para operaciones numéricas con arrays\n",
        "import pandas as pd  # Biblioteca para manipulación y análisis de datos tabulares\n",
        "\n",
        "# -------------------- Semillas para reproducibilidad --------------------\n",
        "import os\n",
        "import random\n",
        "\n",
        "seed_value = 13\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)  # Asegura consistencia en operaciones internas de Python\n",
        "random.seed(seed_value)                         # Fijamos la semilla para el generador aleatorio de Python\n",
        "np.random.seed(seed_value)                      # Fijamos la semilla para NumPy\n",
        "tf.random.set_seed(seed_value)                  # Fijamos la semilla para TensorFlow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este bloque se importan las bibliotecas necesarias para desarrollar la actividad: `Keras` y `TensorFlow` para construir y entrenar la red neuronal, `matplotlib` para visualizar imágenes, y `NumPy` y `pandas` para operaciones numéricas y análisis de datos. Además, se fijan las semillas aleatorias de `NumPy` y `TensorFlow` para mejorar la reproducibilidad de los resultados. Esto es necesario porque las redes neuronales incluyen procesos aleatorios internos, como la inicialización de pesos o la partición de validación, que no permiten especificar una semilla local como en otros algoritmos tradicionales. Por este motivo, las semillas deben establecerse de forma global antes de ejecutar cualquier operación. No obstante, al trabajar en entornos como Google Colab (mi caso) con aceleración por GPU, pueden mantenerse pequeñas variaciones entre ejecuciones, ya que algunas operaciones paralelizadas no son completamente deterministas."
      ],
      "metadata": {
        "id": "OD2AAc7Q4K4g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zScMKU2OKSPD"
      },
      "source": [
        "Tenemos la suerte de que el dataset MNIST, el que vamos a utilizar en esta actividad, está guardado en Keras, por lo que podemos utilizarlo sin necesidad de buscar el dataset de forma externa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4voG2hxxG4h3"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JphLsCvgKrzb"
      },
      "source": [
        "Llamar a **load_data** en este dataset nos dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen los dígitos y sus etiquetas.\n",
        "\n",
        "Nota: Aunque en esta actividad lo veis de esta forma, también lo vais a poder encontrar como 4 variables de esta forma: training_images, training_labels, test_images, test_labels = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1muD4PHEG4h6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43169cba-33b7-4c7a-f4c4-ab1db387a9da"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWGpJqVVLT3Y"
      },
      "source": [
        "Antes de continuar vamos a dar un vistazo a nuestro dataset, para ello vamos a ver una imagen de entrenamiento y su etiqueta o clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5a5PlswG4h8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "outputId": "23bf75dd-2f23-4690-a64e-153396f63800"
      },
      "source": [
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(training_images[0], cmap=\"gray\") # recordad que siempre es preferible trabajar en blanco y negro\n",
        "\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaqXlSMBwmMg"
      },
      "source": [
        "## 1. Información sobre el dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0aer8ZZwmMh"
      },
      "source": [
        "Una vez tenemos los datos cargados en memoria, vamos a obtener información sobre los mismos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-im9PnEwmMh"
      },
      "source": [
        "### Pregunta 1.1\n",
        "\n",
        "¿Cuántas imágenes hay de *training* y de *test*? ¿Qué tamaño tienen las imágenes?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El conjunto de datos está compuesto por **60.000 imágenes de entrenamiento** y **10.000 imágenes de prueba**, sumando un total de **70.000 imágenes**, cada una con un tamaño de **28x28 píxeles**. Esta información puede consultarse en la [descripción del dataset](https://es.wikipedia.org/wiki/Base_de_datos_MNIST), donde se detallan sus características principales.\n",
        "\n",
        "No obstante, si no se dispusiera de dicha documentación, es posible obtener estos datos directamente mediante código en Python:"
      ],
      "metadata": {
        "id": "J2tm4p9impty"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvP0Y4SCwmMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee257d0-0fc1-4e06-c40c-a5c957efcd60"
      },
      "source": [
        "# Obtenemos el número total de imágenes en el conjunto de entrenamiento\n",
        "n_images_training = training_images.shape[0]\n",
        "\n",
        "# Obtenemos el número total de imágenes en el conjunto de prueba\n",
        "n_images_test = test_images.shape[0]\n",
        "\n",
        "# Obtenemos el tamaño (alto x ancho) de una imagen\n",
        "image_shape = training_images[0].shape\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(f\"Tenemos un total de {n_images_training} imágenes de entrenamiento y {n_images_test} imágenes de test, lo que hace un total de {n_images_training + n_images_test} imágenes.\")\n",
        "print(f\"Cada imagen tiene un tamaño de {image_shape[0]}x{image_shape[1]} píxeles.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenemos un total de 60000 imágenes de entrenamiento y 10000 imágenes de test, lo que hace un total de 70000 imágenes.\n",
            "Cada imagen tiene un tamaño de 28x28 píxeles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwp5ljFKwmMj"
      },
      "source": [
        "Este fragmento de código permite calcular y mostrar cuántas imágenes hay en los conjuntos de entrenamiento y prueba del *dataset*, así como el tamaño de cada imagen.\n",
        "\n",
        "En primer lugar, se accede al atributo `shape` del array `training_images`, que devuelve una tupla con las dimensiones del conjunto: el número de imágenes, la altura y la anchura. El valor en la posición `[0]` representa la cantidad total de imágenes de entrenamiento, mientras que `test_images.shape[0]` indica cuántas hay en el conjunto de prueba.\n",
        "\n",
        "Para conocer el tamaño de cada imagen, se accede directamente al primer elemento del conjunto (`training_images[0]`) y se evalúa su atributo `shape`, que devuelve una tupla con las dimensiones en píxeles (altura y anchura). Esta operación es válida porque todas las imágenes tienen la misma resolución.\n",
        "\n",
        "Por último, se imprime un mensaje formateado mediante *f-strings* que resume el número de imágenes en cada conjunto, el total general y el tamaño de cada imagen. De este modo, el código ofrece una manera sencilla y clara de verificar el tamaño del dataset sin necesidad de consultar documentación externa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2LsvfHOwmMk"
      },
      "source": [
        "### Pregunta 1.2\n",
        "\n",
        "Realizar una exploración de las variables que contienen los datos. Describir en qué consiste un example del dataset (qué información se guarda en cada imagen) y describir qué contiene la información en $y$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1 `training_images`"
      ],
      "metadata": {
        "id": "H0O3kfgyssOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos la primera imagen del dataset de entrenamiento\n",
        "plt.imshow(training_images[0], cmap=\"gray\")\n",
        "plt.title(f\"Etiqueta: {training_labels[0]}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Mostramos el tamaño de la imagen\n",
        "print(\"Dimensiones de la imagen:\", training_images[0].shape)\n",
        "\n",
        "# Mostramos los valores mínimo y máximo de la imagen\n",
        "print(\"Valor mínimo en la imagen:\", training_images[0].min())\n",
        "print(\"Valor máximo en la imagen:\", training_images[0].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "K53s7zFQrJop",
        "outputId": "c92db656-780b-4d97-dc24-2440933301d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEI9JREFUeJzt3X+slnX9x/H37TkdJweCcCQbFT9OgiPmTkNtY1i65hzD4zjknDA3zbRVGkpFpf0AmpCtsEaZsuXAxmg0xSLL6RZQf1g0pvZjTlYGTNr5w8Jz5IeBcF/98f36nsdzxPO59ZyDh8dj8w9u7td9XaCepxf3fS5rVVVVAQARccZwnwAApw5RACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRR4JS1YsWKqNVqw30acFoRBQbFhg0bolarveFff/zjHyMi4siRI7FixYrYsWPH8J7wAGzatCl+8IMfDNnxpkyZ0u/v3Wc+85khOwdOP83DfQKMbN/61rdi6tSpfR7/4Ac/GBH/F4WVK1dGRMQll1zS6zlf//rX46tf/eqgn+NAbdq0Kf72t7/FbbfdNmTHbG9vjy9+8Yu9Hps+ffqQHZ/TjygwqObNmxcXXHBBQ9vm5uZobj69/xGdNGlSXHvttcN9GpxG/PERw2bv3r0xYcKEiIhYuXJl/vHIihUrIqL/9xSOHj0aS5cujQkTJsSYMWPiyiuvjP379/faRURcf/31MWXKlD7HfKP3KTZu3BizZ8+Os846K8aPHx/XXHNNPP/88/nzl1xySfz617+Offv25Xm++vrHjh2Lb37zmzF79uwYO3ZstLa2xsUXXxzbt2/vc5yurq549tln45VXXhnw79OxY8fi8OHDA34+vBWn93+GMeh6enri3//+d6/HarVanH322TFhwoS4995747Of/Wx0dnbGwoULIyLi/PPPf8PXu/HGG2Pjxo2xePHimDNnTmzbti3mz5//ls5x1apV8Y1vfCOuvvrquPHGG+OFF16IH/7wh/HRj340nnrqqRg3blx87Wtfi56enti/f398//vfj4iI0aNHR0TESy+9FD/5yU9i0aJFcdNNN8XBgwfj/vvvj8svvzz+9Kc/RXt7ex7r9ttvjwceeCD27NnTb7Reb9u2bTFq1Kg4ceJETJ48OZYuXRq33nrrW/r1wklVMAjWr19fRUS/f5155pn5vBdeeKGKiGr58uV9XmP58uXVa/8Rffrpp6uIqD73uc/1et7ixYv7vMZ1111XTZ48+U1fc+/evVVTU1O1atWqXs/761//WjU3N/d6fP78+f2+5vHjx6ujR4/2euzFF1+szjnnnOqGG27o9fh1111XRUS1Z8+ePq/zeh0dHdV3vvOd6he/+EV1//33VxdffHEVEdWXv/zlN91Co1wpMKjuueeePm+MNjU1NfRav/nNbyIiYsmSJb0ev+2222LTpk0NveaWLVuiXq/H1Vdf3euKZuLEiXHuuefG9u3b44477jjpazQ1NeWvqV6vR3d3d9Tr9bjgggviySef7PXcDRs2xIYNGwZ0blu3bu31409+8pMxb968uPvuu+Pzn/98vO997xvQ60AJUWBQXXTRRQ2/0fx6+/btizPOOCPa2tp6PT5jxoyGX/Pvf/97VFUV5557br8//653vWtAr/PAAw/EmjVr+rxf0N8nrxpVq9Vi6dKl8dhjj8WOHTu8Ac2gEAVGpDf6prcTJ070+nG9Xo9arRaPPvpov1cwr75vcDIbN26M66+/PhYsWBDLli2L9773vdHU1BTf/va347nnnmvsF/AG3v/+90dExIEDB97W14VXiQLDquQ7lidPnhz1ej2ee+65XlcHu3fv7vPc97znPdHd3d3n8X379vX6cVtbW1RVFVOnTn3Tz/+/0bk++OCDMW3atNiyZUuv5yxfvvykr9eIf/7znxER+akteLv5SCrDatSoURER/X4Bf7158+ZFRMTatWt7Pd7fdxm3tbVFT09P/OUvf8nHurq64uGHH+71vIULF0ZTU1OsXLkyqqrq9XNVVcV//vOf/HFra2v09PT0OdarVxiv3e/cuTP+8Ic/9HnuQD+SeuDAgT5XNa+88krcdddd0dLSEpdeeulJ99AoVwoMqkcffTSeffbZPo/PmTMnpk2bFmeddVbMnDkzNm/eHNOnT4/x48fHrFmzYtasWX027e3tsWjRovjxj38cPT09MWfOnPjtb38b//jHP/o895prromvfOUr0dnZGUuWLIkjR47EvffeG9OnT+/15m9bW1vceeedcfvtt8fevXtjwYIFMWbMmNizZ088/PDD8elPfzq+9KUvRUTE7NmzY/PmzfGFL3whLrzwwhg9enR0dHTEFVdcEVu2bInOzs6YP39+7NmzJ+67776YOXNmHDp0qNd5DfQjqVu3bo0777wzrrrqqpg6dWocOHAgv6N69erVMXHixIH+LYAyw/rZJ0ask30kNSKq9evX53OfeOKJavbs2VVLS0uvj5a+/uOjVVVVL7/8crVkyZLq7LPPrlpbW6uOjo7q+eef7/djrY8//ng1a9asqqWlpZoxY0a1cePGfl+zqqrqoYcequbOnVu1trZWra2t1XnnnVfdfPPN1e7du/M5hw4dqhYvXlyNGzeuioj8eGq9Xq9Wr15dTZ48uTrzzDOrD3/4w9UjjzzS78diB/qR1F27dlUdHR3VpEmTqpaWlmr06NHV3Llzq5///Ocn3cFbVauq110zwztQrVaL5cuX9/quZqCc9xQASKIAQBIFAJJPHzEieGsM3h6uFABIogBAGvAfH/kfqAO8sw3kj1ldKQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQmof7BODNNDU1FW/Gjh07CGfy9rjlllsa2o0aNap4M2PGjOLNzTffXLz53ve+V7xZtGhR8SYi4r///W/x5q677irerFy5sngzErhSACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAckO8EeYDH/hA8aalpaV4M2fOnOLN3LlzizcREePGjSvefOITn2joWCPN/v37izdr164t3nR2dhZvDh48WLyJiPjzn/9cvPnd737X0LFOR64UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQalVVVQN6Yq022OfCa7S3tze027ZtW/Fm7NixDR2LoVWv14s3N9xwQ/Hm0KFDxZtGdHV1NbR78cUXize7d+9u6FgjzUC+3LtSACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkruknqLGjx/f0G7nzp3Fm2nTpjV0rJGmkd+77u7u4s2ll15avImIOHbsWPHGHXB5LXdJBaCIKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApObhPgH6d+DAgYZ2y5YtK95cccUVxZunnnqqeLN27driTaOefvrp4s1ll11WvDl8+HDx5kMf+lDxJiLi1ltvbWgHJVwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAg1aqqqgb0xFptsM+FYfLud7+7eHPw4MHizbp164o3ERGf+tSnijfXXntt8eZnP/tZ8QbeSQby5d6VAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUvNwnwDD76WXXhqS4/T09AzJcSIibrrppuLN5s2bizf1er14A6cyVwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAECqVVVVDeiJtdpgnwsjXGtra0O7X/3qV8Wbj33sY8WbefPmFW8ef/zx4g0Ml4F8uXelAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA5IZ4nPLa2tqKN08++WTxpru7u3izffv24s2uXbuKNxER99xzT/FmgP96c5pwQzwAiogCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEByQzxGpM7OzuLN+vXrizdjxowp3jTqjjvuKN789Kc/Ld50dXUVb3hncEM8AIqIAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAckM8+H+zZs0q3tx9993Fm49//OPFm0atW7eueLNq1arizb/+9a/iDUPPDfEAKCIKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJDfHgLRg3blzxpqOjo6FjrV+/vnjTyL+327ZtK95cdtllxRuGnhviAVBEFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkNwlFd4hjh49Wrxpbm4u3hw/frx4c/nllxdvduzYUbzhrXGXVACKiAIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQCq/WxaMUOeff37x5qqrrireXHjhhcWbiMZubteIZ555pnjz+9//fhDOhOHgSgGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAMkN8TjlzZgxo3hzyy23FG8WLlxYvJk4cWLxZiidOHGieNPV1VW8qdfrxRtOTa4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQ3BCPhjRyI7hFixY1dKxGbm43ZcqUho51Ktu1a1fxZtWqVcWbrVu3Fm8YOVwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAguSHeCHPOOecUb2bOnFm8+dGPflS8Oe+884o3p7qdO3cWb7773e82dKxf/vKXxZt6vd7QsTh9uVIAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSu6QOgfHjxxdv1q1b19Cx2tvbizfTpk1r6FinsieeeKJ4s2bNmuLNY489Vrx5+eWXizcwVFwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgndY3xPvIRz5SvFm2bFnx5qKLLireTJo0qXhzqjty5EhDu7Vr1xZvVq9eXbw5fPhw8QZGGlcKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIp/UN8To7O4dkM5SeeeaZ4s0jjzxSvDl+/HjxZs2aNcWbiIju7u6GdkA5VwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEi1qqqqAT2xVhvscwFgEA3ky70rBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEjNA31iVVWDeR4AnAJcKQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQ/gdraDactSFS3gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de la imagen: (28, 28)\n",
            "Valor mínimo en la imagen: 0\n",
            "Valor máximo en la imagen: 255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código explora en detalle el contenido de un ejemplo del dataset. En primer lugar, se utiliza `imshow()` de la biblioteca `matplotlib` para representar visualmente la primera imagen del conjunto de entrenamiento (`training_images[0]`). La opción `cmap=\"gray\"` indica que se debe utilizar una escala de grises, adecuada para imágenes donde cada píxel representa una intensidad luminosa. El título de la imagen se establece con la etiqueta correspondiente (`training_labels[0]`), lo que permite comprobar visualmente si el contenido de la imagen coincide con la categoría indicada. La función `axis(\"off\")` oculta los ejes para mejorar la visualización, y `show()` muestra la imagen renderizada.\n",
        "\n",
        "A continuación, se muestra el tamaño de la imagen mediante `shape`, lo que permite verificar que cada ejemplo del dataset es una matriz de **28x28** píxeles. Esto indica que cada imagen está compuesta por 784 valores individuales que codifican la información visual del dígito.\n",
        "\n",
        "Por último, se examinan los valores mínimo y máximo de la matriz utilizando los métodos `.min()` y `.max()` aplicados directamente sobre el array de la imagen. Esta comprobación permite identificar el rango de intensidades de los píxeles, que en este caso va de **0 a 255**. En esta escala, el valor 0 representa el negro absoluto, el 255 el blanco absoluto y los valores intermedios distintos niveles de gris que, en conjunto, forman la imagen del dígito manuscrito."
      ],
      "metadata": {
        "id": "Q1w5GRCIt-9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.2 `training_labels`"
      ],
      "metadata": {
        "id": "Klac1Cs7t-vc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W5rzaGxwmMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23d36ab-18b3-48ed-ece8-630dd4364982"
      },
      "source": [
        "# Mostramos la primera etiqueta\n",
        "print(\"Etiqueta asociada a la primera imagen:\", training_labels[0])\n",
        "\n",
        "# Mostramos el valor mínimo y máximo de las etiquetas\n",
        "print(\"Valor mínimo en las etiquetas:\", np.min(training_labels))\n",
        "print(\"Valor máximo en las etiquetas:\", np.max(training_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiqueta asociada a la primera imagen: 5\n",
            "Valor mínimo en las etiquetas: 0\n",
            "Valor máximo en las etiquetas: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaEWKFyvwmMm"
      },
      "source": [
        "Este fragmento de código permite explorar el contenido de la variable que almacena las etiquetas del conjunto de entrenamiento (`training_labels`). En primer lugar, se imprime el valor de la primera etiqueta, que ya se había mostrado en el título de la imagen representada anteriormente. Esta etiqueta indica el dígito manuscrito al que corresponde la imagen situada en la misma posición dentro del array de entrenamiento.\n",
        "\n",
        "A continuación, se aplican los métodos `.min()` y `.max()` para obtener el valor mínimo y el máximo presentes en el conjunto completo de etiquetas. Esta comprobación permite confirmar que **todas las clases están comprendidas entre 0 y 9**, lo cual es coherente con la estructura del dataset MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.3 Conclusiones\n",
        "\n",
        "Cada ejemplo del dataset está compuesto por una imagen en escala de grises de 28x28 píxeles, que representa un dígito manuscrito, y una etiqueta numérica asociada que indica el valor del dígito mostrado. La exploración realizada ha permitido comprobar que las imágenes contienen valores de intensidad entre 0 y 255, y que las etiquetas abarcan los diez dígitos posibles, de 0 a 9, lo que confirma que el conjunto de datos es adecuado para una tarea de clasificación multiclase."
      ],
      "metadata": {
        "id": "262gM7-Oxao1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Normalización y preprocesado de los datos"
      ],
      "metadata": {
        "id": "OXWLSFdnwAay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pregunta 2.1\n",
        "\n",
        "Habreis notado que todos los valores numericos están entre 0 y 255. Si estamos entrenando una red neuronal, una buena practica es transformar todos los valores entre 0 y 1, un proceso llamado \"normalización\" y afortunadamente en Python es fácil normalizar una lista. ¿Cómo lo podemos hacer?"
      ],
      "metadata": {
        "id": "H9W9mgi7wUOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A priori, podría parecer que aplicar un `MinMaxScaler` sería suficiente para normalizar los datos al rango [0, 1]. Sin embargo, este enfoque no es tan directo cuando se trabaja con imágenes representadas como matrices, ya que `MinMaxScaler` interpreta la estructura 2D como un conjunto de filas independientes y aplica la normalización de manera separada a cada una de ellas. Esto altera las proporciones globales de intensidad en la imagen y modifica su distribución original, lo que puede afectar negativamente al entrenamiento de una red neuronal.\n",
        "\n",
        "Si se deseara utilizar `MinMaxScaler` sin perder la coherencia de las intensidades relativas entre píxeles, sería necesario seguir estos pasos:\n",
        "\n",
        "1. **Aplanar la imagen**: convertir la matriz de tamaño (28, 28) en un vector columna con forma (784, 1), de modo que todos los píxeles sean tratados como un único conjunto de datos.\n",
        "2. **Aplicar `MinMaxScaler`** sobre ese vector, de forma que la normalización se realizase considerando el valor mínimo y máximo global de toda la imagen.\n",
        "3. **Restaurar la forma original**: transformar nuevamente el vector normalizado a una matriz de (28, 28) para conservar la estructura espacial de la imagen.\n",
        "\n",
        "Este procedimiento garantizaría una normalización correcta, pero resulta más complejo y menos eficiente, especialmente cuando se trabaja con grandes volúmenes de imágenes.\n",
        "\n",
        "Una forma más sencilla, eficiente y estandarizada en el contexto del *deep learning* es **dividir directamente cada valor de píxel entre 255**, ya que se conoce de antemano que los valores están en el rango [0, 255]. Este método no requiere modificar la forma de los datos, conserva las proporciones originales entre intensidades y es totalmente compatible con las redes neuronales implementadas en Keras y TensorFlow."
      ],
      "metadata": {
        "id": "SU-zccVI0DVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizamos de los datos escalando cada valor de píxel al rango [0, 1]\n",
        "norm_training_images = training_images / 255.0\n",
        "norm_test_images = test_images / 255.0\n",
        "\n",
        "# Mostramos la imagen original y la normalizada\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(training_images[0], cmap=\"gray\")\n",
        "plt.title(\"Imagen original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(norm_training_images[0], cmap=\"gray\")\n",
        "plt.title(\"Imagen normalizada\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Mostramos el rango de valores tras la normalización\n",
        "print(\"Valor mínimo tras división:\", norm_training_images.min())\n",
        "print(\"Valor máximo tras división:\", norm_training_images.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "-9jT8Y5g1gbX",
        "outputId": "661020c7-2c26-4107-95fb-d5085928f971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor mínimo tras división: 0.0\n",
            "Valor máximo tras división: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento de código realiza la normalización de los datos, transformando los valores de los píxeles del rango original [0, 255] al rango [0, 1]. Para ello, se divide cada valor del conjunto de entrenamiento y de test entre 255.0, almacenando los resultados en las variables `norm_training_images` y `norm_test_images`. De este modo, se conserva la estructura original de los datos sin sobrescribir las variables iniciales, lo que permite mantener una referencia directa a las imágenes sin normalizar si fuera necesario.\n",
        "\n",
        "A continuación, se comparan visualmente la imagen original y la imagen normalizada utilizando `matplotlib`. Se representan en una figura de dos columnas, con títulos diferenciados para facilitar su identificación. Aunque visualmente ambas imágenes puedan parecer iguales, los valores internos han sido escalados, lo cual se confirma mediante la impresión de los valores mínimo y máximo presentes en el conjunto normalizado. El resultado muestra que los valores ahora se encuentran efectivamente en el intervalo [0, 1], lo que garantiza que el preprocesamiento ha sido aplicado correctamente."
      ],
      "metadata": {
        "id": "q6ijRcCK5uoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pregunta 2.2\n",
        "\n",
        "Utiliza la función ***reshape*** de Numpy para convertir las imágenes en vectores de características de un tamaño de (N, 784). Explica con tus palabras por qué es necesario hacer esto.\n",
        "\n"
      ],
      "metadata": {
        "id": "aAj9bKbJxDoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta etapa, es necesario preparar los datos para que puedan ser procesados por una [red neuronal totalmente conectada (*fully connected*)](https://jacar.es/la-red-neuronal-totalmente-conectada-un-enfoque-innovador-en-el-aprendizaje-automatico/). Este tipo de arquitectura no trabaja con matrices bidimensionales, sino con vectores unidimensionales donde cada elemento representa una característica de entrada. Por tanto, para poder utilizar estas imágenes como entradas del modelo, debemos **convertir cada imagen 28x28 en un vector de 784 elementos**.\n",
        "\n",
        "La función `reshape` de NumPy permite realizar esta transformación sin alterar los valores del array original. Específicamente, se cambia la forma del conjunto de imágenes de `(N, 28, 28)` a `(N, 784)`, donde `N` es el número total de imágenes. Esta operación reorganiza los datos internos para que cada imagen, antes representada como una matriz de píxeles, pase a estar representada como un vector plano con la misma información.\n",
        "\n",
        "No obstante, cuando se construye el modelo en Keras, existe una capa llamada `Flatten` que cumple esta misma función de forma automática. Al incluir `Flatten(input_shape=(28, 28))` como primera capa del modelo, se encarga internamente de aplanar cada imagen al formato requerido, evitando así la necesidad de aplicar `reshape` manualmente sobre los datos antes del entrenamiento. De este modo, se preserva la estructura original del dataset y se simplifica el flujo de preprocesamiento.\n",
        "\n",
        "Por motivos didácticos, en esta actividad utilizaremos `reshape` para observar cómo se realiza el aplanamiento de forma manual y comprender mejor el formato que requieren las capas densas cuando no se emplea `Flatten` dentro del modelo."
      ],
      "metadata": {
        "id": "Y9_kIC_yZhiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_training = norm_training_images.reshape(norm_training_images.shape[0], 784)\n",
        "vector_test = norm_test_images.reshape(norm_test_images.shape[0], 784)"
      ],
      "metadata": {
        "id": "qRdZBcCKxvLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este fragmento de código se aplica el método `reshape` de NumPy para reorganizar la forma de los arrays `norm_training_images` y `norm_test_images`. Ambos tienen inicialmente una estructura tridimensional de la forma `(N, 28, 28)`, donde `N` representa el número de imágenes. Al aplicar `reshape(norm_training_images.shape[0], 784)`, se transforma cada imagen en un vector unidimensional de 784 elementos, resultando en un nuevo array de forma `(N, 784)`. Esta operación no modifica los valores internos, únicamente cambia su disposición para adaptarlos al formato que espera la red neuronal."
      ],
      "metadata": {
        "id": "LCIZJRjWxwrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pregunta 2.3\n",
        "\n",
        "Para facilitar el desarrollo de la actividad, vamos a expresar las etiquetas así:"
      ],
      "metadata": {
        "id": "VUJ9BpFSyR3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_labels_onehot = tf.keras.utils.to_categorical(training_labels)\n",
        "test_labels_onehot = tf.keras.utils.to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "jwgU9vScyZy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento de código transforma las etiquetas de entrenamiento y de test mediante la función `to_categorical()` de Keras. Originalmente, las etiquetas son valores enteros entre 0 y 9 que indican la clase a la que pertenece cada imagen. La función `to_categorical()` convierte estos valores en vectores **one-hot**, es decir, vectores de longitud 10 donde la posición correspondiente a la clase tiene un 1 y el resto son ceros.\n",
        "\n",
        "Por ejemplo, una etiqueta con valor 3 se transforma en el vector `[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]`. Este formato permite representar explícitamente cada clase como un vector binario con una única posición activada."
      ],
      "metadata": {
        "id": "AaPGv7lIe8UN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestra cómo son ahora los datos, como resultado de este cambio y también de los realizados en las dos preguntas anteriores. Debate cómo se beneficiará la red neuronal de todos estos cambios."
      ],
      "metadata": {
        "id": "itJBwG0Lyy2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras los cambios realizados en los pasos anteriores, los datos han pasado por tres transformaciones fundamentales:\n",
        "\n",
        "1. **Normalización de las imágenes**: Las imágenes originales contenían valores enteros entre 0 y 255. Tras dividir cada píxel por 255, ahora todas las intensidades están en el rango `[0, 1]`.\n"
      ],
      "metadata": {
        "id": "6HRXB3xthlfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Rango de valores originales: [{training_images.min()}, {training_images.max()}]\")\n",
        "print(f\"Rango de valores normalizados: [{norm_training_images.min()}, {norm_training_images.max()}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moJeGg3siHfI",
        "outputId": "0d6f92f6-6a20-4eb4-b44e-0d6a1b4999fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rango de valores originales: [0, 255]\n",
            "Rango de valores normalizados: [0.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Reestructuración de las imágenes a vectores**: Cada imagen, originalmente de tamaño 28x28, ha sido convertida en un vector de 784 elementos mediante `reshape`."
      ],
      "metadata": {
        "id": "L3ZDCmt0iGjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Forma del conjunto de entrenamiento:\", vector_training.shape)\n",
        "print(\"Forma del conjunto de test:\", vector_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqxh4Wxoiinq",
        "outputId": "ae0d7002-9f98-42f3-a0bc-9bbefefddc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma del conjunto de entrenamiento: (60000, 784)\n",
            "Forma del conjunto de test: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Codificación one-hot de las etiquetas**: Las etiquetas, que antes eran números enteros (por ejemplo, `3`), ahora son vectores de 10 posiciones con una única posición activada."
      ],
      "metadata": {
        "id": "DaOjSV4pivLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Etiqueta original: {training_labels[0]}\")\n",
        "print(f\"Etiqueta codificada: {training_labels_onehot[0]}\")\n",
        "print(\"Forma de las etiquetas originales:\", training_labels.shape)\n",
        "print(\"Forma de las etiquetas codificadas:\", training_labels_onehot.shape)"
      ],
      "metadata": {
        "id": "J0h1cc3CzJfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec85413-1659-4479-9fbf-b93ff082565f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiqueta original: 5\n",
            "Etiqueta codificada: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "Forma de las etiquetas originales: (60000,)\n",
            "Forma de las etiquetas codificadas: (60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estas tres transformaciones preparan los datos para que puedan ser procesados correctamente y de forma eficiente por una red neuronal:\n",
        "\n",
        "- La **normalización** garantiza que los valores de entrada estén en un rango homogéneo, acelerando así el aprendizaje y evitando problemas de desajuste entre escalas.\n",
        "- El **aplanamiento** de las imágenes permite alimentar correctamente las capas densas, que no pueden operar con estructuras bidimensionales.\n",
        "- La **codificación one-hot** de las etiquetas es necesaria porque se trata de una clasificación multiclase y se utilizará una capa de salida `softmax`."
      ],
      "metadata": {
        "id": "-f99ewYui9WM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Creación del Modelo"
      ],
      "metadata": {
        "id": "dI3IAhOQ8zHi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYUWWsszMAKt"
      },
      "source": [
        "Ahora vamos a definir el modelo, pero antes vamos a repasar algunos comandos y conceptos muy útiles:\n",
        "- **`Sequential`**: Eso define una SECUENCIA de capas en la red neuronal\n",
        "- **`Dense`**: Añade una capa de neuronas\n",
        "- **`Flatten`**: ¿Recuerdas cómo eran las imágenes cuando las imprimiste para poder verlas? Un cuadrado, Flatten toma ese cuadrado y lo convierte en un vector de una dimensión.\n",
        "\n",
        "Cada capa de neuronas necesita una función de activación. Normalmente se usa la función relu en las capas intermedias y softmax en la ultima capa (en problemas de clasificación de más de dos items)\n",
        "- **Relu** significa que:$$ f(x) = \\left\\{\\begin{matrix} {x} & {si\\ x > 0} \\\\ {0} & {si\\ x \\leq 0}  \\end{matrix}\\right.\n",
        "$$\n",
        "\n",
        "  Lo que hace es pasar sólo valores 0 o mayores a la siguiente capa de la red.\n",
        "\n",
        "- **`Softmax`** toma un conjunto de valores, y escoge el más grande."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgBW1yE2MwPp"
      },
      "source": [
        "### Pregunta 3.1\n",
        "\n",
        "Utilizando Keras, y preparando los datos de X e Y como fuera necesario, define y entrena una red neuronal que sea capaz de clasificar imágenes de MNIST con las siguientes características:\n",
        "\n",
        "* Una capa de entrada del tamaño adecuado.\n",
        "* Una capa oculta de 512 neuronas.\n",
        "* Una capa final con 10 salidas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTaD2QXIORwu"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model.add(Flatten())\n",
        "\n",
        "# Añadimos una capa oculta densa con 512 neuronas y activación ReLU\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este bloque de código define la arquitectura de una red neuronal secuencial compuesta por tres capas. En primer lugar, se utiliza la capa `Flatten` para transformar las imágenes de entrada de tamaño `(28, 28)` en vectores de 784 elementos.\n",
        "\n",
        "A continuación, se añade una capa oculta `Dense` con 512 neuronas y función de activación `relu`. Esta función permite introducir no linealidad en el modelo, ya que solo transmite los valores positivos y anula los negativos.\n",
        "\n",
        "Por último, se incorpora una capa de salida `Dense` con 10 neuronas, correspondiente al número de clases del problema (dígitos del 0 al 9), utilizando la activación `softmax`. Esta función convierte la salida en un vector de probabilidades, donde cada valor representa la probabilidad de que la imagen pertenezca a una clase concreta. De esta forma, el modelo puede emitir una predicción multiclase a partir de los datos de entrada."
      ],
      "metadata": {
        "id": "a1VDZ6Jpq72a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxr5hTKYOQnK"
      },
      "source": [
        "### Pregunta 3.2\n",
        "\n",
        "¿Crees conveniente utilizar una capa flatten en este caso? Motiva tu respuesta.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque en la pregunta 2.2 utilizamos `reshape` para aplanar manualmente las imágenes y adaptarlas al formato requerido por las capas densas, es mucho más adecuado aprovechar la capa `Flatten` de Keras. Esta capa realiza la misma transformación de forma interna dentro del modelo, manteniendo el flujo de procesamiento integrado y evitando modificar los datos originales fuera del modelo. Además, mejora la legibilidad del código y facilita la reutilización del pipeline en otros contextos sin depender de preprocesamiento externo."
      ],
      "metadata": {
        "id": "e3eQZt34sBpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pregunta 3.3\n",
        "\n",
        "Utiliza la función `summary()` para mostrar la estructura de tu modelo."
      ],
      "metadata": {
        "id": "QFVEWNBV1WnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "YQpJ-DW61lOO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "cfc6b9ac-35cf-4589-a076-454b11d7800d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función `model.summary()` proporciona una descripción estructurada del modelo definido con Keras. Al ejecutarla, se muestra una tabla con información detallada de cada capa, incluyendo su tipo, la forma de salida que produce (`Output Shape`) y el número total de parámetros que contiene.\n",
        "\n",
        "En este caso, el modelo se compone de tres capas:\n",
        "\n",
        "1. La primera capa es `Flatten`, que transforma las imágenes de entrada de tamaño `(28, 28)` en vectores de 784 elementos. No tiene parámetros entrenables, ya que únicamente reorganiza los datos.\n",
        "\n",
        "2. La segunda capa es `Dense` con 512 neuronas y activación `relu`. Su salida tiene forma `(None, 512)`, donde `None` representa el tamaño variable del lote (*batch*). Esta capa tiene 401.920 parámetros entrenables, que se corresponden con:\n",
        "\n",
        "   - 784 pesos por cada una de las 512 neuronas → $784 \\times 512 = 401.408$\n",
        "   - 512 términos de sesgo (*bias*) → $512$\n",
        "   - Total: $401.408 + 512 = 401.920$\n",
        "\n",
        "3. La tercera capa es otra `Dense`, esta vez con 10 neuronas, correspondiente a las 10 clases del problema, y utiliza activación `softmax`. Tiene 5.130 parámetros entrenables:\n",
        "\n",
        "   - 512 pesos por cada una de las 10 neuronas → $512 \\times 10 = 5.120$\n",
        "   - 10 términos de sesgo → $10$\n",
        "   - Total: $5.120 + 10 = 5.130$\n",
        "\n",
        "Finalmente, el resumen muestra que el modelo tiene un total de **407.050 parámetros entrenables**, lo que corresponde al número total de pesos y sesgos que serán optimizados durante el proceso de entrenamiento. No hay parámetros no entrenables en este modelo.\n",
        "\n",
        "Esta información es útil para verificar que la estructura del modelo es la esperada antes de compilar y entrenar."
      ],
      "metadata": {
        "id": "b4SX3orRu14F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Compilación y entrenamiento"
      ],
      "metadata": {
        "id": "nco-l8vx1Kzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pregunta 4.1\n",
        "\n",
        "**Compila tu modelo**: Utiliza **`categorical_crossentropy`** como función de pérdida, **`Adam`** como optimizador, y monitoriza la **tasa de acierto** durante el entrenamiento. Explica qué hace cada cosa en la compilación."
      ],
      "metadata": {
        "id": "myZQUTCn1yD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En problemas de clasificación multiclase existen dos formas comunes de representar las etiquetas: como enteros (por ejemplo, `3`) o como vectores *one-hot* (por ejemplo, `[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]`). En la pregunta 2.3, transformamos las etiquetas mediante `to_categorical()`, por lo que ahora se encuentran en formato *one-hot*.\n",
        "\n",
        "Si las etiquetas se mantuvieran como enteros, podríamos utilizar directamente la función de pérdida `sparse_categorical_crossentropy`, que internamente las convierte en *one-hot* durante el cálculo. Sin embargo, dado que en nuestro caso ya hemos realizado explícitamente esta transformación, debemos utilizar la función `categorical_crossentropy`.\n",
        "\n",
        "Esta función compara el vector de salida generado por la red (una distribución de probabilidad obtenida mediante `softmax`) con la etiqueta esperada en formato *one-hot*. Calcula la diferencia entre ambas distribuciones usando el concepto de entropía cruzada, penalizando con mayor intensidad aquellas predicciones que se alejan del valor correcto. El objetivo del entrenamiento será minimizar esta pérdida, haciendo que la probabilidad asignada a la clase correcta se aproxime a 1 y las demás tiendan a 0."
      ],
      "metadata": {
        "id": "OA9wt5ICxafK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "I_CPQN9p2a7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento compila el modelo definiendo tres elementos:\n",
        "\n",
        "- El optimizador `Adam`, que ajusta los pesos del modelo durante el entrenamiento\n",
        "- La función de pérdida `categorical_crossentropy`, adecuada para problemas multiclase con etiquetas en formato *one-hot*\n",
        "- La métrica `accuracy`, que permite evaluar el porcentaje de predicciones correctas en cada época (*epoch*)."
      ],
      "metadata": {
        "id": "1Yad_BAvxbHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pregunta 4.2\n",
        "\n",
        "Utiliza la función **`fit()`** para entrenar tu modelo. Para ayudarte en tu primer entrenamiento, utiliza estos valores:\n",
        "\n",
        "- epochs = 5\n",
        "- batch_size = 32\n",
        "- validation_split = 0.25"
      ],
      "metadata": {
        "id": "f7KSdoEr2rLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo utilizando las imágenes normalizadas y las etiquetas codificadas\n",
        "training_history = model.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "yytNVJf33WFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd57900a-be8b-4c27-f12d-bd6764a7c068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8866 - loss: 0.3864 - val_accuracy: 0.9605 - val_loss: 0.1289\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.1031 - val_accuracy: 0.9703 - val_loss: 0.0981\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0602 - val_accuracy: 0.9724 - val_loss: 0.0927\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0372 - val_accuracy: 0.9746 - val_loss: 0.0926\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0226 - val_accuracy: 0.9741 - val_loss: 0.1023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código entrena el modelo utilizando las imágenes normalizadas y las etiquetas codificadas en formato *one-hot*. La función `fit()` recorre el conjunto de entrenamiento durante 5 épocas, dividiendo los datos en bloques de 32 muestras (*batch\\_size*) para actualizar los pesos en cada iteración. Además, se reserva el 25% del conjunto de entrenamiento como conjunto de validación, lo que permite evaluar el rendimiento del modelo sobre datos no vistos durante el ajuste. La opción `verbose=1` activa el registro detallado del proceso, mostrando en pantalla la pérdida y la precisión al final de cada época. Todos los resultados quedan almacenados en la variable `training_history`, que registra la evolución de las métricas a lo largo del entrenamiento."
      ],
      "metadata": {
        "id": "rldjYk21zPWT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiQ8qAzhRQ4L"
      },
      "source": [
        "## 5. Impacto al variar el número de neuronas en las capas ocultas\n",
        "\n",
        "En este ejercicio vamos a experimentar con nuestra red neuronal cambiando el numero de neuronas por 256 y por otros valores. Para ello, utiliza la red neuronal de la pregunta 3, y su capa oculta cambia el número de neuronas:\n",
        "\n",
        "* **256 neuronas en la capa oculta**.\n",
        "* **1024 neuronas en la capa oculta**.\n",
        "\n",
        "y entrena la red en ambos casos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para responder a las siguientes preguntas, se utilizarán los mismos parámetros empleados en el modelo definido en la **pregunta 3**, tanto en la estructura general como en la compilación y el entrenamiento. La única diferencia será el número de neuronas en la capa oculta, lo que permitirá comparar de forma controlada cómo influye este parámetro en el rendimiento del modelo.\n"
      ],
      "metadata": {
        "id": "gm4ATHY1-mz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo de 256 neuronas"
      ],
      "metadata": {
        "id": "v5ycubu-8MOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "8YY8vFGM9Wg-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdP8ZwuaUV93"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_256 = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_256.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_256.add(Flatten())\n",
        "\n",
        "# Añadimos una capa oculta densa con 256 neuronas y activación ReLU\n",
        "model_256.add(Dense(256, activation=\"relu\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_256.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "IDINFUoK-QI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_256.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "jdxAKQbb-Sdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "1wOxodKk9bfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_256 = model_256.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqvsgyS39i89",
        "outputId": "cad1ca3d-1d46-4783-deb7-340f81f70eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8734 - loss: 0.4395 - val_accuracy: 0.9574 - val_loss: 0.1450\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9633 - loss: 0.1233 - val_accuracy: 0.9667 - val_loss: 0.1091\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.0765 - val_accuracy: 0.9706 - val_loss: 0.0983\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9854 - loss: 0.0517 - val_accuracy: 0.9721 - val_loss: 0.0980\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0337 - val_accuracy: 0.9723 - val_loss: 0.1011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo de 1024 neuronas en la capa oculta:"
      ],
      "metadata": {
        "id": "KjDsw0Gt8NL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "-2MNFA_kBKOH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXBlbbfuUaPa"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_1024 = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_1024.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_1024.add(Flatten())\n",
        "\n",
        "# Añadimos una capa oculta densa con 1024 neuronas y activación ReLU\n",
        "model_1024.add(Dense(1024, activation=\"relu\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_1024.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "FzH6n_azBLFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1024.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "p_EARTKYBLra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "scrqTVxKBMCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_1024 = model_1024.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0125un0KBMaV",
        "outputId": "c60c0096-0547-4292-f081-aebc2cce421f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.8904 - loss: 0.3570 - val_accuracy: 0.9625 - val_loss: 0.1231\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.9726 - loss: 0.0926 - val_accuracy: 0.9710 - val_loss: 0.0952\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.9840 - loss: 0.0526 - val_accuracy: 0.9722 - val_loss: 0.0930\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.9895 - loss: 0.0333 - val_accuracy: 0.9736 - val_loss: 0.1000\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.9926 - loss: 0.0219 - val_accuracy: 0.9725 - val_loss: 0.1092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG0h2HL-Uj93"
      },
      "source": [
        "### Pregunta 5.1\n",
        "\n",
        "¿Cual es el impacto que tiene la red neuronal?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El número de neuronas en la capa oculta influye directamente en el tiempo de entrenamiento, que se incrementa notablemente al aumentar la complejidad del modelo. Aunque los tres modelos alcanzan valores de precisión similares en validación, el modelo con 1024 neuronas requiere más tiempo y muestra una ligera tendencia al sobreajuste. Concretamente, a partir de la tercera época, su pérdida de validación comienza a aumentar, mientras que la precisión apenas mejora. Este efecto no se observa ni en el modelo de 256 ni en el de 512, donde la pérdida sigue disminuyendo o estabilizándose sin deterioro significativo.\n",
        "\n",
        "El modelo con 512 neuronas alcanza una buena precisión más rápidamente y mantiene un equilibrio aceptable entre rendimiento y generalización. En cambio, el modelo de 256 neuronas necesita más épocas para converger y muestra una pérdida algo mayor al inicio, aunque su rendimiento final es muy similar.\n",
        "\n",
        "Por tanto, se observa que a partir de cierto número de neuronas, el incremento de capacidad no se traduce en mejoras significativas, y puede comprometer la generalización. Una configuración intermedia (como 512) ofrece un buen compromiso entre rendimiento, tiempo de entrenamiento y estabilidad del modelo.\n",
        "\n",
        "| Modelo        | Accuracy (train) | Loss (train) | Accuracy (val) | Loss (val) | Tiempo por época |\n",
        "| ------------- | ---------------- | ------------ | -------------- | ---------- | ---------------- |\n",
        "| 256 neuronas  | 0.9906           | 0.0337       | 0.9723         | 0.1011     | \\~10–11 s        |\n",
        "| 512 neuronas  | 0.9937           | 0.0226       | 0.9741         | 0.1023     | \\~16–20 s        |\n",
        "| 1024 neuronas | 0.9926           | 0.0219       | 0.9725         | 0.1092     | \\~22–41 s        |"
      ],
      "metadata": {
        "id": "dv-gPhYxFuR5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37cIr81ZYJj"
      },
      "source": [
        "# 6. Número de neuronas de la capa de salida\n",
        "\n",
        "Consideradndo la capa final, la de salida de la red neuronal de la pregunta 3."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 6.1\n",
        "\n",
        "¿Por qué son 10 las neuronas de la última capa?"
      ],
      "metadata": {
        "id": "DwSPHgXjs-tZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La capa de salida está compuesta por 10 neuronas porque el problema que se está resolviendo es una clasificación multiclase con 10 posibles categorías, correspondientes a los dígitos del 0 al 9. Cada neurona representa una de estas clases, y la activación `softmax` asigna a cada clase una probabilidad de pertenencia, permitiendo que el modelo seleccione la clase con mayor probabilidad como predicción final."
      ],
      "metadata": {
        "id": "ONzo1Mu6qLty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 6.2\n",
        "\n",
        "¿Qué pasaría si tuvieras una cantidad diferente a 10?\n",
        "\n",
        "Por ejemplo, intenta entrenar la red con 5, para ello utiliza la red neuronal de la pregunta 1 y cambia a 5 el número de neuronas en la última capa."
      ],
      "metadata": {
        "id": "kFVTw-PUnhlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A priori, y según lo estudiado en la asignatura, se intuye que si se reduce el número de neuronas en la capa de salida a un valor inferior a 10, como por ejemplo 5, la red neuronal no podrá representar correctamente todas las clases posibles del problema. Limitar la salida a solo 5 neuronas implicaría que varias clases quedarían sin representación, lo que previsiblemente generará un error en el entrenamiento.\n",
        "\n",
        "No obstante, se intentará entrenar la red con 5 neuronas en la capa de salida para comprobar empíricamente cómo responde el modelo ante esta configuración incorrecta."
      ],
      "metadata": {
        "id": "Cd3KJ5JcsOiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "3qd0fdMXttZC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhbZkppYZOCS"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_5out = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_5out.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_5out.add(Flatten())\n",
        "\n",
        "# Añadimos una capa oculta densa con 512 neuronas y activación ReLU\n",
        "model_5out.add(Dense(512, activation=\"relu\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_5out.add(Dense(5, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "wNkS-3P6tvE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5out.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "TU2aRU5HtynL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo\n",
        "\n",
        "\n",
        "```python\n",
        "training_history_5out = model_5out.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")\n",
        "```\n",
        "\n",
        "```shell\n",
        "Epoch 1/5\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "\n",
        "ValueError                                Traceback (most recent call last)\n",
        "\n",
        "<ipython-input-26-edd6b2a3bf81> in <cell line: 0>()\n",
        "----> 1 training_history_5out = model_5out.fit(\n",
        "      2     norm_training_images,  # Datos de entrada normalizados\n",
        "      3     training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "      4     epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "      5     batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "\n",
        "1 frames\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py in categorical_crossentropy(target, output, from_logits, axis)\n",
        "    658     for e1, e2 in zip(target.shape, output.shape):\n",
        "    659         if e1 is not None and e2 is not None and e1 != e2:\n",
        "--> 660             raise ValueError(\n",
        "    661                 \"Arguments `target` and `output` must have the same shape. \"\n",
        "    662                 \"Received: \"\n",
        "\n",
        "ValueError: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 10), output.shape=(None, 5)\n",
        "```"
      ],
      "metadata": {
        "id": "4Ff9u-4vty6t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1f_7ZFeaUu6"
      },
      "source": [
        "Tal como se anticipó, al intentar entrenar el modelo con únicamente 5 neuronas en la capa de salida, el proceso falla con un error. Aunque la definición del modelo y su compilación no presentan inconvenientes, el problema se produce durante el entrenamiento, específicamente al comparar las predicciones del modelo con las etiquetas reales.\n",
        "\n",
        "Por este motivo, el código asociado a este entrenamiento no se ejecuta directamente en el notebook, con el fin de evitar errores de compilación durante la ejecución completa del documento.\n",
        "\n",
        "El error generado es el siguiente:\n",
        "\n",
        "```shell\n",
        "ValueError: Arguments `target` and `output` must have the same shape.\n",
        "Received: target.shape=(None, 10), output.shape=(None, 5)\n",
        "```\n",
        "\n",
        "Esto indica que la red produce vectores de salida con forma `(None, 5)`, es decir, predicciones con solo 5 probabilidades por muestra, mientras que las etiquetas reales (`training_labels_onehot`) tienen forma `(None, 10)`, ya que están codificadas en formato *one-hot* con 10 posiciones, una por cada clase (dígito del 0 al 9).\n",
        "\n",
        "Como resultado, no se puede calcular la función de pérdida `categorical_crossentropy`, que requiere que las dimensiones de salida y de las etiquetas coincidan exactamente. Esto confirma que en una clasificación multiclase, el número de neuronas en la capa de salida debe coincidir con el número de clases a predecir. De lo contrario, el modelo no puede representar todas las categorías posibles ni ajustar sus pesos correctamente durante el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNIBCkshaf2y"
      },
      "source": [
        "# 7. Aumento de epoch y su efecto en la red neuronal\n",
        "\n",
        "En este ejercicio vamos a ver el impacto de aumentar los epoch en el entrenamiento. Usando la red neuronal de la pregunta 3."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 7.1\n",
        "\n",
        "Intenta 15 epoch para su entrenamiento, probablemente obtendras un modelo con una pérdida mucho mejor que el que tiene 5."
      ],
      "metadata": {
        "id": "lm-pAmyfu_3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "SKs-lp0TvnIy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT8SquC-vnI2"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_15epoch = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_15epoch.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_15epoch.add(Flatten())\n",
        "\n",
        "# Añadimos una capa oculta densa con 512 neuronas y activación ReLU\n",
        "model_15epoch.add(Dense(512, activation=\"relu\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_15epoch.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "PUVETvc6vnI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_15epoch.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "xNq6yhq2vnI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "NnQNqK2WvnI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_15epoch = model_15epoch.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=15,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "VZXEBp5zvnI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5643f94-7e57-45f2-c5ae-3d2d609c69b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.8875 - loss: 0.3861 - val_accuracy: 0.9599 - val_loss: 0.1316\n",
            "Epoch 2/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9688 - loss: 0.1043 - val_accuracy: 0.9686 - val_loss: 0.1027\n",
            "Epoch 3/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9827 - loss: 0.0605 - val_accuracy: 0.9729 - val_loss: 0.0947\n",
            "Epoch 4/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9900 - loss: 0.0373 - val_accuracy: 0.9717 - val_loss: 0.0994\n",
            "Epoch 5/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0240 - val_accuracy: 0.9753 - val_loss: 0.0978\n",
            "Epoch 6/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0181 - val_accuracy: 0.9711 - val_loss: 0.1193\n",
            "Epoch 7/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0165 - val_accuracy: 0.9763 - val_loss: 0.1044\n",
            "Epoch 8/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0130 - val_accuracy: 0.9769 - val_loss: 0.1013\n",
            "Epoch 9/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0141 - val_accuracy: 0.9759 - val_loss: 0.1111\n",
            "Epoch 10/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0090 - val_accuracy: 0.9771 - val_loss: 0.1028\n",
            "Epoch 11/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0092 - val_accuracy: 0.9771 - val_loss: 0.1130\n",
            "Epoch 12/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0094 - val_accuracy: 0.9765 - val_loss: 0.1190\n",
            "Epoch 13/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 0.9727 - val_loss: 0.1511\n",
            "Epoch 14/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9747 - val_loss: 0.1321\n",
            "Epoch 15/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.9747 - val_loss: 0.1439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 7.2\n",
        "\n",
        "Intenta ahora con 30 epoch para su entrenamiento."
      ],
      "metadata": {
        "id": "LWVGWiT1vP4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "8z-iBm4Fv6xT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpWtIgypv6xV"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_30epoch = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_30epoch.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_30epoch.add(Flatten())\n",
        "\n",
        "# Añadimos una capa oculta densa con 512 neuronas y activación ReLU\n",
        "model_30epoch.add(Dense(512, activation=\"relu\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_30epoch.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "CTNuFB8vv6xX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_30epoch.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "mWBJoOwWv6xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "gf9GH52pv6xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_30epoch = model_30epoch.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=30,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "2mYvermSv6xZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57dc1068-9ba2-4525-bdc1-97b7e95ee0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.8841 - loss: 0.3893 - val_accuracy: 0.9594 - val_loss: 0.1315\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9694 - loss: 0.1036 - val_accuracy: 0.9681 - val_loss: 0.1026\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.0611 - val_accuracy: 0.9721 - val_loss: 0.0957\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0374 - val_accuracy: 0.9725 - val_loss: 0.0974\n",
            "Epoch 5/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0234 - val_accuracy: 0.9737 - val_loss: 0.0991\n",
            "Epoch 6/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0179 - val_accuracy: 0.9742 - val_loss: 0.1054\n",
            "Epoch 7/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0126 - val_accuracy: 0.9775 - val_loss: 0.0950\n",
            "Epoch 8/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0118 - val_accuracy: 0.9749 - val_loss: 0.1097\n",
            "Epoch 9/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0111 - val_accuracy: 0.9751 - val_loss: 0.1156\n",
            "Epoch 10/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.9947 - loss: 0.0156 - val_accuracy: 0.9764 - val_loss: 0.1161\n",
            "Epoch 11/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.9758 - val_loss: 0.1198\n",
            "Epoch 12/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0071 - val_accuracy: 0.9791 - val_loss: 0.1056\n",
            "Epoch 13/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9721 - val_loss: 0.1592\n",
            "Epoch 14/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0150 - val_accuracy: 0.9780 - val_loss: 0.1193\n",
            "Epoch 15/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0077 - val_accuracy: 0.9756 - val_loss: 0.1312\n",
            "Epoch 16/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.9780 - val_loss: 0.1268\n",
            "Epoch 17/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.9711 - val_loss: 0.1723\n",
            "Epoch 18/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0067 - val_accuracy: 0.9772 - val_loss: 0.1363\n",
            "Epoch 19/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9772 - val_loss: 0.1471\n",
            "Epoch 20/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0086 - val_accuracy: 0.9771 - val_loss: 0.1485\n",
            "Epoch 21/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9766 - val_loss: 0.1544\n",
            "Epoch 22/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.9787 - val_loss: 0.1462\n",
            "Epoch 23/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9735 - val_loss: 0.1811\n",
            "Epoch 24/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9803 - val_loss: 0.1392\n",
            "Epoch 25/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.9780 - val_loss: 0.1487\n",
            "Epoch 26/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9781 - val_loss: 0.1531\n",
            "Epoch 27/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0059 - val_accuracy: 0.9772 - val_loss: 0.1706\n",
            "Epoch 28/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.9780 - val_loss: 0.1638\n",
            "Epoch 29/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9777 - val_loss: 0.1595\n",
            "Epoch 30/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.9769 - val_loss: 0.1800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 7.3\n",
        "\n",
        "¿Qué está pasando en la pregunta anterior? Explica tu respuesta y da el nombre de este efecto si lo conoces."
      ],
      "metadata": {
        "id": "kkE5IEkDvS9y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs0fjzH4bmSR"
      },
      "source": [
        "Al aumentar el número de épocas, el tiempo total de entrenamiento crece de forma proporcional, ya que la red realiza más pasadas completas sobre el conjunto de datos. Esto es esperable, ya que el parámetro `epochs` define cuántas veces se recorre todo el conjunto de entrenamiento.\n",
        "\n",
        "En cuanto al comportamiento del modelo, se observa que durante las primeras épocas se produce una mejora significativa tanto en la pérdida como en la exactitud, especialmente en los datos de entrenamiento. Sin embargo, a partir de cierto punto (aproximadamente la época 10 o 15), la red comienza a especializarse demasiado en los datos que ya ha visto, mientras que el rendimiento en el conjunto de validación deja de mejorar e incluso empeora ligeramente.\n",
        "\n",
        "Este fenómeno es conocido como **sobreajuste** (*overfitting*), y se produce cuando el modelo memoriza patrones específicos del conjunto de entrenamiento en lugar de aprender características generales que puedan aplicarse a nuevos datos. Como resultado, la pérdida de validación aumenta a pesar de que la precisión sobre los datos de entrenamiento sigue mejorando, lo que indica una pérdida de capacidad de generalización.\n",
        "\n",
        "Para observar este comportamiento de forma visual, a continuación se generarán gráficas que muestran la evolución de la precisión y la pérdida en el entrenamiento y en la validación para los modelos entrenados con 15 y 30 épocas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# --------- Gráfico de 15 épocas ---------\n",
        "# Eje izquierdo\n",
        "ax1a = ax1\n",
        "line1, = ax1a.plot(training_history_15epoch.history['accuracy'], label='Train Accuracy', color='blue')\n",
        "line2, = ax1a.plot(training_history_15epoch.history['val_accuracy'], label='Val Accuracy', color='orange')\n",
        "ax1a.set_ylabel('Precisión')\n",
        "ax1a.set_xlabel('Época')\n",
        "ax1a.grid(True)\n",
        "\n",
        "# Eje derecho\n",
        "ax1b = ax1a.twinx()\n",
        "line3, = ax1b.plot(training_history_15epoch.history['val_loss'], label='Val Loss', color='green')\n",
        "ax1b.set_ylabel('Pérdida')\n",
        "\n",
        "# Leyenda conjunta\n",
        "lines = [line1, line2, line3]\n",
        "labels = [line.get_label() for line in lines]\n",
        "ax1a.legend(lines, labels, loc='lower right', bbox_to_anchor=(1.0, 0.0))\n",
        "ax1.set_title('Entrenamiento - 15 épocas')\n",
        "\n",
        "# --------- Gráfico de 30 épocas ---------\n",
        "# Eje izquierdo\n",
        "ax2a = ax2\n",
        "line4, = ax2a.plot(training_history_30epoch.history['accuracy'], label='Train Accuracy', color='blue')\n",
        "line5, = ax2a.plot(training_history_30epoch.history['val_accuracy'], label='Val Accuracy', color='orange')\n",
        "ax2a.set_ylabel('Precisión')\n",
        "ax2a.set_xlabel('Época')\n",
        "ax2a.grid(True)\n",
        "\n",
        "# Eje derecho\n",
        "ax2b = ax2a.twinx()\n",
        "line6, = ax2b.plot(training_history_30epoch.history['val_loss'], label='Val Loss', color='green')\n",
        "ax2b.set_ylabel('Pérdida')\n",
        "\n",
        "# Leyenda conjunta\n",
        "lines2 = [line4, line5, line6]\n",
        "labels2 = [line.get_label() for line in lines2]\n",
        "ax2a.legend(lines2, labels2, loc='lower right', bbox_to_anchor=(1.0, 0.0))\n",
        "ax2.set_title('Entrenamiento - 30 épocas')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4_8jlxU66VGx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "0f43ebe4-e762-4cdf-ba49-7a5d3ae80361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento de código genera una visualización comparativa del proceso de entrenamiento de los dos modelos: uno entrenado durante 15 épocas y otro durante 30. Para ello, se utilizan dos gráficos colocados en paralelo, lo que permite observar claramente cómo evolucionan las métricas principales en cada caso.\n",
        "\n",
        "Se utiliza la función `plt.subplots(1, 2, figsize=(14, 5))` para crear una figura con una fila y dos columnas de gráficos. En cada uno de ellos se representa, en el eje izquierdo, la evolución de la precisión sobre el conjunto de entrenamiento (`accuracy`) y sobre el conjunto de validación (`val_accuracy`). Al mismo tiempo, se añade un segundo eje vertical, superpuesto, para representar la pérdida en validación (`val_loss`), con el fin de no distorsionar la escala de la precisión y poder visualizar ambas métricas simultáneamente.\n",
        "\n",
        "Para cada gráfico se definen tres líneas, que se almacenan en variables específicas para luego construir una leyenda conjunta. Esta leyenda se sitúa en la parte inferior derecha del área de trazado correspondiente mediante `bbox_to_anchor=(1.0, 0.0)`, lo que permite que todas las métricas se identifiquen claramente sin superponerse al contenido del gráfico.\n",
        "\n",
        "Finalmente, se ajusta el espaciado con `plt.tight_layout()` para evitar solapamientos y se muestra la figura con `plt.show()`.\n",
        "\n",
        "La gráfica muestra la evolución del entrenamiento de los modelos, incluyendo las métricas de exactitud (*accuracy*) y pérdida (*loss*) tanto en entrenamiento como en validación.\n",
        "\n",
        "En el entrenamiento de 15 épocas, la exactitud sobre el conjunto de entrenamiento mejora progresivamente hasta rozar el 0.999 en las últimas iteraciones. Sin embargo, el mejor valor de exactitud en validación se alcanza de forma temprana, concretamente en la época 4. A partir de ese punto, no se registran mejoras y la pérdida en validación comienza a incrementarse, señal clara de que el modelo empieza a sobreajustarse, aprendiendo patrones específicos del entrenamiento que no se traducen en un mejor rendimiento sobre datos no vistos.\n",
        "\n",
        "En el caso del entrenamiento de 30 épocas, se observa una dinámica similar. La exactitud en entrenamiento se mantiene elevada desde las primeras épocas. El mejor resultado de exactitud en validación se alcanza en la época 6, con una mejora marginal adicional en torno a la época 12. No obstante, más allá de ese punto no se produce un avance real en el desempeño del modelo sobre el conjunto de validación. La pérdida de validación muestra una variabilidad creciente, con oscilaciones que evidencian inestabilidad en la capacidad de generalización.\n",
        "\n",
        "En conjunto, ambos entrenamientos muestran que la mejora en validación se produce en fases tempranas del proceso y que extender el entrenamiento más allá de las épocas 7–12 no aporta beneficios reales, sino que incrementa el riesgo de sobreajuste. Estos resultados justifican el uso de técnicas como la detención temprana (*early stopping*) para identificar automáticamente el punto de parada óptimo.\n"
      ],
      "metadata": {
        "id": "r2G4lrfd4-Yp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlIgNG4Yb_N6"
      },
      "source": [
        "# 8. Early stop\n",
        "\n",
        "En el ejercicio anterior, cuando entrenabas con epoch extras, tenías un problema en el que tu pérdida podía cambiar. Puede que te haya llevado un poco de tiempo esperar a que el entrenamiento lo hiciera,  y puede que hayas pensado \"¿no estaría bien si pudiera parar el entrenamiento cuando alcance un valor deseado?\", es decir, una precisión del 85% podría ser suficiente para ti, y si alcanzas eso después de 3 epoch, ¿por qué sentarte a esperar a que termine muchas más épocas? Como cualquier otro programa existen formas de parar la ejecución\n",
        "\n",
        "A partir del código de ejemplo, hacer una nueva función que tenga en cuenta la perdida (*loss*) y que pueda parar el código para evitar que ocurra el efeto secundario que vimos en el ejercicio 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5UwceFUG4ic"
      },
      "source": [
        "### Ejemplo de código\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')> 0.85):\n",
        "              print(\"\\nAlcanzado el 85% de precisión, se cancela el entrenamiento!!\")\n",
        "              self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento define una clase personalizada llamada `myCallback`, que hereda de una clase especial de Keras llamada `Callback`, diseñada para ejecutar acciones automáticas durante el entrenamiento del modelo. Su propósito es permitir que el entrenamiento se detenga anticipadamente cuando se cumpla una condición específica. La clase se estructura en cuatro partes:\n",
        "\n",
        "1. **Definición de la clase**: se crea una subclase de `Callback` que puede ser utilizada dentro del entrenamiento del modelo.\n",
        "2. **Función `on_epoch_end()`**: se ejecuta automáticamente al final de cada época y permite evaluar los resultados obtenidos en esa iteración.\n",
        "3. **Consulta de la métrica**: mediante `logs.get('accuracy')`, se accede al valor de precisión del entrenamiento en esa época concreta.\n",
        "4. **Condición de parada**: si la precisión supera el 85%, se imprime un mensaje en pantalla y se activa `self.model.stop_training = True`, que detiene el entrenamiento.\n",
        "\n",
        "Como se comentaba anteriormente, este tipo de funcionalidad es útil para evitar entrenar más de lo necesario, especialmente cuando se alcanza una precisión aceptable mucho antes del número total de épocas definido. Así se reduce el tiempo de entrenamiento y se minimiza el riesgo de sobreajuste.\n",
        "\n",
        "En el codigo que se implementará a continuación, la función se adaptará para que tenga en cuenta la **pérdida de validación (`val_loss`)** en lugar de la pérdida sobre el entrenamiento. Esta métrica refleja de forma más precisa cómo se comporta el modelo frente a datos no vistos, lo que la convierte en una mejor referencia para decidir cuándo detener el entrenamiento. Al monitorizar `val_loss`, se puede identificar el momento en que el modelo deja de mejorar su capacidad de generalización y así evitar continuar con épocas adicionales que solo contribuirían al sobreajuste."
      ],
      "metadata": {
        "id": "hlMbglTEDFgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos una clase personalizada que hereda de Callback\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def __init__(self):\n",
        "    # Al iniciar, establecemos la mejor pérdida como un valor muy alto\n",
        "    self.best_loss = float('inf')\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    current_loss = logs.get('val_loss')  # Obtenemos la pérdida de esta época\n",
        "\n",
        "    # Comprobamos si la pérdida ha aumentado respecto a la mejor registrada\n",
        "    if current_loss > self.best_loss:\n",
        "      print(f\"\\nLa pérdida ha aumentado en la época {epoch+1}, se cancela el entrenamiento.\")\n",
        "      self.model.stop_training = True\n",
        "    else:\n",
        "      # Actualizamos la mejor pérdida si esta es menor\n",
        "      self.best_loss = current_loss"
      ],
      "metadata": {
        "id": "W3HIeqb4DGt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código define una clase personalizada llamada `myCallback`, diseñada para detener automáticamente el entrenamiento cuando la pérdida de validación (`val_loss`) deje de mejorar.\n",
        "\n",
        "En primer lugar, se define el método `__init__()`, que se ejecuta al instanciar la clase. En él se inicializa una variable llamada `best_loss` con un valor extremadamente alto (`float('inf')`), lo que garantiza que cualquier pérdida observada en la primera época será considerada una mejora.\n",
        "\n",
        "Posteriormente, la función `on_epoch_end()` se activa automáticamente al finalizar cada época del entrenamiento. En ella se accede al valor actual de la pérdida de validación mediante `logs.get('val_loss')`.\n",
        "\n",
        "Si este valor es superior a `best_loss`, significa que el modelo ha dejado de mejorar su capacidad de generalización, por lo que se imprime un mensaje informativo indicando que se ha alcanzado este punto, y se detiene el entrenamiento mediante `self.model.stop_training = True`.\n",
        "\n",
        "En caso contrario, se actualiza la variable `best_loss` con la nueva pérdida obtenida, ya que representa un avance en el rendimiento del modelo sobre el conjunto de validación. Este enfoque permite evitar entrenamientos innecesarios y reduce el riesgo de sobreajuste."
      ],
      "metadata": {
        "id": "PpWnH7fuHRkO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bjd8wGKccrn"
      },
      "source": [
        "## Pregunta 8.1.\n",
        "\n",
        "Consulta la documentación de Keras y aprende cómo podemos utilizar Early stop en nuestro modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uso de `EarlyStopping` en Keras\n",
        "\n",
        "Keras proporciona una herramienta integrada llamada `EarlyStopping` que permite **detener el entrenamiento automáticamente cuando una métrica deja de mejorar**. Es especialmente útil para evitar el *overfitting*, ahorrar tiempo de cómputo y simplificar la configuración de entrenamientos largos.\n",
        "\n",
        "Esta clase pertenece al módulo `tensorflow.keras.callbacks`, por lo que antes de usarla es necesario importarla usando el siguiente comando:\n",
        "\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "```"
      ],
      "metadata": {
        "id": "TcrJvMnXKipA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parámetros más importantes de `EarlyStopping`\n",
        "\n",
        "- **`monitor`**: Indica qué métrica se va a observar. Por defecto es `'val_loss'`, pero también puede ser `'val_accuracy'`, `'loss'`, `'accuracy'`, etc.\n",
        "\n",
        "- **`min_delta`**: Valor mínimo de mejora considerado como significativo. Si la mejora entre épocas no supera este valor, no se contará como mejora real. Por defecto es `0.0`.\n",
        "\n",
        "- **`patience`**: Número de épocas consecutivas sin mejora antes de detener el entrenamiento. Ayuda a evitar interrupciones por fluctuaciones puntuales. Por defecto es `0`.\n",
        "\n",
        "- **`verbose`**: Si se establece en `1`, se muestra un mensaje en pantalla cuando el entrenamiento se detiene. Si es `0`, no se muestra nada. Valor por defecto: `0`.\n",
        "\n",
        "- **`mode`**: Indica cómo se interpreta la métrica monitorizada. Puede ser:\n",
        "\n",
        "  - `'min'`: Se busca minimizar la métrica (por ejemplo, `'val_loss'`).\n",
        "  - `'max'`: Se busca maximizar la métrica (por ejemplo, `'val_accuracy'`).\n",
        "  - `'auto'`: Keras selecciona automáticamente `'min'` o `'max'` según el nombre de la métrica.\n",
        "\n",
        "- **`restore_best_weights`**: Si se activa (`True`), al detenerse el entrenamiento, se restaurarán automáticamente los pesos que obtuvieron la mejor puntuación. Esto evita quedarse con los pesos de la última época, que podrían ser peores. Por defecto es `False`."
      ],
      "metadata": {
        "id": "hJWM84iIKwBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ejemplo práctico\n"
      ],
      "metadata": {
        "id": "Xj38jTGf4Zob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el callback\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',        # Métrica que queremos observar\n",
        "    patience=3,                # Número de épocas sin mejora antes de parar\n",
        "    min_delta=0.001,           # Umbral mínimo de mejora\n",
        "    verbose=1,                 # Mostrar mensaje cuando se detiene\n",
        "    restore_best_weights=True  # Recuperar automáticamente los mejores pesos\n",
        ")\n",
        "\n",
        "# Entrenamos el modelo usando el callback\n",
        "model.fit(\n",
        "    norm_training_images,\n",
        "    training_labels_onehot,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.25,\n",
        "    callbacks=[early_stop],   # Aquí pasamos el callback\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "R5NbVZ7wLEz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de031d7-7520-4cb8-d485-805207a15ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0171 - val_accuracy: 0.9753 - val_loss: 0.1007\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0144 - val_accuracy: 0.9725 - val_loss: 0.1164\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0145 - val_accuracy: 0.9759 - val_loss: 0.1131\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 0.9737 - val_loss: 0.1187\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b046e8ba190>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se observa tras la ejecución del código, este método permite detener el entrenamiento de forma automática cuando el modelo deja de mejorar, sin necesidad de definir una clase personalizada. En este caso, el proceso se interrumpió tras la cuarta época al no observarse mejoras significativas en la pérdida de validación. Además, se restauraron automáticamente los pesos correspondientes a la mejor época, garantizando que el modelo final mantiene el mejor rendimiento alcanzado durante el entrenamiento. Este mecanismo también puede combinarse con otros *callbacks* como `ModelCheckpoint` para guardar en disco la mejor versión del modelo."
      ],
      "metadata": {
        "id": "XrynBpE7LDlR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_yZ9B8gTFqR"
      },
      "source": [
        "# 9. Unidades de activación\n",
        "\n",
        "En este ejercicio, vamos a evaluar la importancia de utilizar las unidades de activación adecuadas. Como hemos visto en clase, funciones de activación como sigmoid han dejado de utilizarse en favor de otras unidades como ReLU."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 9.1\n",
        "\n",
        "Utilizando la red realizada en el ejercicio 3, escribir un breve análisis comparando la utilización de unidades sigmoid y ReLU (por ejemplo, se pueden comentar aspectos como velocidad de convergencia, métricas obtenidas...). Explicar por qué pueden darse estas diferencias. Opcionalmente, comparar con otras activaciones disponibles en Keras.\n",
        "\n",
        "> *Pista: Usando redes más grandes se hace más sencillo apreciar las diferencias. Es mejor utilizar al menos 3 o 4 capas densas.*"
      ],
      "metadata": {
        "id": "Ad0t2t6WMziz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo ReLU"
      ],
      "metadata": {
        "id": "IlpxHFcgPWPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "NdzFOKSfPH-y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCcm5ZJAPH-3"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_relu = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_relu.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_relu.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas con 512 neuronas y activación ReLU\n",
        "model_relu.add(Dense(512, activation=\"relu\"))\n",
        "model_relu.add(Dense(512, activation=\"relu\"))\n",
        "model_relu.add(Dense(512, activation=\"relu\"))\n",
        "model_relu.add(Dense(512, activation=\"relu\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_relu.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "LpA2yQBNPH-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "alANRSXNPH-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "Y1DeORsXPH-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_relu = model_relu.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "jmmQvYoEPH-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aecd0f4-1d29-47dd-c42d-567c69f8032c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.8789 - loss: 0.3930 - val_accuracy: 0.9613 - val_loss: 0.1350\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.9660 - loss: 0.1205 - val_accuracy: 0.9634 - val_loss: 0.1336\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - accuracy: 0.9755 - loss: 0.0828 - val_accuracy: 0.9611 - val_loss: 0.1674\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 20ms/step - accuracy: 0.9794 - loss: 0.0685 - val_accuracy: 0.9689 - val_loss: 0.1302\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 20ms/step - accuracy: 0.9836 - loss: 0.0542 - val_accuracy: 0.9715 - val_loss: 0.1379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo Sigmoid"
      ],
      "metadata": {
        "id": "8uLGkBjrPl7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "mWMfp7jyPl7_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0KgrN0QPl7_"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_sigmoid = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_sigmoid.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_sigmoid.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas con 512 neuronas y activación Sigmoid\n",
        "model_sigmoid.add(Dense(512, activation=\"sigmoid\"))\n",
        "model_sigmoid.add(Dense(512, activation=\"sigmoid\"))\n",
        "model_sigmoid.add(Dense(512, activation=\"sigmoid\"))\n",
        "model_sigmoid.add(Dense(512, activation=\"sigmoid\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_sigmoid.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "DVUAecBNPl8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_sigmoid.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "Zs8iWCp-Pl8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "UUN1WS2LPl8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_sigmoid = model_sigmoid.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "D5NxfbjyPl8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c441cbad-398b-45b5-dead-e65e07a662e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - accuracy: 0.6741 - loss: 0.9302 - val_accuracy: 0.9303 - val_loss: 0.2373\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 21ms/step - accuracy: 0.9393 - loss: 0.2070 - val_accuracy: 0.9579 - val_loss: 0.1414\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 20ms/step - accuracy: 0.9605 - loss: 0.1379 - val_accuracy: 0.9613 - val_loss: 0.1368\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - accuracy: 0.9708 - loss: 0.1000 - val_accuracy: 0.9645 - val_loss: 0.1287\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.9778 - loss: 0.0748 - val_accuracy: 0.9625 - val_loss: 0.1438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo Leaky ReLU"
      ],
      "metadata": {
        "id": "m8XHy0RpP9-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "hIddlKcIP9-W"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFHefZYcP9-X"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_LeakyReLU = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_LeakyReLU.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_LeakyReLU.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas de 512 neuronas seguidas de la activación LeakyReLU\n",
        "model_LeakyReLU.add(Dense(512))  # Capa oculta 1\n",
        "model_LeakyReLU.add(LeakyReLU())\n",
        "\n",
        "model_LeakyReLU.add(Dense(512))  # Capa oculta 2\n",
        "model_LeakyReLU.add(LeakyReLU())\n",
        "\n",
        "model_LeakyReLU.add(Dense(512))  # Capa oculta 3\n",
        "model_LeakyReLU.add(LeakyReLU())\n",
        "\n",
        "model_LeakyReLU.add(Dense(512))  # Capa oculta 4\n",
        "model_LeakyReLU.add(LeakyReLU())\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_LeakyReLU.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "55GTY4FWP9-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_LeakyReLU.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "tE1iphbYP9-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "B9TEGeWKP9-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_LeakyReLU = model_LeakyReLU.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "MCbAzehAP9-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb84b2e-6698-4e3d-cbde-ec816cc6f165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.8692 - loss: 0.4239 - val_accuracy: 0.9371 - val_loss: 0.2270\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.9426 - loss: 0.1950 - val_accuracy: 0.9562 - val_loss: 0.1501\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.9592 - loss: 0.1421 - val_accuracy: 0.9567 - val_loss: 0.1603\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 26ms/step - accuracy: 0.9659 - loss: 0.1138 - val_accuracy: 0.9543 - val_loss: 0.1886\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.9674 - loss: 0.1102 - val_accuracy: 0.9577 - val_loss: 0.1737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta prueba se han entrenado tres redes neuronales con la misma arquitectura, variando únicamente la función de activación en las capas ocultas: *ReLU*, *sigmoid* y *LeakyReLU*. Cada red cuenta con cuatro capas densas de 512 neuronas y una capa final *softmax* con 10 salidas. El objetivo era comparar cómo afecta esta elección al comportamiento del modelo durante cinco épocas de entrenamiento.\n",
        "\n",
        "Desde la primera época, las redes con *ReLU* y *LeakyReLU* parten con un *accuracy* superior al de *sigmoid*, alcanzando aproximadamente un 87.9 % y 86.9 % respectivamente, frente al 67.4 % inicial del modelo con función sigmoide. No obstante, a partir de la segunda época, la red con *sigmoid* mejora rápidamente y termina obteniendo resultados comparables a los otros dos modelos, con una exactitud final del 97.78 %.\n",
        "\n",
        "En cuanto a la evolución de la pérdida de validación (`val_loss`), el modelo con *ReLU* muestra un comportamiento algo irregular. A pesar de obtener la mejor exactitud en validación en la quinta época (97.15 %), la pérdida de validación aumenta tras la tercera, alcanzando un valor de 0.1379 al final del entrenamiento. El modelo con *LeakyReLU* presenta una dinámica menos estable, con su mejor exactitud en validación en la segunda época (95.67 %) y una pérdida que crece desde la tercera, cerrando con un valor de 0.1737. En contraste, el modelo con *sigmoid* alcanza su mejor rendimiento general en la cuarta época (96.45 % de *accuracy* en validación y *val\\_loss* de 0.1287), con una evolución más consistente en términos de generalización.\n",
        "\n",
        "Aunque los tres modelos alcanzan niveles de exactitud elevados, la evolución de la pérdida de validación sugiere que *sigmoid* ha ofrecido una mejor adaptación al conjunto de validación en este experimento, seguido de cerca por *ReLU*. El comportamiento de *LeakyReLU*, si bien competitivo en términos de *accuracy*, ha sido más inestable en validación, lo que podría estar indicando una mayor sensibilidad al sobreajuste en este caso concreto.\n",
        "\n",
        "Es posible que, por tratarse de imágenes en escala de grises con valores normalizados entre 0 y 1, la función *sigmoid* no se haya visto penalizada como en otros escenarios más complejos o con arquitecturas más profundas. Al operar dentro de su rango óptimo de entrada, se reduce el efecto del *vanishing gradient*. No obstante, *sigmoid* sigue sin ser una función cero-centrada (*zero-centered*) y su derivada es limitada, por lo que no se recomienda para redes profundas o entrenamientos prolongados, donde *ReLU* y sus variantes suelen comportarse mejor.\n",
        "\n",
        "Por tanto, aunque *ReLU* continúa siendo la opción más común por su eficiencia y rapidez de convergencia, los resultados muestran que no siempre garantiza la mejor generalización. En este experimento, *sigmoid* ha sorprendido con un rendimiento competitivo y estable, mientras que *LeakyReLU*, aunque prometedora, ha requerido mayor atención por su mayor oscilación en validación."
      ],
      "metadata": {
        "id": "2mKbUEKsVFrw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu6RbUFKTFqT"
      },
      "source": [
        "# 10. Inicialización de parámetros\n",
        "\n",
        "En este ejercicio, vamos a evaluar la importancia de una correcta inicialización de parámetros en una red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abmm05UPTFqU"
      },
      "source": [
        "## Pregunta 10.1\n",
        "\n",
        "Partiendo de una red similar a la del ejercicio anterior (usando ya ReLUs), comentar las diferencias que se aprecian en el entrenamiento al utilizar distintas estrategias de inicialización de parámetros. Para ello, inicializar todas las capas con las siguientes estrategias, disponibles en Keras, y analizar sus diferencias:\n",
        "\n",
        "* Inicialización con ceros.\n",
        "* Inicialización con una variable aleatoria normal.\n",
        "* Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de comenzar a escribir el código, es importante comprender qué significa la **inicialización de parámetros**. Los nodos de una red neuronal están compuestos por parámetros como los pesos (*weights*) y los sesgos (*biases*), que son entrenados mediante algoritmos como el descenso de gradiente. Sin embargo, antes de que el modelo empiece a aprender, es necesario establecer valores iniciales para esos pesos. Esta decisión afecta directamente tanto a la velocidad de convergencia como a la calidad del entrenamiento.\n",
        "\n",
        "En este ejercicio vamos a comparar tres estrategias de inicialización distintas:\n",
        "\n",
        "- **Inicialización con ceros**:\n",
        "  Asignar el valor 0 a todos los pesos provoca que todas las neuronas comiencen con el mismo valor y reciban los mismos gradientes. Como consecuencia, se actualizan de forma idéntica en cada iteración, impidiendo que la red rompa la simetría y aprenda representaciones distintas. Esta estrategia, aunque sencilla, inutiliza la capacidad de la red para aprender de forma eficaz.\n",
        "\n",
        "- **Inicialización aleatoria (distribución normal)**:\n",
        "  Consiste en asignar pesos iniciales aleatorios siguiendo una distribución gaussiana. Esta estrategia ayuda a romper la simetría inicial y permite que cada neurona evolucione de forma diferente durante el entrenamiento. Es una aproximación más efectiva que la inicialización con ceros, aunque en redes profundas puede no ser suficiente para garantizar una propagación estable de los gradientes.\n",
        "\n",
        "- **Inicialización por defecto en Keras (*Glorot Uniform*)**:\n",
        "  Es la estrategia que utiliza Keras por defecto al definir una capa *Dense*. Se basa en la llamada inicialización *Glorot* (también conocida como *Xavier*), que ajusta la varianza de los pesos teniendo en cuenta tanto el número de entradas como de salidas de cada neurona. Su objetivo es mantener una activación equilibrada entre capas, evitando que los gradientes se desvanezcan o se amplifiquen excesivamente. Resulta especialmente eficaz con funciones de activación simétricas, aunque también se utiliza ampliamente en redes con ReLU.\n",
        "\n",
        "A continuación, se implementarán las distintas estrategias en modelos equivalentes para observar sus diferencias en precisión, pérdida y estabilidad durante el entrenamiento."
      ],
      "metadata": {
        "id": "y7fiIMsz7rAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inicialización con ceros"
      ],
      "metadata": {
        "id": "9fgTKZ4o9c2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "SWTsXbZm9-IZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT3bN9QB9-Ic"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_init_zeros = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_init_zeros.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_init_zeros.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas con 512 neuronas, activación ReLU e inicialización con ceros\n",
        "model_init_zeros.add(Dense(512, activation=\"relu\", kernel_initializer=\"zeros\"))\n",
        "model_init_zeros.add(Dense(512, activation=\"relu\", kernel_initializer=\"zeros\"))\n",
        "model_init_zeros.add(Dense(512, activation=\"relu\", kernel_initializer=\"zeros\"))\n",
        "model_init_zeros.add(Dense(512, activation=\"relu\", kernel_initializer=\"zeros\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax, también con inicialización a ceros\n",
        "model_init_zeros.add(Dense(10, activation=\"softmax\", kernel_initializer=\"zeros\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "m4WMkJli9-Ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_init_zeros.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "LD-LQuCt9-Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "qg4ZQSCL9-If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_init_zeros = model_init_zeros.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "JHNzTkCK-S8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17679641-ad68-447d-ebde-db481ca94432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 24ms/step - accuracy: 0.1115 - loss: 2.3016 - val_accuracy: 0.1076 - val_loss: 2.3020\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.1153 - loss: 2.3008 - val_accuracy: 0.1076 - val_loss: 2.3020\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.1153 - loss: 2.3007 - val_accuracy: 0.1076 - val_loss: 2.3020\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.1153 - loss: 2.3007 - val_accuracy: 0.1076 - val_loss: 2.3020\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.1153 - loss: 2.3007 - val_accuracy: 0.1076 - val_loss: 2.3020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inicialización aleatoria (distribución normal)"
      ],
      "metadata": {
        "id": "0H2zLb8E9tSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "B5-BUN_v_UM5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewWyz9pe_UM6"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_init_random = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_init_random.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_init_random.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas con 512 neuronas, activación ReLU e inicialización aleatoria normal\n",
        "model_init_random.add(Dense(512, activation=\"relu\", kernel_initializer=\"random_normal\"))\n",
        "model_init_random.add(Dense(512, activation=\"relu\", kernel_initializer=\"random_normal\"))\n",
        "model_init_random.add(Dense(512, activation=\"relu\", kernel_initializer=\"random_normal\"))\n",
        "model_init_random.add(Dense(512, activation=\"relu\", kernel_initializer=\"random_normal\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase), también con inicialización aleatoria normal\n",
        "model_init_random.add(Dense(10, activation=\"softmax\", kernel_initializer=\"random_normal\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "mV6dqlEY_UM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_init_random.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "quwaajns_UM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "o7zEHau3_UM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_init_random = model_init_random.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "tdoqukc6_UM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64f71a3-3ae9-4436-cb9b-c34b26bc4a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 25ms/step - accuracy: 0.8828 - loss: 0.3838 - val_accuracy: 0.9576 - val_loss: 0.1543\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.9659 - loss: 0.1213 - val_accuracy: 0.9667 - val_loss: 0.1289\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 22ms/step - accuracy: 0.9745 - loss: 0.0875 - val_accuracy: 0.9677 - val_loss: 0.1376\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.9816 - loss: 0.0654 - val_accuracy: 0.9665 - val_loss: 0.1678\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 24ms/step - accuracy: 0.9843 - loss: 0.0521 - val_accuracy: 0.9723 - val_loss: 0.1353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inicialización por defecto en Keras (*Glorot Uniform*)"
      ],
      "metadata": {
        "id": "W0olyXEm9wXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo\n",
        "\n",
        "Aunque en Keras la inicialización por defecto del parámetro `kernel_initializer` en las capas densas es `glorot_uniform`, y por tanto no es necesario indicarlo explícitamente, en el siguiente modelo se especificará de forma intencionada. Esto se hace con el objetivo de destacar que se está utilizando esta estrategia concreta, facilitando así la comparación con otras formas de inicialización implementadas en los apartados siguientes."
      ],
      "metadata": {
        "id": "6ZnEAvMk_h1C"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luhUOFd6_h1D"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_init_glorot = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_init_glorot.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_init_glorot.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas con 512 neuronas, activación ReLU e inicialización Glorot Uniform\n",
        "model_init_glorot.add(Dense(512, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
        "model_init_glorot.add(Dense(512, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
        "model_init_glorot.add(Dense(512, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
        "model_init_glorot.add(Dense(512, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase), también con inicialización Glorot Uniform\n",
        "model_init_glorot.add(Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "4JIJXj_x_h1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_init_glorot.compile(optimizer=Adam(),  # Utilizamos el optimizador Adam\n",
        "              loss='categorical_crossentropy',  # Función de pérdida para etiquetas en formato one-hot\n",
        "              metrics=['accuracy'])  # Monitorizamos la tasa de acierto durante el entrenamiento"
      ],
      "metadata": {
        "id": "0UlBbXVx_h1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "__vaLCp8_h1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_init_glorot = model_init_glorot.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "cIO3qgdx_h1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4766d8-e031-4114-fcd6-595425fd3454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - accuracy: 0.8779 - loss: 0.3940 - val_accuracy: 0.9571 - val_loss: 0.1495\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - accuracy: 0.9664 - loss: 0.1192 - val_accuracy: 0.9683 - val_loss: 0.1218\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.9762 - loss: 0.0855 - val_accuracy: 0.9687 - val_loss: 0.1273\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.9805 - loss: 0.0663 - val_accuracy: 0.9603 - val_loss: 0.1857\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.9847 - loss: 0.0512 - val_accuracy: 0.9683 - val_loss: 0.1392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se observa en los resultados obtenidos, la estrategia de inicialización de parámetros influye notablemente en el rendimiento del modelo.\n",
        "\n",
        "La **inicialización con ceros** impide completamente el aprendizaje: tanto la exactitud como la pérdida se mantienen constantes a lo largo de todas las épocas, con una exactitud en torno al 11 % y una pérdida fija de aproximadamente 2.30, lo que indica que la red no está actualizando los pesos de forma efectiva. Esto se debe a que todas las neuronas comienzan con los mismos valores y, al no romperse la simetría, aprenden exactamente lo mismo, inutilizando la profundidad del modelo.\n",
        "\n",
        "En contraste, la inicialización aleatoria con distribución normal permite que el modelo aprenda desde la primera época, alcanzando una exactitud del 88 % y una pérdida de 0.38 ya en el primer paso de entrenamiento. A lo largo de las épocas siguientes, la exactitud en entrenamiento supera el 98 %, pero la pérdida en validación muestra un patrón irregular: tras una primera mejora, comienza a incrementarse, alcanzando un valor de 0.1678 en la época 4. Aunque la exactitud en validación se recupera ligeramente en la última época (97.23 %), este comportamiento sugiere que el modelo comienza a sobreajustarse progresivamente, lo que afecta negativamente a su capacidad de generalización.\n",
        "\n",
        "Por último, la inicialización *glorot\\_uniform*, que es el valor por defecto en Keras para capas *Dense*, ofrece un aprendizaje más gradual pero también más estable. La exactitud inicial es similar a la de la inicialización aleatoria (87.79 %) y mejora de forma constante hasta superar el 98 %. La pérdida en validación desciende inicialmente hasta alcanzar 0.1218 en la época 2, pero presenta una subida notable en la época 4 (0.1857), que luego se atenúa. Aunque también hay signos de sobreajuste, las oscilaciones son más contenidas y la evolución del entrenamiento resulta más predecible. Esto refleja un mejor equilibrio entre aprendizaje y generalización, resultado del ajuste que realiza *Glorot* sobre la varianza de los pesos iniciales en función del número de entradas y salidas.\n",
        "\n",
        "Se puede concluir que solo las estrategias que introducen diversidad en los valores iniciales permiten que la red aprenda. Entre ellas, *glorot\\_uniform* proporciona un comportamiento más equilibrado y predecible, lo que la convierte en una opción más recomendable frente a la aleatoriedad sin control."
      ],
      "metadata": {
        "id": "WSWacyEwDyJE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqIAyVWrTFqV"
      },
      "source": [
        "# 11. Optimizadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcYj29hYTFqW"
      },
      "source": [
        "## Pregunta 11.1\n",
        "\n",
        "Partiendo de una red similar a la del ejercicio anterior (utilizando la mejor estrategia de inicialización observada), comparar y analizar las diferencias que se observan  al entrenar con varios de los optimizadores vistos en clase, incluyendo SGD como optimizador básico (se puede explorar el espacio de hiperparámetros de cada optimizador, aunque para optimizadores más avanzados del estilo de RMSprop es buena idea dejar los valores por defecto provistos por Keras)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de comenzar a comparar los distintos optimizadores, es importante entender su función dentro del entrenamiento de una red neuronal. Los optimizadores son los responsables de actualizar los pesos del modelo tras cada paso del algoritmo de retropropagación, y su configuración afecta directamente a la velocidad de convergencia, la estabilidad del aprendizaje y la capacidad del modelo para generalizar. Existen diversos algoritmos de optimización, cada uno con sus propias estrategias para ajustar los parámetros de la red y controlar el descenso del error.\n",
        "\n",
        "En este ejercicio se evaluarán cinco optimizadores ampliamente utilizados (**SGD**, **SGD con momentum**, **Adagrad**, **RMSprop** y **Adam**)"
      ],
      "metadata": {
        "id": "CwrVnjvfTw9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD (Stochastic Gradient Descent)\n",
        "\n",
        "El **descenso de gradiente** es el optimizador más básico. Actualiza los pesos del modelo tomando pequeños pasos en la dirección opuesta al gradiente del error. En lugar de calcular el gradiente sobre todo el conjunto de datos, lo hace usando muestras individuales o *mini-batches*, lo que lo hace más rápido pero también más sensible al ruido. Aunque simple, sigue siendo una base sólida para muchos modelos y permite incorporar mejoras como *momentum* o aceleración de Nesterov. Su comportamiento puede ajustarse mediante varios hiperparámetros:\n",
        "\n",
        "- `learning_rate`: Define la magnitud de los pasos que da el optimizador al actualizar los pesos. Un valor alto acelera el entrenamiento pero puede dificultar la convergencia; uno bajo es más estable pero lento. Valor por defecto: `0.01`.\n",
        "\n",
        "- `momentum`: Introduce una memoria del gradiente anterior para suavizar las actualizaciones. Esto evita oscilaciones y ayuda a escapar de mínimos locales. Valor típico: `0.9`. Por defecto: `0.0`.\n",
        "\n",
        "- `nesterov`: Si se activa (`True`), aplica una variante del *momentum* llamada *Nesterov accelerated gradient*, que anticipa la dirección futura del gradiente. Puede mejorar la convergencia en ciertos problemas. Por defecto: `False`.\n",
        "\n",
        "- `weight_decay`: Añade penalización sobre los pesos durante el entrenamiento, útil para regularización (*L2*). Por defecto: `None`.\n",
        "\n",
        "- `clipnorm` / `clipvalue`: Permiten limitar el valor máximo de los gradientes para evitar explosiones durante el entrenamiento. `clipnorm` restringe la norma del vector de gradiente; `clipvalue` limita cada componente. Por defecto: `None`.\n",
        "\n",
        "- `use_ema`: Activa el uso de *Exponential Moving Average* sobre los pesos del modelo, lo que puede estabilizar el entrenamiento. Por defecto: `False`.\n",
        "\n",
        "- `ema_momentum`: Controla la velocidad de actualización del promedio exponencial si `use_ema` está activo. Por defecto: `0.99`.\n",
        "\n",
        "- `loss_scale_factor`, `gradient_accumulation_steps`, `global_clipnorm`, `ema_overwrite_frequency`: Son parámetros avanzados para configuraciones específicas (por ejemplo, entrenamiento distribuido, precisión mixta o acumulación de gradientes). En la mayoría de los casos, no es necesario modificarlos."
      ],
      "metadata": {
        "id": "QfI7kcUEVCOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD con *momentum*\n",
        "\n",
        "Este optimizador no es una variante diferente, sino el mismo **SGD** al que se le asigna un valor distinto del cero al hiperparámetro `momentum`. Al hacerlo, se introduce una componente de inercia en la actualización de los pesos: además del gradiente actual, el optimizador tiene en cuenta la dirección de los pasos anteriores. Esto permite que el descenso de gradiente avance de forma más estable, reduciendo oscilaciones, superando regiones planas y acercándose al mínimo con mayor fluidez. En Keras, se activa directamente con `momentum=0.9` al instanciar el optimizador `SGD`."
      ],
      "metadata": {
        "id": "B5Qwfb2HXNt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adagrad\n",
        "\n",
        "**Adagrad** es un optimizador adaptativo que ajusta automáticamente el *learning rate* de cada parámetro durante el entrenamiento. A diferencia de *SGD*, que aplica una tasa de aprendizaje constante, Adagrad acumula el cuadrado de los gradientes anteriores para cada parámetro y utiliza esa información para reducir progresivamente su tasa de aprendizaje individual. De este modo, los parámetros que se actualizan con frecuencia reciben pasos más pequeños, mientras que los menos activos mantienen una mayor capacidad de ajuste. Esta propiedad lo hace especialmente útil en contextos con datos dispersos o variables poco frecuentes. No obstante, una de sus limitaciones es que la acumulación continua puede hacer que el *learning rate* se reduzca en exceso, lo que ralentiza o detiene el aprendizaje en fases avanzadas. Para controlar este comportamiento, Adagrad  también permite ajustar varios hiperparámetros:\n",
        "\n",
        "- `learning_rate`: Tasa inicial de aprendizaje. Se ajusta automáticamente durante el entrenamiento. Valor por defecto: `0.001`.\n",
        "\n",
        "- `initial_accumulator_value`: Valor inicial para la acumulación de gradientes. Si es muy bajo, puede provocar inestabilidad en los primeros pasos. Por defecto: `0.1`.\n",
        "\n",
        "- `epsilon`: Valor pequeño añadido para evitar divisiones por cero durante la normalización del gradiente. Por defecto: `1e-7`.\n",
        "\n",
        "- `weight_decay`, `clipnorm`, `clipvalue`, `use_ema`, `ema_momentum`, etc.: Parámetros adicionales similares a los de otros optimizadores, usados para regularización, estabilización o entrenamiento avanzado. No es necesario modificarlos en usos estándar."
      ],
      "metadata": {
        "id": "jmOehREhYIEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RMSprop\n",
        "\n",
        "**RMSprop** es un optimizador adaptativo que mejora las limitaciones de Adagrad al evitar que el *learning rate* disminuya de forma indefinida. Para ello, en lugar de acumular todos los gradientes pasados, mantiene un promedio móvil de los cuadrados de los gradientes recientes. Esto permite ajustar dinámicamente la tasa de aprendizaje por parámetro, dando pasos más pequeños en direcciones con gradientes grandes y pasos más amplios donde los gradientes son más pequeños. Este enfoque estabiliza el entrenamiento y lo hace especialmente adecuado para redes recurrentes o situaciones con gradientes oscilantes. Como ocurre en otros optimizadores, su comportamiento puede controlarse mediante varios hiperparámetros relevantes:\n",
        "\n",
        "- `learning_rate`: Tasa base de aprendizaje. Se adapta a lo largo del entrenamiento según la media de gradientes. Valor por defecto: `0.001`.\n",
        "\n",
        "- `rho`: Factor de decaimiento para calcular el promedio exponencial de los gradientes al cuadrado. Controla cuánta memoria se conserva del pasado. Por defecto: `0.9`.\n",
        "\n",
        "- `epsilon`: Pequeño valor añadido al denominador para evitar divisiones por cero. Por defecto: `1e-7`.\n",
        "\n",
        "- `momentum`: Si se activa, acumula gradientes anteriores como en *SGD con momentum*. Por defecto: `0.0`.\n",
        "\n",
        "- `centered`: Si es `True`, normaliza también respecto a la media de los gradientes (además de su cuadrado), lo que puede mejorar la estabilidad. Por defecto: `False`.\n",
        "\n",
        "- `weight_decay`, `clipnorm`, `clipvalue`, `use_ema`, `ema_momentum`, etc.: Parámetros adicionales que permiten estabilizar y regularizar el entrenamiento en escenarios más avanzados."
      ],
      "metadata": {
        "id": "LPI85hW_YsU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam\n",
        "\n",
        "**Adam** (*Adaptive Moment Estimation*) es uno de los optimizadores más utilizados actualmente por su eficacia y facilidad de uso. Combina las ventajas de **momentum** y de métodos adaptativos como **Adagrad** y **RMSprop**. Por un lado, acumula un promedio exponencial de los gradientes pasados (como *momentum*) para mantener la dirección de descenso más estable, y por otro, ajusta automáticamente el *learning rate* por parámetro utilizando una media de los gradientes al cuadrado (como *RMSprop*). Esto permite realizar actualizaciones eficientes incluso en problemas complejos, con poco ajuste manual de hiperparámetros. Su comportamiento puede refinarse mediante los siguientes parámetros:\n",
        "\n",
        "#### Argumentos principales en `keras.optimizers.Adam()`\n",
        "\n",
        "- `learning_rate`: Tasa base de aprendizaje. Por defecto: `0.001`.\n",
        "\n",
        "- `beta_1`: Coeficiente de decaimiento para el promedio de los gradientes (el término de *momentum*). Por defecto: `0.9`.\n",
        "\n",
        "- `beta_2`: Coeficiente de decaimiento para el promedio de los gradientes al cuadrado (la parte adaptativa). Por defecto: `0.999`.\n",
        "\n",
        "- `epsilon`: Valor pequeño para evitar divisiones por cero en la normalización del gradiente. Por defecto: `1e-7`.\n",
        "\n",
        "- `amsgrad`: Si se activa, utiliza una variante del algoritmo que garantiza que los denominadores no decrezcan, mejorando la estabilidad en ciertos casos. Por defecto: `False`.\n",
        "\n",
        "- `weight_decay`, `clipnorm`, `clipvalue`, `use_ema`, `ema_momentum`, etc.: Hiperparámetros adicionales presentes en otros optimizadores, que pueden utilizarse para regularización y control avanzado del entrenamiento."
      ],
      "metadata": {
        "id": "KVkx9GIZYs5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.2 Comparación práctica de optimizadores en el entrenamiento de redes neuronales\n",
        "\n",
        "Ahora que ya se han descrito las principales estrategias de optimización y se conocen sus fundamentos y parámetros configurables, se precederá a entrenar una misma red neuronal utilizando cada uno de los optimizadores presentados. Para garantizar la coherencia en la comparación, se mantendrá constante la arquitectura del modelo, así como la estrategia de inicialización previamente identificada como más efectiva (`glorot_uniform`). El objetivo es observar y analizar las diferencias en el comportamiento de cada optimizador durante el entrenamiento, prestando especial atención a la velocidad de convergencia, la estabilidad de las métricas y la capacidad de generalización."
      ],
      "metadata": {
        "id": "eKkQlktRicHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `SGD`"
      ],
      "metadata": {
        "id": "jcpPf-VOir4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "kqtbx5h6hDJL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra54YaXrhDJQ"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_opt_SGD = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_opt_SGD.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_opt_SGD.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas de 512 neuronas seguidas de la activación LeakyReLU\n",
        "model_opt_SGD.add(Dense(512))  # Capa oculta 1\n",
        "model_opt_SGD.add(LeakyReLU())\n",
        "\n",
        "model_opt_SGD.add(Dense(512))  # Capa oculta 2\n",
        "model_opt_SGD.add(LeakyReLU())\n",
        "\n",
        "model_opt_SGD.add(Dense(512))  # Capa oculta 3\n",
        "model_opt_SGD.add(LeakyReLU())\n",
        "\n",
        "model_opt_SGD.add(Dense(512))  # Capa oculta 4\n",
        "model_opt_SGD.add(LeakyReLU())\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_opt_SGD.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "0ln5HIYqhDJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo usando SGD como optimizador\n",
        "model_opt_SGD.compile(\n",
        "    optimizer=SGD(learning_rate=0.01),  # Utilizamos el optimizador SDG con su tasa de aprendizaje habitual\n",
        "    loss='categorical_crossentropy',    # Función de pérdida para etiquetas en formato one-hot\n",
        "    metrics=['accuracy']                # Monitorizamos la tasa de acierto durante el entrenamiento\n",
        ")"
      ],
      "metadata": {
        "id": "P8Fggdg3hDJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "59Yrdoy4hDJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_opt_SGD = model_opt_SGD.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWufgnMChDJR",
        "outputId": "151f77a9-4d14-488d-a838-fce3052a6f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.7301 - loss: 1.0504 - val_accuracy: 0.9108 - val_loss: 0.3025\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9131 - loss: 0.2951 - val_accuracy: 0.9305 - val_loss: 0.2418\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.9321 - loss: 0.2327 - val_accuracy: 0.9419 - val_loss: 0.2064\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.9454 - loss: 0.1920 - val_accuracy: 0.9489 - val_loss: 0.1819\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.9537 - loss: 0.1625 - val_accuracy: 0.9527 - val_loss: 0.1650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `SGD` con *momentum*"
      ],
      "metadata": {
        "id": "LsjeW3_Elbun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "P2KEjXizlbuq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mmMcnVmlbuq"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_opt_momentum = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_opt_momentum.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_opt_momentum.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas de 512 neuronas seguidas de la activación LeakyReLU\n",
        "model_opt_momentum.add(Dense(512))  # Capa oculta 1\n",
        "model_opt_momentum.add(LeakyReLU())\n",
        "\n",
        "model_opt_momentum.add(Dense(512))  # Capa oculta 2\n",
        "model_opt_momentum.add(LeakyReLU())\n",
        "\n",
        "model_opt_momentum.add(Dense(512))  # Capa oculta 3\n",
        "model_opt_momentum.add(LeakyReLU())\n",
        "\n",
        "model_opt_momentum.add(Dense(512))  # Capa oculta 4\n",
        "model_opt_momentum.add(LeakyReLU())\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_opt_momentum.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "ppeyKo77lbur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo usando SGD como optimizador\n",
        "model_opt_momentum.compile(\n",
        "    optimizer=SGD(learning_rate=0.01, momentum=0.9),  # Utilizamos el optimizador SDG con su tasa de aprendizaje habitual y le añadimos momentum\n",
        "    loss='categorical_crossentropy',                  # Función de pérdida para etiquetas en formato one-hot\n",
        "    metrics=['accuracy']                              # Monitorizamos la tasa de acierto durante el entrenamiento\n",
        ")"
      ],
      "metadata": {
        "id": "wz5Nbnbblbur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "r0W53Lfelbur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_opt_momentum = model_opt_momentum.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c9b902-fc8d-4e78-ec2d-496e08b79cba",
        "id": "Gl1zXn4Qlbur"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.8346 - loss: 0.5405 - val_accuracy: 0.9491 - val_loss: 0.1633\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - accuracy: 0.9565 - loss: 0.1435 - val_accuracy: 0.9601 - val_loss: 0.1259\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 20ms/step - accuracy: 0.9710 - loss: 0.0943 - val_accuracy: 0.9661 - val_loss: 0.1112\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 17ms/step - accuracy: 0.9797 - loss: 0.0667 - val_accuracy: 0.9669 - val_loss: 0.1178\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9842 - loss: 0.0520 - val_accuracy: 0.9631 - val_loss: 0.1410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Adagrad`"
      ],
      "metadata": {
        "id": "GnrY7cqLmUAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "6a2H5rZOmUAr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUpAI-kbmUAr"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_opt_adagrad = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_opt_adagrad.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_opt_adagrad.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas de 512 neuronas seguidas de la activación LeakyReLU\n",
        "model_opt_adagrad.add(Dense(512))  # Capa oculta 1\n",
        "model_opt_adagrad.add(LeakyReLU())\n",
        "\n",
        "model_opt_adagrad.add(Dense(512))  # Capa oculta 2\n",
        "model_opt_adagrad.add(LeakyReLU())\n",
        "\n",
        "model_opt_adagrad.add(Dense(512))  # Capa oculta 3\n",
        "model_opt_adagrad.add(LeakyReLU())\n",
        "\n",
        "model_opt_adagrad.add(Dense(512))  # Capa oculta 4\n",
        "model_opt_adagrad.add(LeakyReLU())\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_opt_adagrad.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "GGQG7xgjmUAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo usando Adagrad como optimizador\n",
        "model_opt_adagrad.compile(\n",
        "    optimizer=Adagrad(learning_rate=0.001),  # Utilizamos el optimizador Adagrad con su tasa de aprendizaje habitual\n",
        "    loss='categorical_crossentropy',         # Función de pérdida para etiquetas en formato one-hot\n",
        "    metrics=['accuracy']                     # Monitorizamos la tasa de acierto durante el entrenamiento\n",
        ")"
      ],
      "metadata": {
        "id": "rqwtR7m3mUAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "gTvJlqbLmUAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_opt_adagrad = model_opt_adagrad.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec04d87-9643-48cf-bf80-12db440fc619",
        "id": "1sL8B-_lmUAt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 20ms/step - accuracy: 0.5898 - loss: 1.6520 - val_accuracy: 0.8749 - val_loss: 0.4682\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8794 - loss: 0.4435 - val_accuracy: 0.9014 - val_loss: 0.3448\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 19ms/step - accuracy: 0.8998 - loss: 0.3479 - val_accuracy: 0.9117 - val_loss: 0.3048\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.9097 - loss: 0.3095 - val_accuracy: 0.9189 - val_loss: 0.2817\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.9161 - loss: 0.2851 - val_accuracy: 0.9238 - val_loss: 0.2653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `RMSprop`"
      ],
      "metadata": {
        "id": "iCADWkNxmU2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "yhHnmw-1mU2d"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJFl8v-tmU2e"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_opt_RMSprop = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_opt_RMSprop.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_opt_RMSprop.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas de 512 neuronas seguidas de la activación LeakyReLU\n",
        "model_opt_RMSprop.add(Dense(512))  # Capa oculta 1\n",
        "model_opt_RMSprop.add(LeakyReLU())\n",
        "\n",
        "model_opt_RMSprop.add(Dense(512))  # Capa oculta 2\n",
        "model_opt_RMSprop.add(LeakyReLU())\n",
        "\n",
        "model_opt_RMSprop.add(Dense(512))  # Capa oculta 3\n",
        "model_opt_RMSprop.add(LeakyReLU())\n",
        "\n",
        "model_opt_RMSprop.add(Dense(512))  # Capa oculta 4\n",
        "model_opt_RMSprop.add(LeakyReLU())\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_opt_RMSprop.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "MYVN6IrGmU2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo usando RMSprop como optimizador\n",
        "model_opt_RMSprop.compile(\n",
        "    optimizer=RMSprop(learning_rate=0.001), # Utilizamos el optimizador RMSprop con su tasa de aprendizaje habitual\n",
        "    loss='categorical_crossentropy',        # Función de pérdida para etiquetas en formato one-hot\n",
        "    metrics=['accuracy']                    # Monitorizamos la tasa de acierto durante el entrenamiento\n",
        ")"
      ],
      "metadata": {
        "id": "Wm6ETpV-mU2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "CIwJdh4umU2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_opt_RMSprop = model_opt_RMSprop.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df553b5-540c-4030-92f3-11beec87fa67",
        "id": "PCbntwJPmU2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 22ms/step - accuracy: 0.8504 - loss: 0.5017 - val_accuracy: 0.8744 - val_loss: 0.5030\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.9416 - loss: 0.2083 - val_accuracy: 0.9383 - val_loss: 0.2728\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.9556 - loss: 0.1617 - val_accuracy: 0.9518 - val_loss: 0.1983\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.9647 - loss: 0.1308 - val_accuracy: 0.9620 - val_loss: 0.1614\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 21ms/step - accuracy: 0.9660 - loss: 0.1200 - val_accuracy: 0.9589 - val_loss: 0.2019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Adam`"
      ],
      "metadata": {
        "id": "EedIUAqkmV4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición del modelo"
      ],
      "metadata": {
        "id": "UgoHQmmMmV4u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuaPravJmV4u"
      },
      "source": [
        "# Definimos el modelo como una secuencia de capas\n",
        "model_opt_adam = keras.models.Sequential()\n",
        "\n",
        "# Establecemos la forma de entrada con una capa explícita Input\n",
        "model_opt_adam.add(Input(shape=(28, 28)))  # Entrada de imágenes 28x28 píxeles\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_opt_adam.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas densas de 512 neuronas seguidas de la activación LeakyReLU\n",
        "model_opt_adam.add(Dense(512))  # Capa oculta 1\n",
        "model_opt_adam.add(LeakyReLU())\n",
        "\n",
        "model_opt_adam.add(Dense(512))  # Capa oculta 2\n",
        "model_opt_adam.add(LeakyReLU())\n",
        "\n",
        "model_opt_adam.add(Dense(512))  # Capa oculta 3\n",
        "model_opt_adam.add(LeakyReLU())\n",
        "\n",
        "model_opt_adam.add(Dense(512))  # Capa oculta 4\n",
        "model_opt_adam.add(LeakyReLU())\n",
        "\n",
        "# Añadimos la capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_opt_adam.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compilación del modelo"
      ],
      "metadata": {
        "id": "0PFkZ501mV4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo usando Adam como optimizador\n",
        "model_opt_adam.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # Utilizamos el optimizador Adam con su tasa de aprendizaje habitual\n",
        "    loss='categorical_crossentropy',      # Función de pérdida para etiquetas en formato one-hot\n",
        "    metrics=['accuracy']                  # Monitorizamos la tasa de acierto durante el entrenamiento\n",
        ")"
      ],
      "metadata": {
        "id": "YgoyoHKlmV4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "2vr91_rUmV4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_opt_adam = model_opt_adam.fit(\n",
        "    norm_training_images,  # Datos de entrada normalizados\n",
        "    training_labels_onehot,  # Etiquetas en formato one-hot\n",
        "    epochs=5,  # Número de pasadas completas sobre el conjunto de entrenamiento\n",
        "    batch_size=32,  # Número de muestras procesadas antes de actualizar los pesos\n",
        "    validation_split=0.25,  # Porcentaje de datos reservados para validación\n",
        "    verbose=1  # Mostramos el progreso del entrenamiento en cada época\n",
        ")"
      ],
      "metadata": {
        "id": "9h1FxY7WmV4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e7991e-e4d4-4675-d43f-1e7ea78d8a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 26ms/step - accuracy: 0.8703 - loss: 0.4247 - val_accuracy: 0.9424 - val_loss: 0.2005\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.9465 - loss: 0.1867 - val_accuracy: 0.9522 - val_loss: 0.1718\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - accuracy: 0.9588 - loss: 0.1437 - val_accuracy: 0.9600 - val_loss: 0.1495\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - accuracy: 0.9662 - loss: 0.1176 - val_accuracy: 0.9553 - val_loss: 0.1610\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.9681 - loss: 0.1059 - val_accuracy: 0.9659 - val_loss: 0.1383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El análisis comparativo de los distintos optimizadores empleados revela diferencias sustanciales tanto en el ritmo de convergencia como en la calidad del ajuste alcanzado en el conjunto de validación.\n",
        "\n",
        "**SGD** ofrece una progresión constante y predecible. A lo largo de las cinco épocas, la *accuracy* de validación mejora de forma estable hasta alcanzar un 95.27 %, mientras que la pérdida desciende progresivamente hasta situarse en 0.1650. Su rendimiento es sólido y no muestra señales de sobreajuste temprano, aunque necesita más pasos para alcanzar este nivel de precisión.\n",
        "\n",
        "Con **SGD con momentum**, los resultados mejoran notablemente desde la primera época, lo que evidencia una mayor eficiencia en la convergencia gracias a la inercia introducida por el *momentum*. Se alcanza un 96.69 % de *accuracy* de validación en la cuarta época, si bien se observa un ligero incremento en la pérdida en la última (0.1410), lo que podría indicar una estabilización o comienzo de sobreajuste. Aun así, ofrece un excelente compromiso entre velocidad y rendimiento.\n",
        "\n",
        "En el caso de **Adagrad**, el aprendizaje avanza de forma más pausada. El modelo parte de una *accuracy* de validación inicial significativamente inferior, pero mejora gradualmente hasta un 92.38 % en la quinta época. Esta evolución progresiva sugiere que el modelo se sigue ajustando, aunque con un ritmo menor. Podría beneficiarse de un mayor número de épocas, ya que no muestra señales de haber alcanzado aún su techo de rendimiento.\n",
        "\n",
        "**RMSprop** presenta un comportamiento algo irregular. Aunque la *accuracy* mejora hasta un 96.20 % en la cuarta época, se observa un repunte de la pérdida en la quinta (0.2019), lo que podría ser indicativo de una oscilación en la adaptación o de cierta inestabilidad. A pesar de ello, su rendimiento global es positivo y competitivo frente a otros métodos.\n",
        "\n",
        "Finalmente, **Adam** muestra un comportamiento muy eficiente y equilibrado. La *accuracy* de validación alcanza un 96.59 % en la última época, con una pérdida de 0.1383, sin señales claras de sobreajuste. El optimizador aprovecha bien el número limitado de épocas, con una mejora consistente tanto en pérdida como en precisión, y con un coste computacional razonable.\n",
        "\n",
        "**En conclusión**, el mejor resultado corresponde al modelo entrenado con **SGD con momentum**, seguido muy de cerca por **Adam**, que ofrece un comportamiento más suave y menos dependiente del ajuste manual de hiperparámetros. Ambas opciones son válidas en entornos reales, pero si se dispone de capacidad para afinar el modelo, SGD con momentum podría proporcionar un rendimiento ligeramente superior. Si se prioriza la robustez y facilidad de uso, Adam sigue siendo una de las elecciones más equilibradas."
      ],
      "metadata": {
        "id": "_AjK7yqLp4ms"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkfTFoJOTFqZ"
      },
      "source": [
        "# 12. Regularización y red final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6CQhK7ZTFqZ"
      },
      "source": [
        "## Problema 12.1\n",
        "\n",
        "Entrenar una red final que sea capaz de obtener una accuracy en el validation superior al 95%. Para ello, combinar todo lo aprendido anteriormente y utilizar técnicas de regularización para evitar overfitting. Algunos de los elementos que pueden tenerse en cuenta son los siguientes.\n",
        "\n",
        "* Número de capas y neuronas por capa\n",
        "* Optimizadores y sus parámetros\n",
        "* Batch size\n",
        "* Unidades de activación\n",
        "* Uso de capas dropout, regularización L2, regularización L1...\n",
        "* Early stopping (se puede aplicar como un callback de Keras, o se puede ver un poco \"a ojo\" cuándo el modelo empieza a caer en overfitting y seleccionar el número de epochs necesarias)\n",
        "* Batch normalization\n",
        "\n",
        "Si los modelos entrenados anteriormente ya se acercaban al valor requerido de accuracy, probar distintas estrategias igualmente y comentar los resultados.\n",
        "\n",
        "Explicar brevemente la estrategia seguida y los modelos probados para obtener el modelo final, que debe verse entrenado en este Notebook. No es necesario guardar el entrenamiento de todos los modelos que se han probado, es suficiente con explicar cómo se ha llegado al modelo final."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el desarrollo de la red final se parte de los aprendizajes extraídos en ejercicios anteriores, manteniendo aquellos parámetros y configuraciones que han demostrado ofrecer un rendimiento estable y efectivo. Concretamente, se conservará el uso de la función de activación *LeakyReLU*, que ha mostrado un buen comportamiento evitando el problema de unidades muertas y favoreciendo una convergencia más fluida en redes profundas. Igualmente, se mantendrá la arquitectura de **cuatro capas ocultas** con un número elevado pero manejable de neuronas: **512 unidades en cada una de ellas**, lo que proporciona una alta capacidad de representación sin inducir por sí solo un sobreajuste prematuro.\n",
        "\n",
        "También se establecerá un número máximo de **30 épocas**, acompañado de una estrategia de *early stopping*, lo que permitirá detener el entrenamiento de forma automática si no se observa mejora en el conjunto de validación.\n",
        "\n",
        "En cuanto al optimizador, se evaluarán dos de los que ofrecieron mejores resultados: **SGD con momentum** y **Adam**, con el objetivo de analizar sus posibles diferencias en la red final regularizada.\n",
        "\n",
        "Además, se incorporarán por primera vez técnicas de regularización explícitas que no se habían explorado hasta ahora: se probarán distintos valores de **`batch_size`**, se incluirán **capas `Dropout`** entre las capas ocultas, y se aplicará regularización **L2** y **Elastic Net**, esta última combina penalizaciones L1 y L2 sobre los pesos de la red. Estas estrategias permitirán mejorar la generalización del modelo y reducir el riesgo de sobreajuste, especialmente en redes profundas como la que se plantea en esta fase final."
      ],
      "metadata": {
        "id": "ThK-NvcAWJ5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `batch_size`\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-L0fC1kXcWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de seleccionar el tamaño del *batch*, conviene recordar la importancia de mantener una distribución equilibrada de clases durante el entrenamiento. Si los *mini-batches* contienen únicamente ejemplos de una o pocas clases (por ejemplo, todos dígitos “9” en un mismo lote), el modelo podría sesgarse en sus actualizaciones de pesos, generando un aprendizaje inestable o parcial.\n",
        "\n",
        "Aunque no es necesario que cada *batch* tenga una distribución perfecta, sí se espera que, en conjunto, las clases estén representadas de forma similar en todos ellos. Este equilibrio se logra gracias al parámetro `shuffle=True` de Keras, que mezcla los datos en cada época, evitando que las clases se agrupen en *batches* homogéneos.\n",
        "\n",
        "Para asegurar este comportamiento, a continuación se comprobará si el conjunto de entrenamiento está equilibrado entre clases antes de probar distintos valores de `batch_size` como 32, 64 o 128."
      ],
      "metadata": {
        "id": "B9uqdMeYZsCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contamos cuántos ejemplos hay por clase y los ordenamos por número de ejemplos (de menos a más)\n",
        "class_counts = pd.Series(training_labels).value_counts().sort_values()\n",
        "\n",
        "# Representamos la gráfica ordenada de menos a más\n",
        "plt.bar(class_counts.index, class_counts.values)\n",
        "plt.xlabel(\"Clase\")\n",
        "plt.ylabel(\"Número de ejemplos\")\n",
        "plt.title(\"Distribución de clases en el conjunto de entrenamiento\")\n",
        "plt.xticks(class_counts.index)\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Mqfy5AR9Z-BG",
        "outputId": "272df655-4218-4341-ec7f-b446662b5998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento de código permite visualizar de forma clara la distribución de clases en el conjunto de entrenamiento. En primer lugar, se convierte el array `training_labels` en una serie de pandas para aplicar el método `value_counts()`, que cuenta cuántas veces aparece cada etiqueta (dígito del 0 al 9). Posteriormente, se ordenan los resultados de menor a mayor usando `.sort_values()` para facilitar la lectura visual del posible desequilibrio.\n",
        "\n",
        "A continuación, se genera una gráfica de barras verticales mediante `plt.bar()`, donde cada barra representa una clase y su altura indica la cantidad de ejemplos asociados. El eje *x* muestra las etiquetas de clase, y el eje *y* refleja el número de ejemplos. Se han añadido también una cuadrícula horizontal y etiquetas descriptivas para mejorar la interpretación.\n",
        "\n",
        "Al observar el gráfico, se aprecia que la distribución no es perfectamente uniforme, pero sí razonablemente equilibrada. La clase menos representada (dígito 5) cuenta con más de 5.000 ejemplos, mientras que la más frecuente (dígito 1) supera los 6.700. Esta diferencia, aunque no es ideal, no representa un desbalance severo en términos prácticos para el entrenamiento de una red neuronal en tareas de clasificación multiclase.\n",
        "\n",
        "Dado que el conjunto está lo suficientemente equilibrado, **no es necesario aplicar técnicas adicionales de balanceo** como sobremuestreo (*oversampling*) o submuestreo (*undersampling*). El barajado aleatorio realizado por defecto (`shuffle=True`) será suficiente para garantizar que los *mini-batches* durante el entrenamiento contengan ejemplos variados y representativos de todas las clases."
      ],
      "metadata": {
        "id": "QTBKdn9sddsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Función para definir modelos"
      ],
      "metadata": {
        "id": "FdxztlNie4Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función que genera modelos con arquitectura estándar\n",
        "def crear_modelo():\n",
        "    model = keras.models.Sequential()  # Inicializamos el modelo como una secuencia de capas\n",
        "\n",
        "    model.add(Input(shape=(28, 28)))  # Definimos la capa de entrada para imágenes de 28x28 píxeles\n",
        "    model.add(Flatten())  # Aplanamos la imagen para convertirla en un vector unidimensional de 784 elementos\n",
        "\n",
        "    # Añadimos 4 capas ocultas densas con 512 neuronas cada una, seguidas de la activación LeakyReLU\n",
        "    for _ in range(4):\n",
        "        model.add(Dense(512))      # Capa densa con 512 unidades\n",
        "        model.add(LeakyReLU())     # Activación LeakyReLU para evitar el problema de neuronas muertas\n",
        "\n",
        "    model.add(Dense(10, activation=\"softmax\"))  # Capa de salida con 10 neuronas y activación softmax para clasificación multiclase\n",
        "\n",
        "    return model  # Devolvemos el modelo construido"
      ],
      "metadata": {
        "id": "ckkjwmLwhf2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento define una función llamada `crear_modelo()`, que construye y devuelve un modelo neuronal con una arquitectura estándar, pensada para abordar tareas de clasificación multiclase como MNIST. El modelo se organiza de forma secuencial, es decir, las capas se apilan una tras otra en orden.\n",
        "\n",
        "En primer lugar, se establece una **capa de entrada** con una forma de `(28, 28)`, correspondiente al tamaño de las imágenes en escala de grises del dataset. A continuación, la función `Flatten()` transforma cada imagen en un vector de 784 elementos, necesario para conectar con las capas densas posteriores.\n",
        "\n",
        "El bloque central del modelo consta de **cuatro capas ocultas**, cada una compuesta por 512 neuronas. A cada capa densa se le aplica seguidamente una función de activación *LeakyReLU*, la cual permite que las neuronas mantengan un pequeño gradiente cuando la entrada es negativa, evitando así el problema de las unidades muertas que puede aparecer con activaciones como *ReLU*.\n",
        "\n",
        "Finalmente, se añade una **capa de salida** con 10 neuronas y función de activación *softmax*, apropiada para clasificación multiclase, ya que transforma los valores de salida en probabilidades asociadas a cada clase.\n",
        "\n",
        "La función termina con la instrucción `return model`, que devuelve el modelo ya definido para que pueda ser compilado y entrenado posteriormente. Gracias a este diseño modular, `crear_modelo()` puede reutilizarse con distintos optimizadores, *batch sizes* o estrategias de regularización sin modificar su estructura interna."
      ],
      "metadata": {
        "id": "3O02zm3eZWSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Función para entrenar los modelos"
      ],
      "metadata": {
        "id": "X9icJ8DKlWqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función que compila y entrena un modelo con los parámetros definidos\n",
        "def entrenar_modelo(batch_size, optimizer):\n",
        "    \"\"\"\n",
        "    Entrena un modelo utilizando la arquitectura definida en crear_modelo(),\n",
        "    con el optimizador y tamaño de batch especificados.\n",
        "    \"\"\"\n",
        "    model = crear_modelo()  # Construimos la arquitectura base\n",
        "\n",
        "    # Compilamos el modelo con el optimizador indicado\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Entrenamos el modelo con early stopping\n",
        "    history = model.fit(\n",
        "        norm_training_images,         # Datos de entrada normalizados\n",
        "        training_labels_onehot,       # Etiquetas codificadas en one-hot\n",
        "        epochs=30,                    # Número máximo de épocas\n",
        "        batch_size=batch_size,        # Tamaño del batch especificado\n",
        "        validation_split=0.25,        # Porcentaje reservado para validación\n",
        "        verbose=1,                    # Mostrar resultados por época\n",
        "        callbacks=[early_stop]        # Detener si no hay mejora\n",
        "    )\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "yFux1iV1jFX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función, llamada `entrenar_modelo()`, automatiza el proceso de compilación y entrenamiento de un modelo de red neuronal. Recibe como argumentos el tamaño del *batch* (`batch_size`) y el optimizador que se desea utilizar. Su finalidad es reutilizar la arquitectura definida previamente en `crear_modelo()` aplicando distintos ajustes de entrenamiento sin duplicar código.\n",
        "\n",
        "En primer lugar, se construye el modelo llamando a `crear_modelo()`, que genera una red con cuatro capas ocultas y función de activación *LeakyReLU*. A continuación, el modelo se **compila** utilizando el optimizador indicado, junto con la función de pérdida `categorical_crossentropy`, adecuada para clasificación multiclase, y la métrica de `accuracy` para evaluar el rendimiento durante el entrenamiento.\n",
        "\n",
        "Seguidamente, se inicia el entrenamiento con la función `fit()`, que recorre el conjunto de datos durante un máximo de 30 épocas. El parámetro `batch_size` determina cuántas muestras se procesan antes de actualizar los pesos, y `validation_split=0.25` reserva el 25% del conjunto de entrenamiento para validación interna. El argumento `verbose=1` habilita la visualización detallada del proceso de entrenamiento.\n",
        "\n",
        "Por último, se incluye un mecanismo de **early stopping** a través del parámetro `callbacks=[early_stop]`, lo que permite interrumpir el entrenamiento si no se observa mejora en la pérdida de validación, evitando así el sobreajuste.\n",
        "\n",
        "La función devuelve dos objetos: el modelo entrenado y el historial del entrenamiento (`history`), que contiene el seguimiento de métricas por época y puede utilizarse posteriormente para análisis o visualización de resultados. Esta estructura facilita la comparación de distintas configuraciones de forma sistemática y eficiente."
      ],
      "metadata": {
        "id": "WlxzmrQcZYWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento de los modelos"
      ],
      "metadata": {
        "id": "1HR0P1ddf77N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos y entrenamos los modelos\n",
        "# Modelos Adam\n",
        "model_adam_32, history_adam_32 = entrenar_modelo(batch_size=32, optimizer=Adam())\n",
        "model_adam_64, history_adam_64 = entrenar_modelo(batch_size=64, optimizer=Adam())\n",
        "model_adam_128, history_adam_128 = entrenar_modelo(batch_size=128, optimizer=Adam())\n",
        "\n",
        "# Modelos SGD con momentum\n",
        "model_momentum_32, history_momentum_32 = entrenar_modelo(batch_size=32, optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
        "model_momentum_64, history_momentum_64 = entrenar_modelo(batch_size=64, optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
        "model_momentum_128, history_momentum_128 = entrenar_modelo(batch_size=128, optimizer=SGD(learning_rate=0.01, momentum=0.9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2IXsmqqetAf",
        "outputId": "fe5f8ab4-c8b5-4b7f-e8e5-099e171df682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.8708 - loss: 0.4206 - val_accuracy: 0.9385 - val_loss: 0.2150\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - accuracy: 0.9448 - loss: 0.1855 - val_accuracy: 0.9533 - val_loss: 0.1686\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 21ms/step - accuracy: 0.9613 - loss: 0.1356 - val_accuracy: 0.9541 - val_loss: 0.1700\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.9637 - loss: 0.1240 - val_accuracy: 0.9563 - val_loss: 0.1707\n",
            "Epoch 5/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.9692 - loss: 0.1050 - val_accuracy: 0.9554 - val_loss: 0.1833\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "Epoch 1/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.8726 - loss: 0.4150 - val_accuracy: 0.9416 - val_loss: 0.1941\n",
            "Epoch 2/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.9520 - loss: 0.1644 - val_accuracy: 0.9555 - val_loss: 0.1665\n",
            "Epoch 3/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 27ms/step - accuracy: 0.9628 - loss: 0.1231 - val_accuracy: 0.9587 - val_loss: 0.1497\n",
            "Epoch 4/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9655 - loss: 0.1095 - val_accuracy: 0.9617 - val_loss: 0.1551\n",
            "Epoch 5/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9725 - loss: 0.0906 - val_accuracy: 0.9479 - val_loss: 0.2322\n",
            "Epoch 6/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.9736 - loss: 0.0871 - val_accuracy: 0.9647 - val_loss: 0.1502\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "Epoch 1/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 35ms/step - accuracy: 0.8614 - loss: 0.4484 - val_accuracy: 0.9524 - val_loss: 0.1572\n",
            "Epoch 2/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.9574 - loss: 0.1425 - val_accuracy: 0.9543 - val_loss: 0.1612\n",
            "Epoch 3/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.9667 - loss: 0.1063 - val_accuracy: 0.9557 - val_loss: 0.1701\n",
            "Epoch 4/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9718 - loss: 0.0893 - val_accuracy: 0.9569 - val_loss: 0.1632\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.8357 - loss: 0.5345 - val_accuracy: 0.9491 - val_loss: 0.1626\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9575 - loss: 0.1428 - val_accuracy: 0.9588 - val_loss: 0.1304\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - accuracy: 0.9717 - loss: 0.0936 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.9808 - loss: 0.0657 - val_accuracy: 0.9660 - val_loss: 0.1159\n",
            "Epoch 5/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.9850 - loss: 0.0506 - val_accuracy: 0.9678 - val_loss: 0.1215\n",
            "Epoch 6/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.9868 - loss: 0.0405 - val_accuracy: 0.9687 - val_loss: 0.1193\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "Epoch 1/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.8085 - loss: 0.6806 - val_accuracy: 0.9431 - val_loss: 0.1911\n",
            "Epoch 2/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9504 - loss: 0.1681 - val_accuracy: 0.9569 - val_loss: 0.1473\n",
            "Epoch 3/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.9664 - loss: 0.1128 - val_accuracy: 0.9622 - val_loss: 0.1287\n",
            "Epoch 4/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.9755 - loss: 0.0839 - val_accuracy: 0.9668 - val_loss: 0.1129\n",
            "Epoch 5/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.9811 - loss: 0.0634 - val_accuracy: 0.9671 - val_loss: 0.1128\n",
            "Epoch 6/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.9867 - loss: 0.0475 - val_accuracy: 0.9672 - val_loss: 0.1175\n",
            "Epoch 7/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9901 - loss: 0.0365 - val_accuracy: 0.9684 - val_loss: 0.1160\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "Epoch 1/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - accuracy: 0.7553 - loss: 0.9054 - val_accuracy: 0.9314 - val_loss: 0.2412\n",
            "Epoch 2/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.9324 - loss: 0.2252 - val_accuracy: 0.9467 - val_loss: 0.1848\n",
            "Epoch 3/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.9528 - loss: 0.1588 - val_accuracy: 0.9544 - val_loss: 0.1580\n",
            "Epoch 4/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.9641 - loss: 0.1214 - val_accuracy: 0.9598 - val_loss: 0.1394\n",
            "Epoch 5/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.9721 - loss: 0.0965 - val_accuracy: 0.9636 - val_loss: 0.1251\n",
            "Epoch 6/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.9784 - loss: 0.0779 - val_accuracy: 0.9657 - val_loss: 0.1170\n",
            "Epoch 7/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.9815 - loss: 0.0631 - val_accuracy: 0.9666 - val_loss: 0.1158\n",
            "Epoch 8/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.9857 - loss: 0.0518 - val_accuracy: 0.9664 - val_loss: 0.1164\n",
            "Epoch 9/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.9883 - loss: 0.0428 - val_accuracy: 0.9651 - val_loss: 0.1215\n",
            "Epoch 10/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.9905 - loss: 0.0362 - val_accuracy: 0.9652 - val_loss: 0.1202\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante el proceso de entrenamiento se ha observado que los modelos con *batch sizes* más pequeños tienden a tardar más tiempo en completar cada época. Esto se debe a que el conjunto de entrenamiento se divide en un mayor número de bloques más pequeños, lo que incrementa el número total de actualizaciones de pesos que deben realizarse. Aunque cada actualización individual es más rápida, el coste acumulado por la cantidad de iteraciones hace que el tiempo global sea mayor. Por el contrario, los *batch sizes* más grandes reducen el número de iteraciones por época, acelerando el entrenamiento a costa de una menor frecuencia de ajuste de pesos.\n",
        "\n",
        "Esta relación entre tamaño del lote y velocidad de entrenamiento no solo afecta al tiempo, sino también al comportamiento del modelo en cuanto a su capacidad de generalización. Por ello, se ha mantenido constante el resto de parámetros para poder evaluar con claridad el impacto aislado del tamaño de *batch* en el rendimiento del modelo.\n",
        "\n",
        "También se ha observado que los modelos entrenados con **SGD y momentum** tienden a necesitar **más épocas** para alcanzar su punto óptimo de validación en comparación con modelos entrenados con **Adam**. Esta diferencia se debe a que Adam adapta automáticamente la tasa de aprendizaje, lo que le permite converger más rápidamente, mientras que *momentum* requiere más iteraciones para estabilizar su dirección de descenso."
      ],
      "metadata": {
        "id": "UJZHWl_5boOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resultados"
      ],
      "metadata": {
        "id": "m5p9ApuDgDoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario con los historiales y su etiqueta asociada\n",
        "historicos = {\n",
        "    'batch_size_adam_32': history_adam_32,\n",
        "    'batch_size_adam_64': history_adam_64,\n",
        "    'batch_size_adam_128': history_adam_128,\n",
        "    'batch_size_momentum_32': history_momentum_32,\n",
        "    'batch_size_momentum_64': history_momentum_64,\n",
        "    'batch_size_momentum_128': history_momentum_128\n",
        "}\n",
        "\n",
        "# Lista para guardar los resultados\n",
        "resultados = []\n",
        "\n",
        "# Iteramos sobre cada historial\n",
        "for nombre, hist in historicos.items():\n",
        "    val_acc = hist.history['val_accuracy']\n",
        "    val_loss = hist.history['val_loss']\n",
        "    mejor_epoca = int(pd.Series(val_acc).idxmax()) + 1  # +1 porque las epochs se indexan desde 0\n",
        "    resultados.append({\n",
        "        'Modelo': nombre,\n",
        "        'Época óptima': mejor_epoca,\n",
        "        'Val Accuracy (%)': round(val_acc[mejor_epoca - 1] * 100, 2),\n",
        "        'Val Loss': round(val_loss[mejor_epoca - 1], 4)\n",
        "    })\n",
        "\n",
        "# Creamos el DataFrame\n",
        "tabla_resultados = pd.DataFrame(resultados)\n",
        "\n",
        "# Mostramos la tabla de resultados\n",
        "display(tabla_resultados.sort_values(by=\"Val Accuracy (%)\", ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "i6BAV-M_chv3",
        "outputId": "d2f3eccf-caa9-4724-fb4d-b4b34c856757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    Modelo  Época óptima  Val Accuracy (%)  Val Loss\n",
              "3   batch_size_momentum_32             6             96.87    0.1193\n",
              "4   batch_size_momentum_64             7             96.84    0.1160\n",
              "5  batch_size_momentum_128             7             96.66    0.1158\n",
              "1       batch_size_adam_64             6             96.47    0.1502\n",
              "2      batch_size_adam_128             4             95.69    0.1632\n",
              "0       batch_size_adam_32             4             95.63    0.1707"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e50cb7ca-2d03-48cc-9162-1472b8f3c189\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Época óptima</th>\n",
              "      <th>Val Accuracy (%)</th>\n",
              "      <th>Val Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>batch_size_momentum_32</td>\n",
              "      <td>6</td>\n",
              "      <td>96.87</td>\n",
              "      <td>0.1193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>batch_size_momentum_64</td>\n",
              "      <td>7</td>\n",
              "      <td>96.84</td>\n",
              "      <td>0.1160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>batch_size_momentum_128</td>\n",
              "      <td>7</td>\n",
              "      <td>96.66</td>\n",
              "      <td>0.1158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>batch_size_adam_64</td>\n",
              "      <td>6</td>\n",
              "      <td>96.47</td>\n",
              "      <td>0.1502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>batch_size_adam_128</td>\n",
              "      <td>4</td>\n",
              "      <td>95.69</td>\n",
              "      <td>0.1632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>batch_size_adam_32</td>\n",
              "      <td>4</td>\n",
              "      <td>95.63</td>\n",
              "      <td>0.1707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e50cb7ca-2d03-48cc-9162-1472b8f3c189')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e50cb7ca-2d03-48cc-9162-1472b8f3c189 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e50cb7ca-2d03-48cc-9162-1472b8f3c189');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-71ed3d96-3ad5-4e80-8859-895e1991624a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71ed3d96-3ad5-4e80-8859-895e1991624a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-71ed3d96-3ad5-4e80-8859-895e1991624a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(tabla_resultados\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"batch_size_momentum_32\",\n          \"batch_size_momentum_64\",\n          \"batch_size_adam_32\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u00c9poca \\u00f3ptima\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 4,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6,\n          7,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Accuracy (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5611416933360085,\n        \"min\": 95.63,\n        \"max\": 96.87,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          96.87,\n          96.84,\n          95.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025183566069959196,\n        \"min\": 0.1158,\n        \"max\": 0.1707,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.1193,\n          0.116,\n          0.1707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código tiene como objetivo **resumir y comparar el rendimiento** de los distintos modelos entrenados, identificando para cada uno de ellos la mejor época según la precisión de validación (*val accuracy*) y mostrando las métricas correspondientes.\n",
        "\n",
        "En primer lugar, se define un **diccionario llamado `historicos`** que asocia el nombre identificativo de cada modelo (según el tipo de optimizador y el *batch size* utilizado) con su respectivo historial de entrenamiento (`history`), que fue devuelto por la función `fit()`.\n",
        "\n",
        "A continuación, se inicializa una lista vacía llamada `resultados`, que almacenará los valores relevantes de cada modelo.\n",
        "\n",
        "Dentro del bucle `for`, se recorre cada historial para extraer dos listas: `val_accuracy` y `val_loss`. Se identifica la época óptima utilizando `idxmax()`, que devuelve el índice donde se alcanzó la mayor precisión de validación. Como las épocas se indexan desde cero, se suma 1 para mostrar un valor más legible. Luego, se construye un diccionario con el nombre del modelo, la época óptima, la precisión máxima de validación (convertida a porcentaje con dos decimales), y la pérdida correspondiente en esa misma época.\n",
        "\n",
        "Una vez procesados todos los modelos, los resultados se agrupan en un **DataFrame de pandas**, que organiza y presenta los datos de manera tabular, facilitando la comparación directa entre configuraciones.\n",
        "\n",
        "Finalmente, se muestra la tabla `tabla_resultados`, que resume de forma clara los modelos evaluados y sus mejores métricas, lo que permite identificar con rapidez qué combinación de *batch size* y optimizador ha ofrecido el mejor rendimiento. Para facilitar su interpretación, se aplica una ordenación descendente por precisión de validación (`Val Accuracy (%)`), de modo que los modelos con mejor rendimiento aparezcan en la parte superior. Esto permite identificar rápidamente cuál ha sido la estrategia de regularización más eficaz.\n",
        "\n",
        "Los resultados obtenidos reflejan con claridad cómo el tipo de optimizador y el tamaño del *batch* influyen tanto en el número de épocas necesarias para alcanzar el rendimiento óptimo como en las métricas finales en validación.\n",
        "\n",
        "En primer lugar, se confirma que **los modelos entrenados con SGD y *momentum* superan de forma sistemática a los entrenados con Adam**, tanto en exactitud como en pérdida sobre los datos de validación. Entre ellos, la mejor exactitud se alcanza con `batch_size=32` y *momentum*, logrando una *val\\_accuracy* del 96.87 % en la época 6. No obstante, si se amplía la comparación a la pérdida, que representa de forma más directa la calidad del ajuste, el modelo con `batch_size=128` obtiene el **valor más bajo de *val\\_loss* (0.1158)**, manteniendo una exactitud igualmente elevada (96.66 %) y muy próxima a la mejor registrada.\n",
        "\n",
        "Estas diferencias, aunque sutiles, cobran relevancia cuando se consideran otros factores. Por ejemplo, el tamaño del *batch* también afecta al tiempo de entrenamiento. Los modelos con `batch_size=128` procesan más muestras por iteración, lo que reduce el número total de pasos por época y, en consecuencia, **acorta la duración del entrenamiento** sin comprometer la calidad del modelo. Esta ventaja resulta especialmente útil en contextos con recursos limitados o donde se trabaja con grandes volúmenes de datos.\n",
        "\n",
        "En cuanto a estabilidad, los resultados muestran que aumentar el tamaño del *batch* no penaliza la generalización cuando se entrena con *momentum*. Al contrario, la pérdida en validación se mantiene estable y baja incluso con valores elevados, lo que refuerza la solidez del modelo.\n",
        "\n",
        "En contraste, los modelos con Adam se estabilizan antes (épocas 4–6) pero presentan un peor rendimiento general. Aunque convergen más rápido, su sensibilidad al tamaño del *batch* y el aumento de la pérdida en validación indican una menor capacidad de generalización en este escenario.\n",
        "\n",
        "Aunque el modelo con `batch_size=32` logra la mayor exactitud, la diferencia es mínima y no justifica el mayor coste computacional asociado. Por tanto, se selecciona como modelo final el que combina:\n",
        "\n",
        "- **SGD con momentum**\n",
        "- **Batch size 128**\n",
        "- **Época óptima: 7**\n",
        "- **Val Accuracy: 96.66 %**\n",
        "- **Val Loss: 0.1158**\n",
        "\n",
        "Esta configuración representa un mejor equilibrio entre precisión, eficiencia y estabilidad, por lo que se tomará como base para la aplicación de regularizaciones adicionales."
      ],
      "metadata": {
        "id": "xnzGOsg3eybG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regulacización con `Dropout`, `L2` y `Elasticnet`"
      ],
      "metadata": {
        "id": "CeHOXGIzjhK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el objetivo de mejorar la capacidad de generalización del modelo final y reducir el riesgo de sobreajuste, se procederá a entrenar y comparar cinco variantes de la red utilizando diferentes técnicas de regularización. En concreto, se evaluarán por separado los efectos de **L2**, **Elastic Net** y **Dropout**, y posteriormente se combinará *Dropout* con cada una de las dos penalizaciones anteriores, dando lugar a un total de **cinco configuraciones** distintas.\n",
        "\n",
        "Estas estrategias son **compatibles entre sí** y actúan de forma complementaria: mientras que `Dropout` introduce aleatoriedad estructural desactivando nodos durante el entrenamiento, las penalizaciones `L2` y `Elastic Net` aplican restricciones directamente sobre los pesos de la red, evitando que crezcan en exceso o se vuelvan irrelevantes. En la práctica profesional, la regularización **L2** es la más empleada por su simplicidad y eficacia, mientras que `Elastic Net` es útil cuando se desea combinar los beneficios de L1 (sparsity) y L2 (estabilidad). `Dropout`, por su parte, es habitual en redes profundas por su capacidad para reducir la coadaptación entre neuronas.\n",
        "\n",
        "Todos los modelos se entrenarán manteniendo la configuración que ha demostrado mejor rendimiento hasta el momento (activación `LeakyReLU`, cuatro capas ocultas de 512 neuronas, `SGD` con momentum y `batch_size=128`). Esto permitirá comparar de forma justa cómo afecta cada regularización al comportamiento del modelo."
      ],
      "metadata": {
        "id": "g_S39WpvivUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Función para definir los modelos"
      ],
      "metadata": {
        "id": "5s661ZMZodgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_modelo_regularizado(tipo, dropout):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(Input(shape=(28, 28)))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Elegimos la regularización\n",
        "    if tipo == 'l2':\n",
        "        regularizador = l2(0.001)\n",
        "    elif tipo == 'elasticnet':\n",
        "        regularizador = l1_l2(l1=0.0005, l2=0.0005)\n",
        "    else:\n",
        "        regularizador = None  # Sin regularización en los pesos\n",
        "\n",
        "    # Añadimos las capas ocultas con regularización y/o dropout\n",
        "    for _ in range(4):\n",
        "        model.add(Dense(512, kernel_regularizer=regularizador))\n",
        "        model.add(LeakyReLU())\n",
        "        if dropout:\n",
        "            model.add(Dropout(0.3))\n",
        "\n",
        "    # Capa de salida\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "beZ1FHpaogTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este fragmento de código se define una función flexible para generar modelos con regularización y *Dropout* de forma configurable, evitando así duplicación innecesaria de código al probar distintas estrategias. La función se denomina `crear_modelo_regularizado` y recibe dos argumentos: `tipo`, que indica la estrategia de regularización a emplear (`'l2'`, `'elasticnet'` o `None`), y `dropout`, un valor booleano que determina si se incluyen capas `Dropout` entre las ocultas.\n",
        "\n",
        "En primer lugar, se inicializa un modelo secuencial con `Sequential()` y se añade una capa de entrada para imágenes de 28x28 píxeles. Luego, con `Flatten()`, la imagen se transforma en un vector unidimensional para que pueda ser procesada por las capas densas.\n",
        "\n",
        "Después se selecciona el tipo de regularización en función del argumento `tipo`. Si se indica `'l2'`, se aplica regularización L2 con un coeficiente de penalización de 0.001. Si se especifica `'elasticnet'`, se aplica una combinación L1 + L2 con coeficientes 0.0005 para cada término. En caso contrario, no se aplica ninguna penalización sobre los pesos.\n",
        "\n",
        "El núcleo del modelo consiste en un bucle que añade cuatro bloques ocultos. Cada uno está compuesto por una capa densa con 512 neuronas y la regularización correspondiente (si se ha indicado), seguida de una activación *LeakyReLU*, que permite mitigar el problema de unidades muertas. Si el argumento `dropout` es verdadero, se añade una capa `Dropout(0.3)` que desactiva aleatoriamente el 30 % de las neuronas durante el entrenamiento para reducir el sobreajuste.\n",
        "\n",
        "Finalmente, se incluye una capa de salida con 10 neuronas y activación `softmax`, adecuada para problemas de clasificación multiclase como MNIST. La función devuelve el modelo completo, listo para compilar y entrenar."
      ],
      "metadata": {
        "id": "XZC2p5SKogoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clase personalizada para detener el entrenamiento tras superar un umbral\n",
        "\n",
        "En esta sección se define una clase personalizada que implementa una estrategia avanzada de parada temprana (*early stopping*). A diferencia del callback estándar de Keras, este controlador permite **esperar a que el modelo alcance primero un determinado umbral de rendimiento** (por ejemplo, un 95 % de *val_accuracy*) antes de comenzar a evaluar si debe detenerse el entrenamiento. Esto evita que el entrenamiento se interrumpa prematuramente en fases iniciales donde aún se está lejos del objetivo, y solo activa la condición de parada cuando se ha demostrado una calidad mínima suficiente."
      ],
      "metadata": {
        "id": "mdF_z1dzpJ2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStoppingThreshold(Callback):\n",
        "    def __init__(self, monitor, threshold, min_delta, patience):\n",
        "        super().__init__()\n",
        "        self.monitor = monitor\n",
        "        self.threshold = threshold\n",
        "        self.min_delta = min_delta\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.best = -float('inf')\n",
        "        self.stopped_epoch = 0\n",
        "        self.stop_training = False\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        # Solo actuamos si ya hemos superado el umbral mínimo de rendimiento\n",
        "        if current >= self.threshold:\n",
        "            if current - self.best > self.min_delta:\n",
        "                self.best = current\n",
        "                self.wait = 0\n",
        "            else:\n",
        "                self.wait += 1\n",
        "                if self.wait >= self.patience:\n",
        "                    self.stopped_epoch = epoch\n",
        "                    self.model.stop_training = True\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(f\"\\nSe detuvo el entrenamiento en la época {self.stopped_epoch + 1} por falta de mejora tras superar el 95% de val_accuracy.\")"
      ],
      "metadata": {
        "id": "PPZJB1YqpImW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta clase, llamada `EarlyStoppingThreshold`, **hereda de `Callback`**, el componente base de Keras que permite ejecutar funciones personalizadas durante el entrenamiento. Está estructurada en tres partes:\n",
        "\n",
        "1. **Constructor `__init__()`**\n",
        "   Aquí se inicializan los parámetros del comportamiento del callback:\n",
        "\n",
        "   * `monitor`: métrica a seguir.\n",
        "   * `threshold`: valor mínimo que debe alcanzarse antes de activar la lógica de parada.\n",
        "   * `min_delta`: mejora mínima que debe producirse entre épocas consecutivas para no considerarse estancamiento.\n",
        "   * `patience`: número de épocas que se permiten sin mejora significativa.\n",
        "     También se definen variables internas para almacenar el mejor valor registrado, el conteo de espera (`wait`) y la época de detención.\n",
        "\n",
        "2. **Método `on_epoch_end()`**\n",
        "   Esta función se ejecuta automáticamente al final de cada época. Evalúa si se ha alcanzado el umbral definido (`threshold`).\n",
        "\n",
        "   * Si aún no se ha alcanzado, el callback no actúa.\n",
        "   * Si se ha alcanzado, compara la métrica actual con la mejor registrada:\n",
        "\n",
        "     * Si mejora lo suficiente (`> min_delta`), se actualiza el mejor valor y se reinicia el contador.\n",
        "     * Si no mejora, se incrementa `wait`; si este contador supera la paciencia permitida, se detiene el entrenamiento.\n",
        "\n",
        "3. **Método `on_train_end()`**\n",
        "   Si el entrenamiento fue detenido por este callback, muestra un mensaje indicando en qué época ocurrió y que fue debido a la falta de mejora tras haber superado el umbral mínimo requerido."
      ],
      "metadata": {
        "id": "3mbkVmgTqBZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Función para entrenar los modelos con regularización"
      ],
      "metadata": {
        "id": "wVHT3tR2kD0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entrenar_modelo_regularizado(tipo, dropout):\n",
        "\n",
        "    \"\"\"\n",
        "    Entrena un modelo utilizando la arquitectura definida en crear_modelo_regularizado(),\n",
        "    con el tipo especificado de regularizador y si el dropout esta activado.\n",
        "    \"\"\"\n",
        "    model = crear_modelo_regularizado(tipo, dropout)  # Construimos la arquitectura base\n",
        "\n",
        "    # Compilamos el modelo\n",
        "    model.compile(\n",
        "        optimizer=SGD(learning_rate=0.01, momentum=0.9), # Optimizador SGD con momentum\n",
        "        loss='categorical_crossentropy',                 # Función de pérdida para clasificación multiclase\n",
        "        metrics=['accuracy']                             # Métrica que monitoriza la tasa de acierto\n",
        "    )\n",
        "\n",
        "    # Definimos un callback personalizado que detiene el entrenamiento si no mejora\n",
        "    # la precisión de validación tras alcanzar un umbral mínimo aceptable\n",
        "\n",
        "    early_stop = EarlyStoppingThreshold(\n",
        "        monitor='val_accuracy',     # Métrica que se evalúa en cada época (precisión en validación)\n",
        "        threshold=0.95,             # El criterio de parada solo se activa si se ha alcanzado al menos un 95 % de val_accuracy\n",
        "        min_delta=0.001,            # Se considera mejora solo si el incremento es mayor a este valor\n",
        "        patience=3                  # Número de épocas consecutivas sin mejora antes de detener el entrenamiento\n",
        "    )\n",
        "\n",
        "\n",
        "    history = model.fit(\n",
        "        norm_training_images,         # Datos de entrada normalizados\n",
        "        training_labels_onehot,       # Etiquetas codificadas en one-hot\n",
        "        epochs=30,                    # Número máximo de épocas\n",
        "        batch_size=128,               # Tamaño del batch especificado\n",
        "        validation_split=0.25,        # Porcentaje reservado para validación\n",
        "        verbose=1,                    # Mostrar resultados por época\n",
        "        callbacks=[early_stop]        # Detener si no hay mejora\n",
        "    )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "y3SJf1S1j55w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función entrena un modelo neuronal cuya arquitectura y regularización son configurables. Para ello, primero invoca `crear_modelo_regularizado()`, pasándole como argumentos el tipo de regularización deseada (`l2`, `elasticnet` o `None`) y un valor booleano que indica si se deben incluir capas `Dropout`. Esto permite construir una red adaptada a cada combinación experimental.\n",
        "\n",
        "A continuación, se compila el modelo utilizando el optimizador **SGD** con tasa de aprendizaje de `0.01` y `momentum=0.9`, junto con la función de pérdida `categorical_crossentropy`, adecuada para clasificación multiclase. La métrica principal que se monitoriza durante el entrenamiento es la **exactitud** (`accuracy`).\n",
        "\n",
        "Luego, se define un *callback* personalizado llamado `EarlyStoppingThreshold`, que supervisa la métrica de exactitud en validación (`val_accuracy`). Este callback detiene el entrenamiento si se alcanza una precisión mínima del 95 % y no se observa una mejora significativa (mayor a `0.01`) durante tres épocas consecutivas (`patience=3`). Esto permite evitar el sobreentrenamiento una vez que el modelo ha alcanzado un rendimiento aceptable.\n",
        "\n",
        "Finalmente, el modelo se entrena con los datos de entrada normalizados y las etiquetas codificadas en *one-hot*, durante un máximo de 30 épocas, con un `batch_size` de 128 y utilizando el 25 % del conjunto de entrenamiento para validación. El historial completo del entrenamiento (pérdida, exactitud, etc.) se almacena en la variable `history`, que se devuelve al finalizar para su análisis posterior."
      ],
      "metadata": {
        "id": "xGZww158nNfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento de los modelos"
      ],
      "metadata": {
        "id": "SdW4VdLQkKMA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUJ5AtunTFqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afc1354-b042-4df0-a9d4-5d71ada9ddee"
      },
      "source": [
        "# Creamos y entrenamos los modelos\n",
        "history_l2 = entrenar_modelo_regularizado(tipo='l2', dropout=False)\n",
        "history_elasticnet = entrenar_modelo_regularizado(tipo='elasticnet', dropout=False)\n",
        "history_dropout = entrenar_modelo_regularizado(tipo=None, dropout=True)\n",
        "history_l2_dropout = entrenar_modelo_regularizado(tipo='l2', dropout=True)\n",
        "history_elasticnet_dropout = entrenar_modelo_regularizado(tipo='elasticnet', dropout=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 42ms/step - accuracy: 0.7354 - loss: 3.0219 - val_accuracy: 0.9283 - val_loss: 2.1619\n",
            "Epoch 2/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.9295 - loss: 2.0888 - val_accuracy: 0.9440 - val_loss: 1.8725\n",
            "Epoch 3/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - accuracy: 0.9475 - loss: 1.8021 - val_accuracy: 0.9523 - val_loss: 1.6426\n",
            "Epoch 4/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.9571 - loss: 1.5715 - val_accuracy: 0.9577 - val_loss: 1.4471\n",
            "Epoch 5/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.9647 - loss: 1.3784 - val_accuracy: 0.9618 - val_loss: 1.2784\n",
            "Epoch 6/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9693 - loss: 1.2135 - val_accuracy: 0.9644 - val_loss: 1.1336\n",
            "Epoch 7/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9729 - loss: 1.0715 - val_accuracy: 0.9661 - val_loss: 1.0089\n",
            "Epoch 8/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9756 - loss: 0.9488 - val_accuracy: 0.9669 - val_loss: 0.9016\n",
            "Epoch 9/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.9789 - loss: 0.8426 - val_accuracy: 0.9677 - val_loss: 0.8087\n",
            "\n",
            "Se detuvo el entrenamiento en la época 9 por falta de mejora tras superar el 95% de val_accuracy.\n",
            "Epoch 1/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.7484 - loss: 21.3920 - val_accuracy: 0.9157 - val_loss: 13.3295\n",
            "Epoch 2/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9136 - loss: 11.3661 - val_accuracy: 0.9168 - val_loss: 6.3534\n",
            "Epoch 3/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.9111 - loss: 5.2183 - val_accuracy: 0.9001 - val_loss: 2.6175\n",
            "Epoch 4/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9000 - loss: 2.1473 - val_accuracy: 0.9014 - val_loss: 1.2241\n",
            "Epoch 5/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9030 - loss: 1.0921 - val_accuracy: 0.9063 - val_loss: 0.8329\n",
            "Epoch 6/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 51ms/step - accuracy: 0.9108 - loss: 0.7752 - val_accuracy: 0.9092 - val_loss: 0.6840\n",
            "Epoch 7/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - accuracy: 0.9159 - loss: 0.6406 - val_accuracy: 0.9130 - val_loss: 0.6066\n",
            "Epoch 8/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.9215 - loss: 0.5696 - val_accuracy: 0.9177 - val_loss: 0.5603\n",
            "Epoch 9/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9267 - loss: 0.5252 - val_accuracy: 0.9203 - val_loss: 0.5316\n",
            "Epoch 10/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - accuracy: 0.9310 - loss: 0.4949 - val_accuracy: 0.9239 - val_loss: 0.5084\n",
            "Epoch 11/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 42ms/step - accuracy: 0.9336 - loss: 0.4733 - val_accuracy: 0.9245 - val_loss: 0.4974\n",
            "Epoch 12/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9361 - loss: 0.4586 - val_accuracy: 0.9300 - val_loss: 0.4787\n",
            "Epoch 13/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9381 - loss: 0.4458 - val_accuracy: 0.9301 - val_loss: 0.4693\n",
            "Epoch 14/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9401 - loss: 0.4366 - val_accuracy: 0.9279 - val_loss: 0.4721\n",
            "Epoch 15/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9402 - loss: 0.4311 - val_accuracy: 0.9241 - val_loss: 0.4783\n",
            "Epoch 16/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - accuracy: 0.9409 - loss: 0.4248 - val_accuracy: 0.9237 - val_loss: 0.4754\n",
            "Epoch 17/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.9428 - loss: 0.4172 - val_accuracy: 0.9268 - val_loss: 0.4635\n",
            "Epoch 18/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.9446 - loss: 0.4088 - val_accuracy: 0.9290 - val_loss: 0.4557\n",
            "Epoch 19/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9453 - loss: 0.4022 - val_accuracy: 0.9311 - val_loss: 0.4481\n",
            "Epoch 20/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.9459 - loss: 0.3955 - val_accuracy: 0.9325 - val_loss: 0.4400\n",
            "Epoch 21/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.9470 - loss: 0.3897 - val_accuracy: 0.9327 - val_loss: 0.4348\n",
            "Epoch 22/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9471 - loss: 0.3851 - val_accuracy: 0.9334 - val_loss: 0.4330\n",
            "Epoch 23/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9481 - loss: 0.3813 - val_accuracy: 0.9338 - val_loss: 0.4279\n",
            "Epoch 24/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9491 - loss: 0.3778 - val_accuracy: 0.9349 - val_loss: 0.4250\n",
            "Epoch 25/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.9505 - loss: 0.3738 - val_accuracy: 0.9349 - val_loss: 0.4219\n",
            "Epoch 26/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.9514 - loss: 0.3701 - val_accuracy: 0.9334 - val_loss: 0.4261\n",
            "Epoch 27/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9518 - loss: 0.3682 - val_accuracy: 0.9358 - val_loss: 0.4181\n",
            "Epoch 28/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.9527 - loss: 0.3648 - val_accuracy: 0.9347 - val_loss: 0.4223\n",
            "Epoch 29/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - accuracy: 0.9528 - loss: 0.3634 - val_accuracy: 0.9331 - val_loss: 0.4249\n",
            "Epoch 30/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.9534 - loss: 0.3614 - val_accuracy: 0.9348 - val_loss: 0.4221\n",
            "Epoch 1/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 37ms/step - accuracy: 0.6507 - loss: 1.0884 - val_accuracy: 0.9262 - val_loss: 0.2481\n",
            "Epoch 2/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.9097 - loss: 0.3020 - val_accuracy: 0.9432 - val_loss: 0.1910\n",
            "Epoch 3/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9321 - loss: 0.2305 - val_accuracy: 0.9549 - val_loss: 0.1544\n",
            "Epoch 4/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9390 - loss: 0.1995 - val_accuracy: 0.9590 - val_loss: 0.1387\n",
            "Epoch 5/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.9486 - loss: 0.1700 - val_accuracy: 0.9632 - val_loss: 0.1254\n",
            "Epoch 6/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.9527 - loss: 0.1557 - val_accuracy: 0.9629 - val_loss: 0.1239\n",
            "\n",
            "Se detuvo el entrenamiento en la época 6 por falta de mejora tras superar el 95% de val_accuracy.\n",
            "Epoch 1/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.6461 - loss: 3.1948 - val_accuracy: 0.9246 - val_loss: 2.1660\n",
            "Epoch 2/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.9054 - loss: 2.1618 - val_accuracy: 0.9432 - val_loss: 1.8726\n",
            "Epoch 3/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9284 - loss: 1.8626 - val_accuracy: 0.9517 - val_loss: 1.6384\n",
            "Epoch 4/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9404 - loss: 1.6291 - val_accuracy: 0.9565 - val_loss: 1.4445\n",
            "Epoch 5/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.9463 - loss: 1.4293 - val_accuracy: 0.9585 - val_loss: 1.2795\n",
            "Epoch 6/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.9518 - loss: 1.2648 - val_accuracy: 0.9609 - val_loss: 1.1342\n",
            "\n",
            "Se detuvo el entrenamiento en la época 6 por falta de mejora tras superar el 95% de val_accuracy.\n",
            "Epoch 1/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.6508 - loss: 21.5478 - val_accuracy: 0.9129 - val_loss: 13.3211\n",
            "Epoch 2/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 42ms/step - accuracy: 0.8922 - loss: 11.4220 - val_accuracy: 0.9157 - val_loss: 6.3494\n",
            "Epoch 3/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 50ms/step - accuracy: 0.8912 - loss: 5.2933 - val_accuracy: 0.9075 - val_loss: 2.7064\n",
            "Epoch 4/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.8752 - loss: 2.3777 - val_accuracy: 0.9055 - val_loss: 1.4892\n",
            "Epoch 5/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.8712 - loss: 1.4717 - val_accuracy: 0.9074 - val_loss: 1.0997\n",
            "Epoch 6/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.8767 - loss: 1.1593 - val_accuracy: 0.9177 - val_loss: 0.9150\n",
            "Epoch 7/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - accuracy: 0.8797 - loss: 1.0142 - val_accuracy: 0.9181 - val_loss: 0.8277\n",
            "Epoch 8/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.8836 - loss: 0.9395 - val_accuracy: 0.9221 - val_loss: 0.7704\n",
            "Epoch 9/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - accuracy: 0.8894 - loss: 0.8848 - val_accuracy: 0.9271 - val_loss: 0.7271\n",
            "Epoch 10/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.8912 - loss: 0.8538 - val_accuracy: 0.9275 - val_loss: 0.7029\n",
            "Epoch 11/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8923 - loss: 0.8304 - val_accuracy: 0.9286 - val_loss: 0.6866\n",
            "Epoch 12/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.8944 - loss: 0.8104 - val_accuracy: 0.9309 - val_loss: 0.6747\n",
            "Epoch 13/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - accuracy: 0.8964 - loss: 0.7953 - val_accuracy: 0.9300 - val_loss: 0.6642\n",
            "Epoch 14/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.8981 - loss: 0.7835 - val_accuracy: 0.9324 - val_loss: 0.6524\n",
            "Epoch 15/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.8999 - loss: 0.7693 - val_accuracy: 0.9343 - val_loss: 0.6413\n",
            "Epoch 16/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - accuracy: 0.8992 - loss: 0.7642 - val_accuracy: 0.9346 - val_loss: 0.6373\n",
            "Epoch 17/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - accuracy: 0.9005 - loss: 0.7606 - val_accuracy: 0.9317 - val_loss: 0.6353\n",
            "Epoch 18/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - accuracy: 0.9001 - loss: 0.7521 - val_accuracy: 0.9329 - val_loss: 0.6307\n",
            "Epoch 19/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.9049 - loss: 0.7391 - val_accuracy: 0.9367 - val_loss: 0.6195\n",
            "Epoch 20/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - accuracy: 0.9030 - loss: 0.7367 - val_accuracy: 0.9346 - val_loss: 0.6182\n",
            "Epoch 21/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9065 - loss: 0.7283 - val_accuracy: 0.9343 - val_loss: 0.6203\n",
            "Epoch 22/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.9027 - loss: 0.7315 - val_accuracy: 0.9382 - val_loss: 0.6077\n",
            "Epoch 23/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.9060 - loss: 0.7246 - val_accuracy: 0.9395 - val_loss: 0.6044\n",
            "Epoch 24/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - accuracy: 0.9054 - loss: 0.7229 - val_accuracy: 0.9347 - val_loss: 0.6162\n",
            "Epoch 25/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.9055 - loss: 0.7196 - val_accuracy: 0.9357 - val_loss: 0.6068\n",
            "Epoch 26/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - accuracy: 0.9028 - loss: 0.7205 - val_accuracy: 0.9400 - val_loss: 0.5953\n",
            "Epoch 27/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - accuracy: 0.9078 - loss: 0.7157 - val_accuracy: 0.9380 - val_loss: 0.6003\n",
            "Epoch 28/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - accuracy: 0.9051 - loss: 0.7115 - val_accuracy: 0.9341 - val_loss: 0.6160\n",
            "Epoch 29/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - accuracy: 0.9064 - loss: 0.7161 - val_accuracy: 0.9442 - val_loss: 0.5829\n",
            "Epoch 30/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - accuracy: 0.9086 - loss: 0.7062 - val_accuracy: 0.9414 - val_loss: 0.5889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resultados"
      ],
      "metadata": {
        "id": "hbZjjr5bOBOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario con los historiales y su etiqueta asociada\n",
        "historicos = {\n",
        "    'l2': history_l2,\n",
        "    'elasticnet': history_elasticnet,\n",
        "    'dropout': history_dropout,\n",
        "    'l2_dropout': history_l2_dropout,\n",
        "    'elasticnet_dropout': history_elasticnet_dropout\n",
        "}\n",
        "\n",
        "# Lista para guardar los resultados\n",
        "resultados = []\n",
        "\n",
        "# Iteramos sobre cada historial\n",
        "for nombre, hist in historicos.items():\n",
        "    val_acc = hist.history['val_accuracy']\n",
        "    val_loss = hist.history['val_loss']\n",
        "    mejor_epoca = int(pd.Series(val_acc).idxmax()) + 1  # +1 porque las epochs se indexan desde 0\n",
        "    resultados.append({\n",
        "        'Modelo': nombre,\n",
        "        'Época óptima': mejor_epoca,\n",
        "        'Val Accuracy (%)': round(val_acc[mejor_epoca - 1] * 100, 2),\n",
        "        'Val Loss': round(val_loss[mejor_epoca - 1], 4)\n",
        "    })\n",
        "\n",
        "# Creamos el DataFrame\n",
        "tabla_resultados = pd.DataFrame(resultados)\n",
        "\n",
        "# Mostramos la tabla de resultados\n",
        "tabla_resultados.sort_values(by=\"Val Accuracy (%)\", ascending=False)"
      ],
      "metadata": {
        "id": "qOn_cSjGugDr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "17ba24b8-bd58-4105-f249-233498a56e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Modelo  Época óptima  Val Accuracy (%)  Val Loss\n",
              "0                  l2             9             96.77    0.8087\n",
              "2             dropout             5             96.32    0.1254\n",
              "3          l2_dropout             6             96.09    1.1342\n",
              "4  elasticnet_dropout            29             94.42    0.5829\n",
              "1          elasticnet            27             93.58    0.4181"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a6571ba-e290-41b3-891e-a6d5660b838a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Época óptima</th>\n",
              "      <th>Val Accuracy (%)</th>\n",
              "      <th>Val Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l2</td>\n",
              "      <td>9</td>\n",
              "      <td>96.77</td>\n",
              "      <td>0.8087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dropout</td>\n",
              "      <td>5</td>\n",
              "      <td>96.32</td>\n",
              "      <td>0.1254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>l2_dropout</td>\n",
              "      <td>6</td>\n",
              "      <td>96.09</td>\n",
              "      <td>1.1342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>elasticnet_dropout</td>\n",
              "      <td>29</td>\n",
              "      <td>94.42</td>\n",
              "      <td>0.5829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>elasticnet</td>\n",
              "      <td>27</td>\n",
              "      <td>93.58</td>\n",
              "      <td>0.4181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a6571ba-e290-41b3-891e-a6d5660b838a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a6571ba-e290-41b3-891e-a6d5660b838a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a6571ba-e290-41b3-891e-a6d5660b838a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e666b13e-5cc9-44dd-aa34-e5c675de10c1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e666b13e-5cc9-44dd-aa34-e5c675de10c1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e666b13e-5cc9-44dd-aa34-e5c675de10c1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tabla_resultados\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"dropout\",\n          \"elasticnet\",\n          \"l2_dropout\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u00c9poca \\u00f3ptima\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 5,\n        \"max\": 29,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          27,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Accuracy (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3661734882510332,\n        \"min\": 93.58,\n        \"max\": 96.77,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          96.32,\n          93.58,\n          96.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38294582253890697,\n        \"min\": 0.1254,\n        \"max\": 1.1342,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1254,\n          0.4181,\n          1.1342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este fragmento de código permite organizar y comparar los resultados obtenidos tras entrenar los modelos regularizados, extrayendo de cada uno de ellos las métricas clave para evaluar su desempeño.\n",
        "\n",
        "En primer lugar, se define un diccionario llamado `historicos` donde se almacena el historial de entrenamiento de cada modelo bajo una etiqueta identificativa. A continuación, se inicializa una lista vacía llamada `resultados`, que servirá para almacenar la información más relevante de cada entrenamiento.\n",
        "\n",
        "El bucle `for` recorre cada uno de los modelos registrados en `historicos`. Para cada modelo, se extraen las listas de exactitud de validación (`val_accuracy`) y pérdida de validación (`val_loss`) que fueron registradas durante el proceso de entrenamiento. A partir de estas listas, se identifica la época en la que se alcanzó la máxima exactitud de validación utilizando `idxmax()`. Como las épocas en Keras se indexan desde cero, se añade una unidad al valor para que el número de época refleje correctamente la posición.\n",
        "\n",
        "Con estos datos, se construye un diccionario por modelo donde se almacena: el nombre del modelo, la época óptima, la exactitud de validación en esa época expresada como porcentaje con dos decimales, y la pérdida de validación en ese mismo punto. Cada uno de estos diccionarios se añade a la lista `resultados`.\n",
        "\n",
        "Finalmente, se convierte la lista en un `DataFrame` llamado `tabla_resultados`, que permite visualizar los datos de forma estructurada y ordenada.\n",
        "\n",
        "Los resultados obtenidos reflejan con claridad el impacto de las distintas estrategias de regularización aplicadas sobre la red neuronal final, tanto de forma individual como combinada.\n",
        "\n",
        "El mejor rendimiento se ha obtenido utilizando **regularización L2 de forma aislada**, alcanzando una *val_accuracy* del **96.77 %** en la **época 9**. Aunque su pérdida de validación es elevada (**0.8087**), lo que podría indicar cierta inestabilidad o dispersión en los errores, el modelo logra generalizar bien en cuanto a acierto global. Esto refuerza el hecho de que L2 es una técnica robusta y muy utilizada en contextos reales, ya que penaliza los pesos grandes sin forzar la dispersión total como hace L1.\n",
        "\n",
        "En segundo lugar, el modelo con **Dropout** sin ninguna otra regularización obtiene una precisión ligeramente inferior (**96.32 %**) pero con una **pérdida de validación mucho más baja** (**0.1254**), lo que sugiere una salida más estable y un mejor control del sobreajuste en las primeras épocas. Además, converge rápidamente (época 5), lo que puede ser ventajoso en entornos con limitaciones de tiempo o recursos.\n",
        "\n",
        "La combinación de **Dropout con L2** o con **Elastic Net** no ha resultado tan efectiva. En el caso de **L2 + Dropout**, aunque se alcanza una *val\\_accuracy* aceptable (**96.09 %**), la pérdida de validación es **la más alta del conjunto** (**1.1342**), indicando posiblemente un conflicto entre ambas regularizaciones que penaliza en exceso el aprendizaje. El modelo puede haber quedado subajustado o haber sufrido una oscilación excesiva durante el entrenamiento.\n",
        "\n",
        "En cuanto a **Elastic Net**, tanto de forma individual como combinada con Dropout, los resultados han sido claramente inferiores. La precisión final se sitúa por debajo del 95 % en ambos casos (**93.58 %** y **94.42 %**), y aunque las pérdidas de validación no son excesivas, **los modelos requieren muchas más épocas para converger** (27 y 29, respectivamente). Esto sugiere que **la penalización simultánea L1 y L2 puede no ser adecuada** en este caso, probablemente por la naturaleza del conjunto MNIST, que no requiere un nivel tan agresivo de regularización combinada.\n",
        "\n",
        "**En resumen**, los dos mejores modelos han sido:\n",
        "\n",
        "1. **L2 regularización (val_accuracy = 96.77 %)**\n",
        "2. **Dropout (val_accuracy = 96.32 %, val\\_loss mucho menor)**\n",
        "\n",
        "Aunque la regularización *L2* obtiene una *val_accuracy* ligeramente superior (96.77 % frente a 96.32 %), esta diferencia es mínima y no representa una ventaja sustancial en términos prácticos. En cambio, la **pérdida de validación** del modelo con Dropout es **mucho menor** (0.1254 frente a 0.8087), lo que indica que sus predicciones son más estables y que **el modelo se ajusta mejor al conjunto de validación sin sobreajustarse**.\n",
        "\n",
        "Además, el modelo con Dropout **alcanza su mejor rendimiento en menos épocas** (época 5 frente a la 9 del modelo con L2), lo que implica un entrenamiento más eficiente y menor riesgo de sobreentrenamiento.\n",
        "\n",
        "Por tanto, teniendo en cuenta el equilibrio entre **precisión, pérdida y eficiencia**, se concluye que **la red neuronal final seleccionada será la que utiliza Dropout como única técnica de regularización**. Este modelo garantiza un rendimiento competitivo con una mayor capacidad de generalización."
      ],
      "metadata": {
        "id": "0nJ2SYjLv_qS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento de la red final (modelo con *Dropout*)"
      ],
      "metadata": {
        "id": "bqF_2TNYafXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos la arquitectura final del modelo\n",
        "model_final = keras.models.Sequential()\n",
        "\n",
        "# Capa de entrada para imágenes de 28x28 píxeles\n",
        "model_final.add(Input(shape=(28, 28)))\n",
        "\n",
        "# Aplanamos la imagen en un vector de 784 elementos\n",
        "model_final.add(Flatten())\n",
        "\n",
        "# Añadimos 4 capas ocultas con 512 neuronas, activación LeakyReLU y Dropout\n",
        "for _ in range(4):\n",
        "    model_final.add(Dense(512))\n",
        "    model_final.add(LeakyReLU())        # Activación para evitar unidades muertas\n",
        "    model_final.add(Dropout(0.3))       # Dropout con 30% de apagado para reducir sobreajuste\n",
        "\n",
        "# Capa de salida con 10 neuronas (una por clase) y activación softmax\n",
        "model_final.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compilamos el modelo con SGD y momentum\n",
        "model_final.compile(\n",
        "    optimizer=SGD(learning_rate=0.01, momentum=0.9),  # Optimizador con inercia para mejorar la convergencia\n",
        "    loss='categorical_crossentropy',                  # Función de pérdida para clasificación multiclase\n",
        "    metrics=['accuracy']                              # Métrica de precisión para monitorización\n",
        ")\n",
        "\n",
        "# Definimos el callback EarlyStopping basado en val_loss\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',           # Observamos la pérdida en el conjunto de validación\n",
        "    patience=3,                   # Permitimos 3 épocas sin mejora\n",
        "    min_delta=0.001,              # Solo consideramos mejora si la pérdida baja al menos 0.001\n",
        "    restore_best_weights=True,   # Restauramos los mejores pesos automáticamente\n",
        "    verbose=1                     # Mostramos el motivo de parada anticipada\n",
        ")\n",
        "\n",
        "# Entrenamiento del modelo final\n",
        "history_final = model_final.fit(\n",
        "    norm_training_images,        # Imágenes de entrenamiento normalizadas\n",
        "    training_labels_onehot,      # Etiquetas codificadas en formato one-hot\n",
        "    epochs=30,                   # Número máximo de épocas\n",
        "    batch_size=128,              # Tamaño del batch\n",
        "    validation_split=0.25,       # Proporción reservada para validación\n",
        "    verbose=1,                   # Mostrar progreso por época\n",
        "    callbacks=[early_stop]       # Aplicar parada temprana si no hay mejora\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CNz-OzXcLbA",
        "outputId": "3a1991f4-b06a-4e3c-d3ef-a4bd855f5902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.6428 - loss: 1.0987 - val_accuracy: 0.9261 - val_loss: 0.2528\n",
            "Epoch 2/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9089 - loss: 0.3063 - val_accuracy: 0.9429 - val_loss: 0.1940\n",
            "Epoch 3/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.9289 - loss: 0.2346 - val_accuracy: 0.9539 - val_loss: 0.1564\n",
            "Epoch 4/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.9392 - loss: 0.1971 - val_accuracy: 0.9575 - val_loss: 0.1446\n",
            "Epoch 5/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9465 - loss: 0.1719 - val_accuracy: 0.9603 - val_loss: 0.1333\n",
            "Epoch 6/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.9533 - loss: 0.1510 - val_accuracy: 0.9628 - val_loss: 0.1253\n",
            "Epoch 7/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - accuracy: 0.9582 - loss: 0.1370 - val_accuracy: 0.9647 - val_loss: 0.1183\n",
            "Epoch 8/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.9608 - loss: 0.1318 - val_accuracy: 0.9664 - val_loss: 0.1110\n",
            "Epoch 9/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.9636 - loss: 0.1181 - val_accuracy: 0.9679 - val_loss: 0.1087\n",
            "Epoch 10/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.9637 - loss: 0.1141 - val_accuracy: 0.9679 - val_loss: 0.1034\n",
            "Epoch 11/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.9649 - loss: 0.1105 - val_accuracy: 0.9705 - val_loss: 0.0979\n",
            "Epoch 12/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9687 - loss: 0.1007 - val_accuracy: 0.9713 - val_loss: 0.0987\n",
            "Epoch 13/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.9708 - loss: 0.0952 - val_accuracy: 0.9713 - val_loss: 0.0942\n",
            "Epoch 14/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.9727 - loss: 0.0882 - val_accuracy: 0.9715 - val_loss: 0.0927\n",
            "Epoch 15/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9733 - loss: 0.0867 - val_accuracy: 0.9735 - val_loss: 0.0908\n",
            "Epoch 16/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.9744 - loss: 0.0828 - val_accuracy: 0.9747 - val_loss: 0.0880\n",
            "Epoch 17/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.9744 - loss: 0.0785 - val_accuracy: 0.9735 - val_loss: 0.0892\n",
            "Epoch 18/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9761 - loss: 0.0753 - val_accuracy: 0.9738 - val_loss: 0.0880\n",
            "Epoch 19/30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.9765 - loss: 0.0720 - val_accuracy: 0.9735 - val_loss: 0.0907\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 16.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código define y entrena la red neuronal definitiva utilizando la arquitectura y los hiperparámetros que han ofrecido el mejor rendimiento en validación.\n",
        "\n",
        "En primer lugar, se inicializa el modelo como una secuencia de capas (`Sequential`). Se establece una **capa de entrada** que acepta imágenes de 28x28 píxeles, seguida de una capa `Flatten()` que transforma cada imagen en un vector unidimensional de 784 características. Este aplanamiento es necesario para poder alimentar los datos a las capas densas que componen la red.\n",
        "\n",
        "La estructura principal del modelo está formada por **cuatro capas ocultas**, cada una con 512 neuronas. A cada capa densa le sigue una activación `LeakyReLU`, elegida por su capacidad para evitar el problema de *neuronas muertas* que puede darse con `ReLU`. Además, se incluye una capa `Dropout` con una tasa del 30 % después de cada activación, lo que fuerza al modelo a no depender excesivamente de ninguna neurona concreta y mejora la capacidad de generalización.\n",
        "\n",
        "A continuación, se añade la **capa de salida**, compuesta por 10 neuronas con activación `softmax`, que produce una distribución de probabilidad sobre las clases posibles (del 0 al 9).\n",
        "\n",
        "El modelo se **compila** utilizando el optimizador `SGD` con `momentum`, lo que permite que el descenso del gradiente tenga una trayectoria más estable, evitando oscilaciones y acelerando la convergencia. La función de pérdida es `categorical_crossentropy`, adecuada para clasificación multiclase con etiquetas codificadas en *one-hot*. Se monitoriza la métrica `accuracy` durante el entrenamiento.\n",
        "\n",
        "Se define un **callback de parada temprana (`EarlyStopping`)**, que interrumpe el entrenamiento si la pérdida en el conjunto de validación (`val_loss`) no mejora al menos 0.001 durante tres épocas consecutivas. Esto previene el sobreentrenamiento y asegura que se conserven los pesos del modelo en su mejor momento de generalización (`restore_best_weights=True`).\n",
        "\n",
        "Finalmente, se **entrena el modelo** con los datos normalizados y codificados. Se establece un máximo de 30 épocas, un `batch_size` de 128, y se reserva el 25 % del conjunto de entrenamiento como validación interna. El resultado del entrenamiento se almacena en `history_final`, que contiene el historial de métricas por época.\n",
        "\n",
        "Los resultados del entrenamiento de la red final muestran un rendimiento excelente y estable:\n",
        "\n",
        "- **Precisión en validación alcanzada:** 97.47 %\n",
        "- **Pérdida mínima de validación:** 0.0880\n",
        "- **Época óptima identificada automáticamente:** 16\n",
        "- **Activación del *EarlyStopping*** tras detectar que en las siguientes 3 épocas no hubo mejora significativa en la *val\\_loss*\n",
        "\n",
        "Este comportamiento indica que el modelo logró no solo superar con margen el umbral del 95 % exigido por la actividad, sino que además mantuvo una tendencia de mejora clara hasta aproximadamente la época 16. A partir de ese punto, las métricas comienzan a estancarse o a fluctuar ligeramente, por lo que la parada automática ha sido oportuna y eficaz para evitar sobreentrenamiento.\n",
        "\n",
        "En conjunto, el entrenamiento ha sido eficiente y confirma que la combinación elegida de **Dropout**, **SGD con momentum** y una arquitectura profunda con activación *LeakyReLU* ha sido adecuada para lograr un modelo final robusto, preciso y con buena capacidad de generalización."
      ],
      "metadata": {
        "id": "1c6eX8jadQlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Conclusiones\n",
        "\n",
        "A lo largo de esta actividad se ha llevado a cabo un proceso exhaustivo de diseño, ajuste y evaluación de redes neuronales para la clasificación de imágenes del conjunto MNIST. El objetivo final era desarrollar un modelo capaz de superar el 95 % de *val\\_accuracy* y, al mismo tiempo, garantizar una buena capacidad de generalización sin incurrir en sobreajuste. Para alcanzar este objetivo, se ha trabajado de forma sistemática en diferentes bloques, combinando teoría, experimentación y análisis crítico de resultados.\n",
        "\n",
        "En una primera fase, se abordaron aspectos fundamentales del preprocesamiento de datos, como la normalización de las imágenes (escalado al rango \\[0, 1]) y la conversión de las etiquetas a formato *one-hot*, lo que permitió preparar correctamente los datos de entrada y salida para su uso en redes neuronales densas.\n",
        "\n",
        "Posteriormente, se definieron modelos básicos utilizando capas densas y activaciones estándar como *ReLU*, aunque se observó que *LeakyReLU* ofrecía una mejor estabilidad al evitar el problema de unidades muertas. Se exploraron diferentes estrategias de inicialización de pesos, comprobando que la inicialización a ceros impedía el aprendizaje y que *Glorot Uniform* ofrecía un rendimiento robusto y equilibrado. Estos hallazgos fueron esenciales para garantizar una convergencia eficiente durante el entrenamiento.\n",
        "\n",
        "En la fase de optimización, se evaluaron varios optimizadores: *SGD*, *SGD con momentum*, *Adagrad*, *RMSProp* y *Adam*. Se comprobó que, aunque *Adam* converge más rápido, *SGD con momentum* ofrece un rendimiento más elevado si se le permite entrenar durante más tiempo, alcanzando mayores niveles de precisión y generalización. También se estudió el impacto del *batch size*, observando que valores mayores reducen el tiempo de entrenamiento y ofrecen una precisión muy similar, lo que llevó a seleccionar un valor de 128 como opción equilibrada.\n",
        "\n",
        "Una vez configurada la arquitectura y los parámetros principales, se introdujeron técnicas de regularización para mitigar el sobreajuste. Se probaron estrategias como *L2*, *Elastic Net* y *Dropout*, tanto de forma individual como combinada. Los resultados evidenciaron que Dropout, aplicado de forma aislada, era la opción más adecuada en este contexto: alcanzaba una precisión muy competitiva con una pérdida de validación más baja y una convergencia más rápida, lo que sugiere una mejor capacidad de generalización.\n",
        "\n",
        "Además, se implementó un *callback* personalizado para *early stopping*, que detenía el entrenamiento si no se observaban mejoras en *val\\_accuracy* tras alcanzar un umbral mínimo del 95 %. Esto permitió evitar sobreentrenamientos innecesarios y seleccionar automáticamente el modelo más eficaz.\n",
        "\n",
        "Este trabajo ha demostrado la importancia de ajustar cuidadosamente todos los componentes del entrenamiento de una red neuronal: desde el preprocesamiento y la arquitectura hasta los hiperparámetros del optimizador, el tamaño del batch y la regularización. La combinación de *SGD con momentum*, *Dropout* como regularizador, una arquitectura de 4 capas ocultas con 512 neuronas y *LeakyReLU*, junto con una estrategia de parada temprana basada en umbral, ha resultado ser la más adecuada para resolver el problema planteado."
      ],
      "metadata": {
        "id": "rhjR-HN-BWz1"
      }
    }
  ]
}