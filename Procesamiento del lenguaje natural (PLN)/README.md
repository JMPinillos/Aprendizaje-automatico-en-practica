# Procesamiento del Lenguaje Natural (PLN)

Esta secci贸n del repositorio recopila pr谩cticas centradas en el desarrollo de modelos de aprendizaje autom谩tico aplicados al procesamiento del lenguaje natural, con especial 茅nfasis en el idioma espa帽ol. Las actividades abordan tareas clave como la clasificaci贸n de texto y el reconocimiento de entidades nombradas, combinando t茅cnicas tradicionales de vectorizaci贸n con modelos preentrenados basados en *transformers*.

Cada notebook sigue una estructura completa, desde la exploraci贸n inicial y el tratamiento del texto, hasta la construcci贸n y evaluaci贸n de modelos. Se analizan m茅tricas de rendimiento adaptadas al problema, y se incluyen reflexiones sobre el uso pr谩ctico de cada t茅cnica en entornos reales.



###  Clasificaci贸n de mensajes en ingl茅s con *word embeddings* y *transformers*

Este proyecto aborda la clasificaci贸n de mensajes escritos en ingl茅s seg煤n su intensidad de odio, etiquetados en una escala del 1 al 5. Se comparan dos aproximaciones: un modelo neuronal tradicional entrenado desde cero y un modelo *transformer* preentrenado multiling眉e.

- En el primer enfoque, se construye un modelo secuencial con *word embeddings* y capas densas, utilizando t茅cnicas como `TextVectorization`, `Embedding` y *pooling*. Se eval煤a su rendimiento mediante m茅tricas como la exactitud categ贸rica y el error cuadr谩tico medio.

- En el segundo enfoque, se aplica *fine-tuning* sobre el modelo `bert-base-multilingual-cased` de Hugging Face. Se tokenizan los textos con `BertTokenizerFast`, se entrena con `Trainer`, y se eval煤a utilizando m煤ltiples m茅tricas de clasificaci贸n.

La actividad permite comparar el rendimiento entre modelos simples y modelos avanzados de *transformers*, mostrando una mejora significativa en la capacidad predictiva al utilizar modelos preentrenados.

[ `Word_embeddings_y_transformers_para_clasificaci贸n_de_texto.ipynb`](2-PLN_Clasificaci贸n_transformers/Word_embeddings_y_transformers_para_clasificaci贸n_de_texto.ipynb)



## Notebooks

### Reconocimiento de entidades nombradas (NER)

Este trabajo aborda la tarea de *Named Entity Recognition* sobre un corpus anotado manualmente en espa帽ol. Tras aplicar t茅cnicas de preprocesamiento textual, se implementa una red neuronal densa sobre secuencias codificadas con etiquetas *BIO*, entrenada con una funci贸n de p茅rdida categ贸rica y m茅tricas de exactitud por clase.

El estudio se centra en comprender el comportamiento del modelo al identificar correctamente entidades como nombres, ubicaciones y organizaciones, y se acompa帽a de visualizaciones de predicciones y matrices de confusi贸n para cada clase.

[ `Named_Entity_Recognition.ipynb`](1-Named_Entity_Recognition/Named_Entity_Recognition.ipynb)



### Clasificaci贸n de texto con *word embeddings* y *transformers*

Este proyecto compara dos aproximaciones para la clasificaci贸n de mensajes en espa帽ol. La primera utiliza una arquitectura basada en *word embeddings* y capas densas, mientras que la segunda incorpora un modelo *transformer* preentrenado, adaptado mediante *fine-tuning*.

El trabajo incluye la preparaci贸n del corpus, tokenizaci贸n con *AutoTokenizer*, vectorizaci贸n, entrenamiento supervisado y an谩lisis comparativo entre ambos enfoques. Se visualizan m茅tricas clave como la *exactitud*, la matriz de confusi贸n y las predicciones para evaluar el impacto de los *embeddings* frente al uso de modelos del estado del arte.

[ `Word_embeddings_y_transformers_para_clasificaci贸n_de_texto.ipynb`](2-PLN_Clasificaci贸n_transformers/Word_embeddings_y_transformers_para_clasificaci贸n_de_texto.ipynb)



<center>by <strong>Jose Manuel Pinillos</strong></center>