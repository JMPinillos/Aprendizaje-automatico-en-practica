# Procesamiento del Lenguaje Natural (PLN)

Esta secci贸n del repositorio recopila pr谩cticas centradas en el desarrollo de modelos de aprendizaje autom谩tico aplicados al procesamiento del lenguaje natural, con especial 茅nfasis en el idioma espa帽ol. Las actividades abordan tareas clave como la clasificaci贸n de texto y el reconocimiento de entidades nombradas, combinando t茅cnicas tradicionales de vectorizaci贸n con modelos preentrenados basados en *transformers*.

Cada notebook sigue una estructura completa, desde la exploraci贸n inicial y el tratamiento del texto, hasta la construcci贸n y evaluaci贸n de modelos. Se analizan m茅tricas de rendimiento adaptadas al problema, y se incluyen reflexiones sobre el uso pr谩ctico de cada t茅cnica en entornos reales.



## Notebooks

### Reconocimiento de entidades nombradas (NER)

Este trabajo aborda la tarea de *Named Entity Recognition* sobre un corpus anotado manualmente en espa帽ol. Tras aplicar t茅cnicas de preprocesamiento textual, se implementa una red neuronal densa sobre secuencias codificadas con etiquetas *BIO*, entrenada con una funci贸n de p茅rdida categ贸rica y m茅tricas de exactitud por clase.

El estudio se centra en comprender el comportamiento del modelo al identificar correctamente entidades como nombres, ubicaciones y organizaciones, y se acompa帽a de visualizaciones de predicciones y matrices de confusi贸n para cada clase.

[ `Named_Entity_Recognition.ipynb`](1-Named_Entity_Recognition/Named_Entity_Recognition.ipynb)



### Clasificaci贸n de texto con *word embeddings* y *transformers*

Este proyecto compara dos aproximaciones para la clasificaci贸n de mensajes en espa帽ol. La primera utiliza una arquitectura basada en *word embeddings* y capas densas, mientras que la segunda incorpora un modelo *transformer* preentrenado, adaptado mediante *fine-tuning*.

El trabajo incluye la preparaci贸n del corpus, tokenizaci贸n con *AutoTokenizer*, vectorizaci贸n, entrenamiento supervisado y an谩lisis comparativo entre ambos enfoques. Se visualizan m茅tricas clave como la *exactitud*, la matriz de confusi贸n y las predicciones para evaluar el impacto de los *embeddings* frente al uso de modelos del estado del arte.

[ `Word_embeddings_y_transformers_para_clasificaci贸n_de_texto.ipynb`](2-PLN_Clasificaci贸n_transformers/Word_embeddings_y_transformers_para_clasificaci贸n_de_texto.ipynb)



<center>by <strong>Jose Manuel Pinillos</strong></center>