# Redes Neuronales y Aprendizaje Profundo

En esta secci贸n se re煤nen pr谩cticas avanzadas centradas en el dise帽o, entrenamiento y evaluaci贸n de redes neuronales, abarcando desde arquitecturas densas cl谩sicas como **perceptrones multicapa** hasta modelos especializados como **redes convolucionales (CNN)** y **redes recurrentes (RNN)**. Estas actividades forman parte del itinerario del M谩ster en Inteligencia Artificial y reflejan un dominio progresivo de t茅cnicas profundas aplicadas a diferentes tipos de datos y tareas.

Cada *notebook* implementa un caso pr谩ctico completo, desde la preparaci贸n y transformaci贸n de datos hasta la definici贸n del modelo, su entrenamiento con distintas estrategias y el an谩lisis cr铆tico de los resultados. Se presta especial atenci贸n a la arquitectura de las redes, el impacto de los hiperpar谩metros, el uso de t茅cnicas de regularizaci贸n, y la adecuaci贸n de cada tipo de red al problema planteado.

Esta colecci贸n de trabajos demuestra la capacidad para aplicar t茅cnicas de *Deep Learning* de forma eficaz, tanto en entornos visuales como en procesamiento secuencial de datos, con un enfoque anal铆tico y orientado a resultados reales.



## Notebooks

### Clasificaci贸n de d铆gitos con perceptrones multicapa

Este trabajo explora el uso de redes neuronales densas (*fully connected*) para la clasificaci贸n del conjunto de im谩genes manuscritas *MNIST*. Se define una arquitectura tipo *Multilayer Perceptron (MLP)*, evaluando el impacto del n煤mero de neuronas, funciones de activaci贸n, 茅pocas y algoritmos de optimizaci贸n.

El estudio incluye una comparaci贸n de optimizadores como *SGD*, *Adam*, *RMSprop* o *Adagrad*, as铆 como t茅cnicas de regularizaci贸n (*Dropout*, *L2*) y el uso de *EarlyStopping*. Se automatiza el entrenamiento y evaluaci贸n mediante funciones personalizadas y se recopilan m茅tricas clave en un *DataFrame* para su an谩lisis comparativo.

[`Clasificaci贸n_de_d铆gitos_utilizando_perceptrones_multicapa.ipynb`](1-Clasificaci贸n_de_d铆gitos_utilizando_perceptrones_multicapa/Clasificaci贸n_de_d铆gitos_utilizando_perceptrones_multicapa.ipynb)



### Clasificaci贸n visual con redes convolucionales (CNN)

En este notebook se implementa un modelo basado en redes convolucionales profundas para abordar la clasificaci贸n de im谩genes del conjunto *MNIST*. Se definen m煤ltiples bloques de capas *Conv2D*, *MaxPooling* y *Dropout*, adaptando la arquitectura a la complejidad de los datos visuales.

El trabajo incluye la comparaci贸n de distintos tama帽os de filtros, funciones de activaci贸n y configuraciones de *pooling*, as铆 como una optimizaci贸n progresiva del rendimiento mediante ajuste de hiperpar谩metros. Se analiza el efecto de la regularizaci贸n y se interpretan los resultados a partir de las curvas de aprendizaje y las m茅tricas de evaluaci贸n obtenidas.

[`Redes_neuronales_convolucionales.ipynb`](2-Redes_Neuronales_Convolucionales/Redes_neuronales_convolucionales.ipynb)



### Predicci贸n secuencial con redes neuronales recurrentes (RNN)

Este proyecto aborda la predicci贸n de la intensidad de odio en mensajes escritos en espa帽ol mediante redes neuronales recurrentes, utilizando una versi贸n simplificada y preprocesada del *dataset* original del proyecto transversal.

Se construye una arquitectura basada en una capa de *embedding* seguida de una *Bidirectional LSTM*. El trabajo incluye t茅cnicas de ponderaci贸n de clases para mitigar el desbalanceo, y se eval煤an distintas configuraciones de regularizaci贸n, funci贸n de p茅rdida y optimizadores.

[`Redes_Neuronales_Recurrentes.ipynb`](3-Redes_Neuronales_Recurrentes/Redes_Neuronales_Recurrentes.ipynb)



<center>by <strong>Jose Manuel Pinillos</strong></center>
